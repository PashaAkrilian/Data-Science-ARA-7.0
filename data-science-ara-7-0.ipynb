{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4662d40",
   "metadata": {
    "papermill": {
     "duration": 0.003126,
     "end_time": "2026-02-06T20:07:03.830086",
     "exception": false,
     "start_time": "2026-02-06T20:07:03.826960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Understanding & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51f96fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T20:07:03.835859Z",
     "iopub.status.busy": "2026-02-06T20:07:03.835565Z",
     "iopub.status.idle": "2026-02-06T20:07:36.981951Z",
     "shell.execute_reply": "2026-02-06T20:07:36.981126Z"
    },
    "papermill": {
     "duration": 33.151111,
     "end_time": "2026-02-06T20:07:36.983475",
     "exception": false,
     "start_time": "2026-02-06T20:07:03.832364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train images : 498\n",
      "[INFO] Train masks  : 498\n",
      "[INFO] Test images  : 295\n",
      "[INFO] Valid image-mask pairs: 498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing dataset: 100%|██████████| 498/498 [00:29<00:00, 16.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INSIGHT] Pothole presence distribution:\n",
      "area_ratio\n",
      "True    498\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[INSIGHT] Empty-mask ratio: 0.00%\n",
      "\n",
      "[INSIGHT] Pothole area ratio (% of image):\n",
      "count    498.000000\n",
      "mean       0.134860\n",
      "std        0.128772\n",
      "min        0.000235\n",
      "25%        0.040943\n",
      "50%        0.091678\n",
      "75%        0.193834\n",
      "max        0.674005\n",
      "Name: area_ratio, dtype: float64\n",
      "\n",
      "[INSIGHT] Number of components per image:\n",
      "count    498.000000\n",
      "mean       4.261044\n",
      "std        6.239045\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        2.000000\n",
      "75%        5.000000\n",
      "max       67.000000\n",
      "Name: num_components, dtype: float64\n",
      "\n",
      "[INSIGHT] Dominant component ratio:\n",
      "count    498.000000\n",
      "mean       0.112599\n",
      "std        0.119287\n",
      "min        0.000235\n",
      "25%        0.030156\n",
      "50%        0.066428\n",
      "75%        0.162189\n",
      "max        0.636689\n",
      "Name: max_component_ratio, dtype: float64\n",
      "\n",
      "[INSIGHT] Connected component area (pixels):\n",
      "count    2.122000e+03\n",
      "mean     5.588544e+04\n",
      "std      3.030841e+05\n",
      "min      1.000000e+00\n",
      "25%      3.930000e+02\n",
      "50%      1.913000e+03\n",
      "75%      1.203275e+04\n",
      "max      6.700584e+06\n",
      "Name: component_area, dtype: float64\n",
      "\n",
      "[RECOMMENDATION] Candidate MIN_AREA (remove FP): ~130 pixels\n",
      "\n",
      "[FEASIBILITY CHECK]\n",
      "Images with pothole <1% area: 11.85%\n",
      "[FEASIBILITY STATUS] FAVORABLE (0.80+ achievable)\n",
      "\n",
      "[THRESHOLD PRIOR]\n",
      "→ Start sweep in range: 0.30 – 0.45 (Dice-friendly)\n",
      "\n",
      "[INFO] Final training samples: 498\n",
      "\n",
      "[STAGE 1 COMPLETE — LEADERBOARD READY]\n",
      "✓ Dataset validated\n",
      "✓ Dice risk quantified\n",
      "✓ Min-area & threshold priors extracted\n",
      "✓ Ready for STAGE 2 (augmentation design)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 1 — Data Understanding & Preparation (FINAL FIX)\n",
    "# Data Science ARA 7.0 — Pothole Segmentation\n",
    "# Compatible with index-based filenames:\n",
    "#   train_XXX.jpg <-> mask_XXX.png\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# -------------------------------\n",
    "# Paths (Kaggle)\n",
    "# -------------------------------\n",
    "ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "\n",
    "TRAIN_IMG_DIR = ROOT / \"train\" / \"images\"\n",
    "TRAIN_MSK_DIR = ROOT / \"train\" / \"mask\"\n",
    "TEST_IMG_DIR  = ROOT / \"test\"  / \"images\"\n",
    "\n",
    "assert TRAIN_IMG_DIR.exists()\n",
    "assert TRAIN_MSK_DIR.exists()\n",
    "assert TEST_IMG_DIR.exists()\n",
    "\n",
    "# -------------------------------\n",
    "# Load file lists\n",
    "# -------------------------------\n",
    "train_imgs = sorted(TRAIN_IMG_DIR.glob(\"train_*.jpg\"))\n",
    "train_msks = sorted(TRAIN_MSK_DIR.glob(\"mask_*.png\"))\n",
    "test_imgs  = sorted(TEST_IMG_DIR.glob(\"test_*.jpg\"))\n",
    "\n",
    "print(f\"[INFO] Train images : {len(train_imgs)}\")\n",
    "print(f\"[INFO] Train masks  : {len(train_msks)}\")\n",
    "print(f\"[INFO] Test images  : {len(test_imgs)}\")\n",
    "\n",
    "assert len(train_imgs) == len(train_msks), \"Mismatch train image & mask count\"\n",
    "\n",
    "# -------------------------------\n",
    "# Pairing by index\n",
    "# -------------------------------\n",
    "pairs = list(zip(train_imgs, train_msks))\n",
    "print(f\"[INFO] Valid image-mask pairs: {len(pairs)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Profiling\n",
    "# -------------------------------\n",
    "image_records = []\n",
    "component_records = []\n",
    "\n",
    "for img_path, msk_path in tqdm(pairs, desc=\"Analyzing dataset\"):\n",
    "    mask = cv2.imread(str(msk_path), cv2.IMREAD_GRAYSCALE)\n",
    "    h, w = mask.shape\n",
    "    total_pixels = h * w\n",
    "\n",
    "    bin_mask = (mask > 0).astype(np.uint8)\n",
    "    pos_pixels = bin_mask.sum()\n",
    "    area_ratio = pos_pixels / total_pixels\n",
    "\n",
    "    lbl = label(bin_mask)\n",
    "    regions = regionprops(lbl)\n",
    "\n",
    "    num_components = len(regions)\n",
    "    comp_areas = [r.area for r in regions]\n",
    "\n",
    "    max_comp_ratio = max(comp_areas) / total_pixels if comp_areas else 0\n",
    "\n",
    "    image_records.append({\n",
    "        \"image_id\": img_path.name,\n",
    "        \"area_ratio\": area_ratio,\n",
    "        \"num_components\": num_components,\n",
    "        \"max_component_ratio\": max_comp_ratio\n",
    "    })\n",
    "\n",
    "    for r in regions:\n",
    "        component_records.append({\n",
    "            \"image_id\": img_path.name,\n",
    "            \"component_area\": r.area,\n",
    "            \"component_ratio\": r.area / total_pixels\n",
    "        })\n",
    "\n",
    "df_img = pd.DataFrame(image_records)\n",
    "df_comp = pd.DataFrame(component_records)\n",
    "\n",
    "# -------------------------------\n",
    "# INSIGHTS\n",
    "# -------------------------------\n",
    "print(\"\\n[INSIGHT] Pothole presence distribution:\")\n",
    "print((df_img[\"area_ratio\"] > 0).value_counts())\n",
    "\n",
    "empty_ratio = (df_img[\"area_ratio\"] == 0).mean()\n",
    "print(f\"\\n[INSIGHT] Empty-mask ratio: {empty_ratio:.2%}\")\n",
    "\n",
    "print(\"\\n[INSIGHT] Pothole area ratio (% of image):\")\n",
    "print(df_img[\"area_ratio\"].describe())\n",
    "\n",
    "print(\"\\n[INSIGHT] Number of components per image:\")\n",
    "print(df_img[\"num_components\"].describe())\n",
    "\n",
    "print(\"\\n[INSIGHT] Dominant component ratio:\")\n",
    "print(df_img[\"max_component_ratio\"].describe())\n",
    "\n",
    "print(\"\\n[INSIGHT] Connected component area (pixels):\")\n",
    "print(df_comp[\"component_area\"].describe())\n",
    "\n",
    "# -------------------------------\n",
    "# Leaderboard-oriented priors\n",
    "# -------------------------------\n",
    "min_area_prior = int(df_comp[\"component_area\"].quantile(0.10))\n",
    "print(f\"\\n[RECOMMENDATION] Candidate MIN_AREA (remove FP): ~{min_area_prior} pixels\")\n",
    "\n",
    "small_obj_ratio = (df_img[\"area_ratio\"] < 0.01).mean()\n",
    "print(\"\\n[FEASIBILITY CHECK]\")\n",
    "print(f\"Images with pothole <1% area: {small_obj_ratio:.2%}\")\n",
    "\n",
    "if small_obj_ratio < 0.20:\n",
    "    print(\"[FEASIBILITY STATUS] FAVORABLE (0.80+ achievable)\")\n",
    "else:\n",
    "    print(\"[FEASIBILITY STATUS] HARD (small-object dominant)\")\n",
    "\n",
    "print(\"\\n[THRESHOLD PRIOR]\")\n",
    "print(\"→ Start sweep in range: 0.30 – 0.45 (Dice-friendly)\")\n",
    "\n",
    "print(\"\\n[INFO] Final training samples:\", len(df_img))\n",
    "\n",
    "print(\"\\n[STAGE 1 COMPLETE — LEADERBOARD READY]\")\n",
    "print(\"✓ Dataset validated\")\n",
    "print(\"✓ Dice risk quantified\")\n",
    "print(\"✓ Min-area & threshold priors extracted\")\n",
    "print(\"✓ Ready for STAGE 2 (augmentation design)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7f199",
   "metadata": {
    "papermill": {
     "duration": 0.006514,
     "end_time": "2026-02-06T20:07:36.997063",
     "exception": false,
     "start_time": "2026-02-06T20:07:36.990549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing & Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce78ee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T20:07:37.011469Z",
     "iopub.status.busy": "2026-02-06T20:07:37.011161Z",
     "iopub.status.idle": "2026-02-06T20:07:45.159147Z",
     "shell.execute_reply": "2026-02-06T20:07:45.158271Z"
    },
    "papermill": {
     "duration": 8.15707,
     "end_time": "2026-02-06T20:07:45.160597",
     "exception": false,
     "start_time": "2026-02-06T20:07:37.003527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STAGE 2 CHECK — REVISED]\n",
      "✓ Train transform OK\n",
      "✓ Val/Test transform OK\n",
      "[STAGE 2 REVISED — READY FOR STAGE 3]\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Imports\n",
    "# ===============================\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ===============================\n",
    "# Global Config\n",
    "# ===============================\n",
    "IMG_SIZE = 512\n",
    "POS_VALUE = 255\n",
    "\n",
    "NEGATIVE_CROP_PROB = 0.3   # 30% background-only crop\n",
    "\n",
    "# ===============================\n",
    "# Mask Sanity\n",
    "# ===============================\n",
    "def sanitize_mask(mask: np.ndarray) -> np.ndarray:\n",
    "    return (mask > 0).astype(np.uint8) * POS_VALUE\n",
    "\n",
    "# ===============================\n",
    "# TRAIN AUGMENTATION (CROP-BASED)\n",
    "# ===============================\n",
    "train_tfms = A.Compose(\n",
    "    [\n",
    "        # --- crop instead of resize ---\n",
    "        A.RandomCrop(IMG_SIZE, IMG_SIZE),\n",
    "\n",
    "        # --- geometry ---\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.2),\n",
    "        A.Rotate(limit=10, p=0.3),\n",
    "\n",
    "        # --- illumination ---\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.2,\n",
    "            contrast_limit=0.2,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.RandomGamma(\n",
    "            gamma_limit=(80, 120),\n",
    "            p=0.3\n",
    "        ),\n",
    "\n",
    "        # --- texture robustness ---\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.15),\n",
    "        A.GaussNoise(p=0.15),\n",
    "\n",
    "        # --- normalize ---\n",
    "        A.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# VAL / TEST AUGMENTATION\n",
    "# ===============================\n",
    "val_tfms = A.Compose(\n",
    "    [\n",
    "        A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "        A.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225),\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Dataset (NEGATIVE-AWARE)\n",
    "# ===============================\n",
    "class PotholeDataset:\n",
    "    def __init__(self, image_paths, mask_paths, transforms):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(str(self.image_paths[idx]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = cv2.imread(str(self.mask_paths[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = sanitize_mask(mask)\n",
    "\n",
    "        # ---- NEGATIVE CROP LOGIC ----\n",
    "        if random.random() < NEGATIVE_CROP_PROB:\n",
    "            # force background-only crop\n",
    "            h, w = mask.shape\n",
    "            for _ in range(10):\n",
    "                y = random.randint(0, h - IMG_SIZE)\n",
    "                x = random.randint(0, w - IMG_SIZE)\n",
    "                patch = mask[y:y+IMG_SIZE, x:x+IMG_SIZE]\n",
    "                if patch.sum() == 0:\n",
    "                    img = img[y:y+IMG_SIZE, x:x+IMG_SIZE]\n",
    "                    mask = patch\n",
    "                    break\n",
    "\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented[\"image\"]\n",
    "        mask = augmented[\"mask\"] / POS_VALUE\n",
    "\n",
    "        return img, mask.float()\n",
    "\n",
    "# ===============================\n",
    "# Sanity Check\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[STAGE 2 CHECK — REVISED]\")\n",
    "    dummy_img = np.zeros((1024, 1024, 3), dtype=np.uint8)\n",
    "    dummy_mask = np.zeros((1024, 1024), dtype=np.uint8)\n",
    "\n",
    "    out = train_tfms(image=dummy_img, mask=dummy_mask)\n",
    "    print(\"✓ Train transform OK\")\n",
    "\n",
    "    out = val_tfms(image=dummy_img)\n",
    "    print(\"✓ Val/Test transform OK\")\n",
    "\n",
    "    print(\"[STAGE 2 REVISED — READY FOR STAGE 3]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e21b0",
   "metadata": {
    "papermill": {
     "duration": 0.006355,
     "end_time": "2026-02-06T20:07:45.173563",
     "exception": false,
     "start_time": "2026-02-06T20:07:45.167208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Construction & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6084ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T20:07:45.187689Z",
     "iopub.status.busy": "2026-02-06T20:07:45.186922Z",
     "iopub.status.idle": "2026-02-06T20:07:58.221706Z",
     "shell.execute_reply": "2026-02-06T20:07:58.220909Z"
    },
    "papermill": {
     "duration": 13.043515,
     "end_time": "2026-02-06T20:07:58.223425",
     "exception": false,
     "start_time": "2026-02-06T20:07:45.179910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q segmentation-models-pytorch==0.3.3 timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2890b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T20:07:58.240193Z",
     "iopub.status.busy": "2026-02-06T20:07:58.239891Z",
     "iopub.status.idle": "2026-02-06T20:41:05.847491Z",
     "shell.execute_reply": "2026-02-06T20:41:05.846397Z"
    },
    "papermill": {
     "duration": 1987.618148,
     "end_time": "2026-02-06T20:41:05.849303",
     "exception": false,
     "start_time": "2026-02-06T20:07:58.231155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "[INFO] Train: 423 | Val: 75\n",
      "\n",
      "===== TRAINING UNET++ =====\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74.4M/74.4M [00:00<00:00, 191MB/s]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 01 | TrainLoss 0.7037 | ValDice 0.4221\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 02 | TrainLoss 0.5645 | ValDice 0.4587\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 03 | TrainLoss 0.4801 | ValDice 0.5163\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 04 | TrainLoss 0.4088 | ValDice 0.5319\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 05 | TrainLoss 0.3835 | ValDice 0.5769\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 06 | TrainLoss 0.3461 | ValDice 0.5636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 07 | TrainLoss 0.3213 | ValDice 0.6027\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 08 | TrainLoss 0.3074 | ValDice 0.5702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 09 | TrainLoss 0.2902 | ValDice 0.5934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 10 | TrainLoss 0.3003 | ValDice 0.6206\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 11 | TrainLoss 0.2844 | ValDice 0.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 12 | TrainLoss 0.2612 | ValDice 0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 13 | TrainLoss 0.2560 | ValDice 0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 14 | TrainLoss 0.2564 | ValDice 0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 15 | TrainLoss 0.2451 | ValDice 0.5824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 16 | TrainLoss 0.2296 | ValDice 0.6010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 17 | TrainLoss 0.2123 | ValDice 0.6431\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 18 | TrainLoss 0.2350 | ValDice 0.5982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 19 | TrainLoss 0.2264 | ValDice 0.6017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 20 | TrainLoss 0.2183 | ValDice 0.6056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 21 | TrainLoss 0.1965 | ValDice 0.6141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 22 | TrainLoss 0.2001 | ValDice 0.6383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 23 | TrainLoss 0.1935 | ValDice 0.6078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 24 | TrainLoss 0.1956 | ValDice 0.6612\n",
      ">> Best unetpp saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 25 | TrainLoss 0.1861 | ValDice 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 26 | TrainLoss 0.2176 | ValDice 0.6220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 27 | TrainLoss 0.1810 | ValDice 0.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 28 | TrainLoss 0.1988 | ValDice 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 29 | TrainLoss 0.1971 | ValDice 0.6443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unetpp | Epoch 30 | TrainLoss 0.2004 | ValDice 0.6548\n",
      "[DONE] unetpp best Val Dice: 0.6612\n",
      "\n",
      "===== TRAINING DEEPLAB =====\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:00<00:00, 306MB/s]\n",
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 01 | TrainLoss 0.6302 | ValDice 0.3676\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 02 | TrainLoss 0.5522 | ValDice 0.4152\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 03 | TrainLoss 0.5042 | ValDice 0.4440\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 04 | TrainLoss 0.4760 | ValDice 0.4775\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 05 | TrainLoss 0.4290 | ValDice 0.4984\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 06 | TrainLoss 0.4293 | ValDice 0.5471\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 07 | TrainLoss 0.4205 | ValDice 0.5609\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 08 | TrainLoss 0.3928 | ValDice 0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 09 | TrainLoss 0.3920 | ValDice 0.5760\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 10 | TrainLoss 0.3749 | ValDice 0.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 11 | TrainLoss 0.3652 | ValDice 0.5166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 12 | TrainLoss 0.3232 | ValDice 0.5495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 13 | TrainLoss 0.3086 | ValDice 0.5870\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 14 | TrainLoss 0.3324 | ValDice 0.5449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 15 | TrainLoss 0.3158 | ValDice 0.5831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 16 | TrainLoss 0.2789 | ValDice 0.5729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 17 | TrainLoss 0.3004 | ValDice 0.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 18 | TrainLoss 0.2974 | ValDice 0.5642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 19 | TrainLoss 0.2718 | ValDice 0.5689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 20 | TrainLoss 0.2842 | ValDice 0.5976\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 21 | TrainLoss 0.2763 | ValDice 0.6049\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 22 | TrainLoss 0.2494 | ValDice 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 23 | TrainLoss 0.2475 | ValDice 0.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 24 | TrainLoss 0.2531 | ValDice 0.5537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 25 | TrainLoss 0.2251 | ValDice 0.5821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 26 | TrainLoss 0.2297 | ValDice 0.5846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 27 | TrainLoss 0.2427 | ValDice 0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 28 | TrainLoss 0.2331 | ValDice 0.5711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 29 | TrainLoss 0.2500 | ValDice 0.6247\n",
      ">> Best deeplab saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplab | Epoch 30 | TrainLoss 0.2081 | ValDice 0.5897\n",
      "[DONE] deeplab best Val Dice: 0.6247\n",
      "\n",
      "[STAGE 3 COMPLETE]\n",
      "UNet++  best Dice: 0.6612\n",
      "DeepLab best Dice: 0.6247\n",
      "→ Ready for STAGE 4\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Imports\n",
    "# ===============================\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import cv2\n",
    "\n",
    "# ===============================\n",
    "# Config\n",
    "# ===============================\n",
    "SEED = 42\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "LR = 2e-4\n",
    "WEIGHT_DECAY = 1e-2\n",
    "VAL_RATIO = 0.15\n",
    "ACCUM_STEPS = 2        # gradient accumulation\n",
    "IMG_SIZE = 512\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ===============================\n",
    "# Seed\n",
    "# ===============================\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ===============================\n",
    "# Dataset (SAFE CROP)\n",
    "# ===============================\n",
    "class PotholeDataset:\n",
    "    def __init__(self, image_paths, mask_paths=None, transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def random_crop_safe(self, img, mask=None, size=512):\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        if h >= size and w >= size:\n",
    "            y = random.randint(0, h - size)\n",
    "            x = random.randint(0, w - size)\n",
    "            img = img[y:y+size, x:x+size]\n",
    "            if mask is not None:\n",
    "                mask = mask[y:y+size, x:x+size]\n",
    "        else:\n",
    "            img = cv2.resize(img, (size, size), interpolation=cv2.INTER_LINEAR)\n",
    "            if mask is not None:\n",
    "                mask = cv2.resize(mask, (size, size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(str(self.image_paths[idx]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.mask_paths is not None:\n",
    "            mask = cv2.imread(str(self.mask_paths[idx]), cv2.IMREAD_GRAYSCALE)\n",
    "            mask = (mask > 0).astype(np.uint8) * 255\n",
    "\n",
    "            img, mask = self.random_crop_safe(img, mask, IMG_SIZE)\n",
    "\n",
    "            augmented = self.transforms(image=img, mask=mask)\n",
    "            img = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"] / 255.0\n",
    "\n",
    "            return img, mask.float()\n",
    "        else:\n",
    "            img, _ = self.random_crop_safe(img, None, IMG_SIZE)\n",
    "            augmented = self.transforms(image=img)\n",
    "            return augmented[\"image\"]\n",
    "\n",
    "# ===============================\n",
    "# Train / Val Split\n",
    "# ===============================\n",
    "idx_all = np.arange(len(train_imgs))\n",
    "idx_tr, idx_val = train_test_split(\n",
    "    idx_all,\n",
    "    test_size=VAL_RATIO,\n",
    "    random_state=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_imgs_tr = [train_imgs[i] for i in idx_tr]\n",
    "train_msks_tr = [train_msks[i] for i in idx_tr]\n",
    "val_imgs_tr   = [train_imgs[i] for i in idx_val]\n",
    "val_msks_tr   = [train_msks[i] for i in idx_val]\n",
    "\n",
    "print(f\"[INFO] Train: {len(train_imgs_tr)} | Val: {len(val_imgs_tr)}\")\n",
    "\n",
    "# ===============================\n",
    "# Datasets\n",
    "# ===============================\n",
    "train_dataset = PotholeDataset(\n",
    "    train_imgs_tr,\n",
    "    train_msks_tr,\n",
    "    transforms=train_tfms\n",
    ")\n",
    "\n",
    "val_dataset = PotholeDataset(\n",
    "    val_imgs_tr,\n",
    "    val_msks_tr,\n",
    "    transforms=val_tfms\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# DataLoaders\n",
    "# ===============================\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# Loss (SMALL OBJECT FRIENDLY)\n",
    "# ===============================\n",
    "dice_loss = smp.losses.DiceLoss(mode=\"binary\", from_logits=True)\n",
    "focal_loss = smp.losses.FocalLoss(\n",
    "    mode=\"binary\",\n",
    "    alpha=0.75,\n",
    "    gamma=2.0,\n",
    "    normalized=True\n",
    ")\n",
    "\n",
    "def criterion(logits, targets):\n",
    "    return dice_loss(logits, targets) + 0.5 * focal_loss(logits, targets)\n",
    "\n",
    "# ===============================\n",
    "# Dice Metric (SOFT)\n",
    "# ===============================\n",
    "@torch.no_grad()\n",
    "def dice_soft(probs, targets, eps=1e-7):\n",
    "    inter = (probs * targets).sum()\n",
    "    union = probs.sum() + targets.sum()\n",
    "    return (2 * inter + eps) / (union + eps)\n",
    "\n",
    "# ===============================\n",
    "# Models\n",
    "# ===============================\n",
    "def build_unetpp():\n",
    "    return smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b4\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "    )\n",
    "\n",
    "def build_deeplab():\n",
    "    return smp.DeepLabV3Plus(\n",
    "        encoder_name=\"resnet101\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "    )\n",
    "\n",
    "# ===============================\n",
    "# Train / Val loops\n",
    "# ===============================\n",
    "def train_one_epoch(model, loader, optimizer, scaler, epoch, name):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"{name} | Epoch {epoch}\", leave=False)\n",
    "\n",
    "    for step, (imgs, masks) in enumerate(pbar):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        masks = masks.to(DEVICE).unsqueeze(1)\n",
    "\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, masks) / ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % ACCUM_STEPS == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * ACCUM_STEPS\n",
    "        pbar.set_postfix(loss=f\"{loss.item() * ACCUM_STEPS:.4f}\")\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    dices = []\n",
    "\n",
    "    for imgs, masks in loader:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        masks = masks.to(DEVICE).unsqueeze(1)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        dices.append(dice_soft(probs, masks).item())\n",
    "\n",
    "    return float(np.mean(dices))\n",
    "\n",
    "# ===============================\n",
    "# Training Wrapper\n",
    "# ===============================\n",
    "def train_model(name, model):\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=LR,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=EPOCHS\n",
    "    )\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    best_dice = 0.0\n",
    "    ckpt_path = f\"{name}_best.pt\"\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        tr_loss = train_one_epoch(model, train_loader, optimizer, scaler, epoch, name)\n",
    "        val_dice = validate(model, val_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(\n",
    "            f\"{name} | Epoch {epoch:02d} | \"\n",
    "            f\"TrainLoss {tr_loss:.4f} | ValDice {val_dice:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            torch.save(model.state_dict(), ckpt_path)\n",
    "            print(f\">> Best {name} saved\")\n",
    "\n",
    "    print(f\"[DONE] {name} best Val Dice: {best_dice:.4f}\")\n",
    "    return ckpt_path, best_dice\n",
    "\n",
    "# ===============================\n",
    "# RUN\n",
    "# ===============================\n",
    "print(\"\\n===== TRAINING UNET++ =====\")\n",
    "unetpp_ckpt, unetpp_dice = train_model(\"unetpp\", build_unetpp())\n",
    "\n",
    "print(\"\\n===== TRAINING DEEPLAB =====\")\n",
    "deeplab_ckpt, deeplab_dice = train_model(\"deeplab\", build_deeplab())\n",
    "\n",
    "print(\"\\n[STAGE 3 COMPLETE]\")\n",
    "print(f\"UNet++  best Dice: {unetpp_dice:.4f}\")\n",
    "print(f\"DeepLab best Dice: {deeplab_dice:.4f}\")\n",
    "print(\"→ Ready for STAGE 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110861bc",
   "metadata": {
    "papermill": {
     "duration": 0.55952,
     "end_time": "2026-02-06T20:41:06.885159",
     "exception": false,
     "start_time": "2026-02-06T20:41:06.325639",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimization, Validation & Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf6f066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T20:41:07.834555Z",
     "iopub.status.busy": "2026-02-06T20:41:07.833783Z",
     "iopub.status.idle": "2026-02-06T20:43:45.393255Z",
     "shell.execute_reply": "2026-02-06T20:43:45.392278Z"
    },
    "papermill": {
     "duration": 158.035407,
     "end_time": "2026-02-06T20:43:45.394950",
     "exception": false,
     "start_time": "2026-02-06T20:41:07.359543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] UNet++ best model loaded\n",
      "\n",
      "[OPTIMIZATION] LB-stable sweep...\n",
      "thr=0.24 | area= 20 | DiceH=0.8411 | DiceS=0.6100 | Empty=25.33%\n",
      "thr=0.24 | area= 30 | DiceH=0.7623 | DiceS=0.6245 | Empty=18.67%\n",
      "thr=0.24 | area= 40 | DiceH=0.7581 | DiceS=0.5939 | Empty=22.67%\n",
      "thr=0.24 | area= 60 | DiceH=0.7847 | DiceS=0.6206 | Empty=21.33%\n",
      "thr=0.26 | area= 20 | DiceH=0.7750 | DiceS=0.6356 | Empty=18.67%\n",
      "thr=0.26 | area= 30 | DiceH=0.7885 | DiceS=0.6509 | Empty=17.33%\n",
      "thr=0.26 | area= 40 | DiceH=0.7732 | DiceS=0.6612 | Empty=16.00%\n",
      "thr=0.26 | area= 60 | DiceH=0.7644 | DiceS=0.6508 | Empty=17.33%\n",
      "thr=0.28 | area= 20 | DiceH=0.7991 | DiceS=0.6467 | Empty=20.00%\n",
      "thr=0.28 | area= 30 | DiceH=0.8021 | DiceS=0.6111 | Empty=21.33%\n",
      "thr=0.28 | area= 40 | DiceH=0.7432 | DiceS=0.6054 | Empty=18.67%\n",
      "thr=0.28 | area= 60 | DiceH=0.7761 | DiceS=0.6374 | Empty=24.00%\n",
      "thr=0.30 | area= 20 | DiceH=0.8103 | DiceS=0.6454 | Empty=18.67%\n",
      "thr=0.30 | area= 30 | DiceH=0.8159 | DiceS=0.6251 | Empty=21.33%\n",
      "thr=0.30 | area= 40 | DiceH=0.7916 | DiceS=0.6275 | Empty=18.67%\n",
      "thr=0.30 | area= 60 | DiceH=0.7887 | DiceS=0.6364 | Empty=21.33%\n",
      "thr=0.32 | area= 20 | DiceH=0.8149 | DiceS=0.6235 | Empty=22.67%\n",
      "thr=0.32 | area= 30 | DiceH=0.7954 | DiceS=0.6178 | Empty=22.67%\n",
      "thr=0.32 | area= 40 | DiceH=0.7908 | DiceS=0.6002 | Empty=22.67%\n",
      "thr=0.32 | area= 60 | DiceH=0.7857 | DiceS=0.6221 | Empty=24.00%\n",
      "thr=0.34 | area= 20 | DiceH=0.8179 | DiceS=0.6271 | Empty=22.67%\n",
      "thr=0.34 | area= 30 | DiceH=0.7652 | DiceS=0.6275 | Empty=17.33%\n",
      "thr=0.34 | area= 40 | DiceH=0.7779 | DiceS=0.6393 | Empty=17.33%\n",
      "thr=0.34 | area= 60 | DiceH=0.7728 | DiceS=0.6482 | Empty=18.67%\n",
      "\n",
      "[BEST LB-STABLE CONFIG — SAFE]\n",
      "Threshold : 0.30\n",
      "Min area  : 20\n",
      "DiceHard : 0.8103\n",
      "DiceSoft : 0.6454\n",
      "Empty %  : 18.67%\n",
      "Mean comp: 2.16\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 4 — OPTIMIZATION, VALIDATION & REFINEMENT (UPGRADED)\n",
    "# LB-STABLE SELECTION\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# ===============================\n",
    "# Load BEST model (UNet++)\n",
    "# ===============================\n",
    "def load_unetpp():\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b4\",\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "    )\n",
    "    model.load_state_dict(torch.load(\"unetpp_best.pt\", map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_unetpp()\n",
    "print(\"[INFO] UNet++ best model loaded\")\n",
    "\n",
    "# ===============================\n",
    "# Dice metrics\n",
    "# ===============================\n",
    "@torch.no_grad()\n",
    "def dice_soft(probs, targets, eps=1e-7):\n",
    "    inter = (probs * targets).sum()\n",
    "    union = probs.sum() + targets.sum()\n",
    "    return (2 * inter + eps) / (union + eps)\n",
    "\n",
    "@torch.no_grad()\n",
    "def dice_hard(preds, targets, eps=1e-7):\n",
    "    inter = (preds * targets).sum()\n",
    "    union = preds.sum() + targets.sum()\n",
    "    return (2 * inter + eps) / (union + eps)\n",
    "\n",
    "# ===============================\n",
    "# Post-process (SAME AS STAGE 5)\n",
    "# ===============================\n",
    "def post_process(prob, thr, min_area):\n",
    "    mask = (prob > thr).astype(np.uint8)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, 8)\n",
    "    out = np.zeros_like(mask)\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            out[labels == i] = 1\n",
    "\n",
    "    return out\n",
    "\n",
    "# ===============================\n",
    "# Sweep space (FOCUSED)\n",
    "# ===============================\n",
    "thresholds = np.arange(0.24, 0.36, 0.02)\n",
    "min_areas  = [20, 30, 40, 60]\n",
    "\n",
    "records = []\n",
    "\n",
    "print(\"\\n[OPTIMIZATION] LB-stable sweep...\")\n",
    "\n",
    "val_dataset = PotholeDataset(\n",
    "    val_imgs_tr,\n",
    "    val_msks_tr,\n",
    "    transforms=val_tfms\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for thr in thresholds:\n",
    "    for min_area in min_areas:\n",
    "        dices_h = []\n",
    "        dices_s = []\n",
    "        empty_cnt = []\n",
    "        comp_counts = []\n",
    "\n",
    "        for img, mask in val_loader:\n",
    "            img = img.to(DEVICE)\n",
    "            gt = mask.numpy()[0]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prob = torch.sigmoid(model(img)).cpu().numpy()[0, 0]\n",
    "\n",
    "            pred = post_process(prob, thr, min_area)\n",
    "\n",
    "            dices_h.append(dice_hard(pred, gt).item())\n",
    "            dices_s.append(dice_soft(prob, gt).item())\n",
    "\n",
    "            empty_cnt.append(pred.sum() == 0)\n",
    "            comp_counts.append(\n",
    "                cv2.connectedComponents(pred.astype(np.uint8))[0] - 1\n",
    "            )\n",
    "\n",
    "        records.append({\n",
    "            \"thr\": thr,\n",
    "            \"min_area\": min_area,\n",
    "            \"dice_hard\": np.mean(dices_h),\n",
    "            \"dice_soft\": np.mean(dices_s),\n",
    "            \"empty_ratio\": np.mean(empty_cnt),\n",
    "            \"mean_components\": np.mean(comp_counts)\n",
    "        })\n",
    "\n",
    "        print(\n",
    "            f\"thr={thr:.2f} | area={min_area:3d} | \"\n",
    "            f\"DiceH={np.mean(dices_h):.4f} | \"\n",
    "            f\"DiceS={np.mean(dices_s):.4f} | \"\n",
    "            f\"Empty={np.mean(empty_cnt):.2%}\"\n",
    "        )\n",
    "\n",
    "# ===============================\n",
    "# SELECT LB-STABLE CONFIG (SAFE)\n",
    "# ===============================\n",
    "\n",
    "# convert to list of dicts (already is)\n",
    "assert len(records) > 0, \"No sweep records generated\"\n",
    "\n",
    "best_soft = max(r[\"dice_soft\"] for r in records)\n",
    "best_hard = max(r[\"dice_hard\"] for r in records)\n",
    "\n",
    "# ---------- Tier 1: ideal ----------\n",
    "candidates = [\n",
    "    r for r in records\n",
    "    if r[\"dice_soft\"] >= 0.97 * best_soft\n",
    "    and r[\"empty_ratio\"] < 0.15\n",
    "]\n",
    "\n",
    "# ---------- Tier 2: relax empty constraint ----------\n",
    "if len(candidates) == 0:\n",
    "    candidates = [\n",
    "        r for r in records\n",
    "        if r[\"dice_soft\"] >= 0.95 * best_soft\n",
    "        and r[\"empty_ratio\"] < 0.25\n",
    "    ]\n",
    "\n",
    "# ---------- Tier 3: fallback to hard dice ----------\n",
    "if len(candidates) == 0:\n",
    "    candidates = [\n",
    "        r for r in records\n",
    "        if r[\"dice_hard\"] >= 0.98 * best_hard\n",
    "    ]\n",
    "\n",
    "# ---------- Final safety ----------\n",
    "assert len(candidates) > 0, \"STAGE 4 FAILED: no valid threshold candidates\"\n",
    "\n",
    "def score_fn(r):\n",
    "    # prefer hard dice, penalize over-fragmentation\n",
    "    return (\n",
    "        r[\"dice_hard\"]\n",
    "        - 0.015 * abs(r[\"mean_components\"] - 2.5)\n",
    "        - 0.10 * r[\"empty_ratio\"]\n",
    "    )\n",
    "\n",
    "best_cfg = max(candidates, key=score_fn)\n",
    "\n",
    "OPT_CONFIG = {\n",
    "    \"thr\": float(best_cfg[\"thr\"]),\n",
    "    \"min_area\": int(best_cfg[\"min_area\"]),\n",
    "}\n",
    "\n",
    "print(\"\\n[BEST LB-STABLE CONFIG — SAFE]\")\n",
    "print(f\"Threshold : {best_cfg['thr']:.2f}\")\n",
    "print(f\"Min area  : {best_cfg['min_area']}\")\n",
    "print(f\"DiceHard : {best_cfg['dice_hard']:.4f}\")\n",
    "print(f\"DiceSoft : {best_cfg['dice_soft']:.4f}\")\n",
    "print(f\"Empty %  : {best_cfg['empty_ratio']:.2%}\")\n",
    "print(f\"Mean comp: {best_cfg['mean_components']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95707162",
   "metadata": {
    "papermill": {
     "duration": 0.473322,
     "end_time": "2026-02-06T20:43:46.428907",
     "exception": false,
     "start_time": "2026-02-06T20:43:45.955585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference, Encoding & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7f493d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T20:43:47.470153Z",
     "iopub.status.busy": "2026-02-06T20:43:47.469846Z",
     "iopub.status.idle": "2026-02-06T20:44:48.270714Z",
     "shell.execute_reply": "2026-02-06T20:44:48.269983Z"
    },
    "papermill": {
     "duration": 61.809826,
     "end_time": "2026-02-06T20:44:48.716972",
     "exception": false,
     "start_time": "2026-02-06T20:43:46.907146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONFIG]\n",
      "thr_unetpp : 0.26\n",
      "thr_deeplab: 0.32\n",
      "min_area  : 60\n",
      "[INFO] Models loaded\n",
      "[INFO] Test images: 295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Structural Ensemble Inference: 100%|██████████| 295/295 [00:59<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STAGE 5 COMPLETE — SUBMISSION READY]\n",
      "Saved to: /kaggle/working/submission.csv\n",
      "Rows: 295\n",
      "Empty RLE: 4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 5 — STRUCTURAL ENSEMBLE INFERENCE & SUBMISSION\n",
    "# FINAL SAFE VERSION (ANTI-NAMESPACE COLLISION)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as _pd   # <<< ALIAS AMAN\n",
    "import torch\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "TEST_IMG_DIR = DATA_ROOT / \"test\" / \"images\"\n",
    "OUT_SUB = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# FROM STAGE 4 (LB-STABLE)\n",
    "THR_U = 0.26\n",
    "THR_D = 0.32\n",
    "MIN_AREA = 60\n",
    "\n",
    "INPUT_SIZE = 512\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "print(\"[CONFIG]\")\n",
    "print(\"thr_unetpp :\", THR_U)\n",
    "print(\"thr_deeplab:\", THR_D)\n",
    "print(\"min_area  :\", MIN_AREA)\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD MODELS\n",
    "# -----------------------------\n",
    "unetpp = smp.UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "deeplab = smp.DeepLabV3Plus(\n",
    "    encoder_name=\"resnet101\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "unetpp.load_state_dict(\n",
    "    torch.load(\"/kaggle/working/unetpp_best.pt\", map_location=DEVICE)\n",
    ")\n",
    "deeplab.load_state_dict(\n",
    "    torch.load(\"/kaggle/working/deeplab_best.pt\", map_location=DEVICE)\n",
    ")\n",
    "\n",
    "unetpp.eval()\n",
    "deeplab.eval()\n",
    "\n",
    "print(\"[INFO] Models loaded\")\n",
    "\n",
    "# -----------------------------\n",
    "# RLE ENCODER (OFFICIAL)\n",
    "# -----------------------------\n",
    "def encode_rle(mask: np.ndarray) -> str:\n",
    "    binary = (mask == 1).astype(np.uint8)\n",
    "    pixels = binary.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[0::2]\n",
    "    return \" \".join(str(x) for x in runs)\n",
    "\n",
    "# -----------------------------\n",
    "# SMALL OBJECT FILTER\n",
    "# -----------------------------\n",
    "def remove_small_objects(mask, min_area):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n",
    "        mask.astype(np.uint8), connectivity=8\n",
    "    )\n",
    "    clean = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            clean[labels == i] = 1\n",
    "    return clean\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD TEST FILES\n",
    "# -----------------------------\n",
    "test_images = sorted(TEST_IMG_DIR.glob(\"*.jpg\"))\n",
    "print(\"[INFO] Test images:\", len(test_images))\n",
    "assert len(test_images) == 295, \"TEST IMAGE COUNT HARUS 295\"\n",
    "\n",
    "# -----------------------------\n",
    "# INFERENCE + H-FLIP TTA\n",
    "# -----------------------------\n",
    "records = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_path in tqdm(test_images, desc=\"Structural Ensemble Inference\"):\n",
    "        img_name = img_path.name\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h0, w0 = img.shape[:2]\n",
    "\n",
    "        img_r = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE)).astype(np.float32) / 255.0\n",
    "        for c in range(3):\n",
    "            img_r[..., c] = (img_r[..., c] - IMAGENET_MEAN[c]) / IMAGENET_STD[c]\n",
    "\n",
    "        x = torch.from_numpy(img_r.transpose(2, 0, 1)).unsqueeze(0).to(DEVICE)\n",
    "        x_flip = torch.flip(x, dims=[3])\n",
    "\n",
    "        pu = torch.sigmoid(unetpp(x))\n",
    "        pd = torch.sigmoid(deeplab(x))\n",
    "\n",
    "        pu_f = torch.flip(torch.sigmoid(unetpp(x_flip)), dims=[3])\n",
    "        pd_f = torch.flip(torch.sigmoid(deeplab(x_flip)), dims=[3])\n",
    "\n",
    "        pu = ((pu + pu_f) / 2.0)[0, 0].cpu().numpy()\n",
    "        pd = ((pd + pd_f) / 2.0)[0, 0].cpu().numpy()\n",
    "\n",
    "        mask_u = (pu > THR_U).astype(np.uint8)\n",
    "\n",
    "        if mask_u.sum() == 0:\n",
    "            pred = np.zeros((h0, w0), dtype=np.uint8)\n",
    "        else:\n",
    "            mask_d = (pd > THR_D).astype(np.uint8)\n",
    "            mask_d = remove_small_objects(mask_d, MIN_AREA)\n",
    "\n",
    "            if mask_d.sum() == 0:\n",
    "                pred = cv2.resize(mask_u, (w0, h0), interpolation=cv2.INTER_NEAREST)\n",
    "            else:\n",
    "                mask_d = cv2.dilate(mask_d, np.ones((3, 3), np.uint8))\n",
    "                pred = mask_u & mask_d\n",
    "                pred = cv2.resize(pred, (w0, h0), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        rle = \"\" if pred.sum() == 0 else encode_rle(pred)\n",
    "\n",
    "        records.append({\n",
    "            \"ImageId\": img_name,\n",
    "            \"rle\": rle\n",
    "        })\n",
    "\n",
    "# -----------------------------\n",
    "# SAVE SUBMISSION (SAFE)\n",
    "# -----------------------------\n",
    "df_sub = _pd.DataFrame(records, columns=[\"ImageId\", \"rle\"])\n",
    "df_sub.to_csv(OUT_SUB, index=False)\n",
    "\n",
    "print(\"\\n[STAGE 5 COMPLETE — SUBMISSION READY]\")\n",
    "print(\"Saved to:\", OUT_SUB)\n",
    "print(\"Rows:\", len(df_sub))\n",
    "print(\"Empty RLE:\", (df_sub[\"rle\"] == \"\").sum())\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15445689,
     "sourceId": 128328,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2272.387838,
   "end_time": "2026-02-06T20:44:52.350446",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-06T20:06:59.962608",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
