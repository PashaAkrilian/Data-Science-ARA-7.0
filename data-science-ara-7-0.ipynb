{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":128328,"databundleVersionId":15445689,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Understanding & Preparation","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 1 â€” Data Understanding & Preparation (FINAL FIX)\n# Data Science ARA 7.0 â€” Pothole Segmentation\n# Compatible with index-based filenames:\n#   train_XXX.jpg <-> mask_XXX.png\n# ============================================================\n\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nfrom skimage.measure import label, regionprops\n\n# -------------------------------\n# Paths (Kaggle)\n# -------------------------------\nROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n\nTRAIN_IMG_DIR = ROOT / \"train\" / \"images\"\nTRAIN_MSK_DIR = ROOT / \"train\" / \"mask\"\nTEST_IMG_DIR  = ROOT / \"test\"  / \"images\"\n\nassert TRAIN_IMG_DIR.exists()\nassert TRAIN_MSK_DIR.exists()\nassert TEST_IMG_DIR.exists()\n\n# -------------------------------\n# Load file lists\n# -------------------------------\ntrain_imgs = sorted(TRAIN_IMG_DIR.glob(\"train_*.jpg\"))\ntrain_msks = sorted(TRAIN_MSK_DIR.glob(\"mask_*.png\"))\ntest_imgs  = sorted(TEST_IMG_DIR.glob(\"test_*.jpg\"))\n\nprint(f\"[INFO] Train images : {len(train_imgs)}\")\nprint(f\"[INFO] Train masks  : {len(train_msks)}\")\nprint(f\"[INFO] Test images  : {len(test_imgs)}\")\n\nassert len(train_imgs) == len(train_msks), \"Mismatch train image & mask count\"\n\n# -------------------------------\n# Pairing by index\n# -------------------------------\npairs = list(zip(train_imgs, train_msks))\nprint(f\"[INFO] Valid image-mask pairs: {len(pairs)}\")\n\n# -------------------------------\n# Profiling\n# -------------------------------\nimage_records = []\ncomponent_records = []\n\nfor img_path, msk_path in tqdm(pairs, desc=\"Analyzing dataset\"):\n    mask = cv2.imread(str(msk_path), cv2.IMREAD_GRAYSCALE)\n    h, w = mask.shape\n    total_pixels = h * w\n\n    bin_mask = (mask > 0).astype(np.uint8)\n    pos_pixels = bin_mask.sum()\n    area_ratio = pos_pixels / total_pixels\n\n    lbl = label(bin_mask)\n    regions = regionprops(lbl)\n\n    num_components = len(regions)\n    comp_areas = [r.area for r in regions]\n\n    max_comp_ratio = max(comp_areas) / total_pixels if comp_areas else 0\n\n    image_records.append({\n        \"image_id\": img_path.name,\n        \"area_ratio\": area_ratio,\n        \"num_components\": num_components,\n        \"max_component_ratio\": max_comp_ratio\n    })\n\n    for r in regions:\n        component_records.append({\n            \"image_id\": img_path.name,\n            \"component_area\": r.area,\n            \"component_ratio\": r.area / total_pixels\n        })\n\ndf_img = pd.DataFrame(image_records)\ndf_comp = pd.DataFrame(component_records)\n\n# -------------------------------\n# INSIGHTS\n# -------------------------------\nprint(\"\\n[INSIGHT] Pothole presence distribution:\")\nprint((df_img[\"area_ratio\"] > 0).value_counts())\n\nempty_ratio = (df_img[\"area_ratio\"] == 0).mean()\nprint(f\"\\n[INSIGHT] Empty-mask ratio: {empty_ratio:.2%}\")\n\nprint(\"\\n[INSIGHT] Pothole area ratio (% of image):\")\nprint(df_img[\"area_ratio\"].describe())\n\nprint(\"\\n[INSIGHT] Number of components per image:\")\nprint(df_img[\"num_components\"].describe())\n\nprint(\"\\n[INSIGHT] Dominant component ratio:\")\nprint(df_img[\"max_component_ratio\"].describe())\n\nprint(\"\\n[INSIGHT] Connected component area (pixels):\")\nprint(df_comp[\"component_area\"].describe())\n\n# -------------------------------\n# Leaderboard-oriented priors\n# -------------------------------\nmin_area_prior = int(df_comp[\"component_area\"].quantile(0.10))\nprint(f\"\\n[RECOMMENDATION] Candidate MIN_AREA (remove FP): ~{min_area_prior} pixels\")\n\nsmall_obj_ratio = (df_img[\"area_ratio\"] < 0.01).mean()\nprint(\"\\n[FEASIBILITY CHECK]\")\nprint(f\"Images with pothole <1% area: {small_obj_ratio:.2%}\")\n\nif small_obj_ratio < 0.20:\n    print(\"[FEASIBILITY STATUS] FAVORABLE (0.80+ achievable)\")\nelse:\n    print(\"[FEASIBILITY STATUS] HARD (small-object dominant)\")\n\nprint(\"\\n[THRESHOLD PRIOR]\")\nprint(\"â†’ Start sweep in range: 0.30 â€“ 0.45 (Dice-friendly)\")\n\nprint(\"\\n[INFO] Final training samples:\", len(df_img))\n\nprint(\"\\n[STAGE 1 COMPLETE â€” LEADERBOARD READY]\")\nprint(\"âœ“ Dataset validated\")\nprint(\"âœ“ Dice risk quantified\")\nprint(\"âœ“ Min-area & threshold priors extracted\")\nprint(\"âœ“ Ready for STAGE 2 (augmentation design)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T03:14:32.019381Z","iopub.execute_input":"2026-02-06T03:14:32.019996Z","iopub.status.idle":"2026-02-06T03:15:03.633770Z","shell.execute_reply.started":"2026-02-06T03:14:32.019964Z","shell.execute_reply":"2026-02-06T03:15:03.632952Z"}},"outputs":[{"name":"stdout","text":"[INFO] Train images : 498\n[INFO] Train masks  : 498\n[INFO] Test images  : 295\n[INFO] Valid image-mask pairs: 498\n","output_type":"stream"},{"name":"stderr","text":"Analyzing dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498/498 [00:30<00:00, 16.46it/s]","output_type":"stream"},{"name":"stdout","text":"\n[INSIGHT] Pothole presence distribution:\narea_ratio\nTrue    498\nName: count, dtype: int64\n\n[INSIGHT] Empty-mask ratio: 0.00%\n\n[INSIGHT] Pothole area ratio (% of image):\ncount    498.000000\nmean       0.134860\nstd        0.128772\nmin        0.000235\n25%        0.040943\n50%        0.091678\n75%        0.193834\nmax        0.674005\nName: area_ratio, dtype: float64\n\n[INSIGHT] Number of components per image:\ncount    498.000000\nmean       4.261044\nstd        6.239045\nmin        1.000000\n25%        1.000000\n50%        2.000000\n75%        5.000000\nmax       67.000000\nName: num_components, dtype: float64\n\n[INSIGHT] Dominant component ratio:\ncount    498.000000\nmean       0.112599\nstd        0.119287\nmin        0.000235\n25%        0.030156\n50%        0.066428\n75%        0.162189\nmax        0.636689\nName: max_component_ratio, dtype: float64\n\n[INSIGHT] Connected component area (pixels):\ncount    2.122000e+03\nmean     5.588544e+04\nstd      3.030841e+05\nmin      1.000000e+00\n25%      3.930000e+02\n50%      1.913000e+03\n75%      1.203275e+04\nmax      6.700584e+06\nName: component_area, dtype: float64\n\n[RECOMMENDATION] Candidate MIN_AREA (remove FP): ~130 pixels\n\n[FEASIBILITY CHECK]\nImages with pothole <1% area: 11.85%\n[FEASIBILITY STATUS] FAVORABLE (0.80+ achievable)\n\n[THRESHOLD PRIOR]\nâ†’ Start sweep in range: 0.30 â€“ 0.45 (Dice-friendly)\n\n[INFO] Final training samples: 498\n\n[STAGE 1 COMPLETE â€” LEADERBOARD READY]\nâœ“ Dataset validated\nâœ“ Dice risk quantified\nâœ“ Min-area & threshold priors extracted\nâœ“ Ready for STAGE 2 (augmentation design)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Preprocessing & Data Augmentation","metadata":{}},{"cell_type":"code","source":"# ===============================\n# Imports\n# ===============================\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\nimport numpy as np\n\n# ===============================\n# Global Config\n# ===============================\nIMG_SIZE = 512\nPOS_VALUE = 255  # mask positive value\n\n# ===============================\n# Mask Sanity Function\n# ===============================\ndef sanitize_mask(mask: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Ensure binary mask {0, POS_VALUE}\n    Dice-safe (no interpolation artifacts)\n    \"\"\"\n    return (mask > 0).astype(np.uint8) * POS_VALUE\n\n# ===============================\n# Train Augmentation (FINAL)\n# ===============================\ntrain_tfms = A.Compose(\n    [\n        # --- geometry (SAFE) ---\n        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_LINEAR),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.2),\n\n        # --- illumination ---\n        A.RandomBrightnessContrast(\n            brightness_limit=0.15,\n            contrast_limit=0.15,\n            p=0.5\n        ),\n        A.RandomGamma(\n            gamma_limit=(80, 120),\n            p=0.3\n        ),\n\n        # --- noise & blur (FIXED) ---\n        A.GaussianBlur(\n            blur_limit=(3, 5),\n            p=0.2\n        ),\n        A.GaussNoise(\n            p=0.2   # âœ… NO invalid arguments\n        ),\n\n        # --- normalize ---\n        A.Normalize(\n            mean=(0.485, 0.456, 0.406),\n            std=(0.229, 0.224, 0.225),\n        ),\n\n        ToTensorV2(),\n    ]\n)\n\n# ===============================\n# Validation / Test Augmentation\n# ===============================\nval_tfms = A.Compose(\n    [\n        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=cv2.INTER_LINEAR),\n        A.Normalize(\n            mean=(0.485, 0.456, 0.406),\n            std=(0.229, 0.224, 0.225),\n        ),\n        ToTensorV2(),\n    ]\n)\n\n# ===============================\n# Dataset Class (Segmentation)\n# ===============================\nclass PotholeDataset:\n    def __init__(self, image_paths, mask_paths=None, transforms=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(str(self.image_paths[idx]))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        if self.mask_paths is not None:\n            mask = cv2.imread(str(self.mask_paths[idx]), cv2.IMREAD_GRAYSCALE)\n            mask = sanitize_mask(mask)\n\n            augmented = self.transforms(image=img, mask=mask)\n            img = augmented[\"image\"]\n            mask = augmented[\"mask\"] / POS_VALUE  # {0,1}\n\n            return img, mask.float()\n        else:\n            augmented = self.transforms(image=img)\n            return augmented[\"image\"]\n\n# ===============================\n# Sanity Check\n# ===============================\nif __name__ == \"__main__\":\n    print(\"[STAGE 2 CHECK â€” FINAL]\")\n    dummy_img = np.zeros((720, 1280, 3), dtype=np.uint8)\n    dummy_mask = np.zeros((720, 1280), dtype=np.uint8)\n\n    train_tfms(image=dummy_img, mask=dummy_mask)\n    print(\"âœ“ Train transform OK (no warnings)\")\n\n    val_tfms(image=dummy_img)\n    print(\"âœ“ Val/Test transform OK\")\n\n    print(\"[STAGE 2 FINAL â€” READY FOR TRAINING]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T03:15:03.635333Z","iopub.execute_input":"2026-02-06T03:15:03.635831Z","iopub.status.idle":"2026-02-06T03:15:09.226946Z","shell.execute_reply.started":"2026-02-06T03:15:03.635784Z","shell.execute_reply":"2026-02-06T03:15:09.226228Z"}},"outputs":[{"name":"stdout","text":"[STAGE 2 CHECK â€” FINAL]\nâœ“ Train transform OK (no warnings)\nâœ“ Val/Test transform OK\n[STAGE 2 FINAL â€” READY FOR TRAINING]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Model Construction & Training","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch==0.3.3 timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T03:15:09.228033Z","iopub.execute_input":"2026-02-06T03:15:09.228439Z","iopub.status.idle":"2026-02-06T03:15:20.667641Z","shell.execute_reply.started":"2026-02-06T03:15:09.228414Z","shell.execute_reply":"2026-02-06T03:15:20.666773Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# STAGE 3 â€” Model Construction & Training (tqdm version)\n# ============================================================\n\n# ===============================\n# Imports\n# ===============================\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nimport segmentation_models_pytorch as smp\n\n# ===============================\n# Config\n# ===============================\nSEED = 42\nBATCH_SIZE = 4\nEPOCHS = 25\nLR = 2e-4\nWEIGHT_DECAY = 1e-2\nVAL_RATIO = 0.15\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# ===============================\n# Seed\n# ===============================\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# ===============================\n# Train / Val Split\n# ===============================\nidx_all = np.arange(len(train_imgs))\nidx_tr, idx_val = train_test_split(\n    idx_all,\n    test_size=VAL_RATIO,\n    random_state=SEED,\n    shuffle=True\n)\n\ntrain_imgs_tr = [train_imgs[i] for i in idx_tr]\ntrain_msks_tr = [train_msks[i] for i in idx_tr]\nval_imgs_tr   = [train_imgs[i] for i in idx_val]\nval_msks_tr   = [train_msks[i] for i in idx_val]\n\nprint(f\"[INFO] Train: {len(train_imgs_tr)} | Val: {len(val_imgs_tr)}\")\n\n# ===============================\n# Datasets\n# ===============================\ntrain_dataset = PotholeDataset(\n    train_imgs_tr,\n    train_msks_tr,\n    transforms=train_tfms\n)\n\nval_dataset = PotholeDataset(\n    val_imgs_tr,\n    val_msks_tr,\n    transforms=val_tfms\n)\n\n# ===============================\n# DataLoaders\n# ===============================\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=2,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\n# ===============================\n# Loss\n# ===============================\ndice_loss = smp.losses.DiceLoss(mode=\"binary\", from_logits=True)\nbce_loss  = nn.BCEWithLogitsLoss()\n\ndef criterion(logits, targets):\n    return dice_loss(logits, targets) + 0.5 * bce_loss(logits, targets)\n\n# ===============================\n# Dice Metric\n# ===============================\n@torch.no_grad()\ndef dice_coeff(probs, targets, eps=1e-7):\n    probs = (probs > 0.5).float()\n    targets = targets.float()\n    inter = (probs * targets).sum()\n    union = probs.sum() + targets.sum()\n    return (2 * inter + eps) / (union + eps)\n\n# ===============================\n# Models\n# ===============================\ndef build_unetpp():\n    return smp.UnetPlusPlus(\n        encoder_name=\"efficientnet-b4\",\n        encoder_weights=\"imagenet\",\n        in_channels=3,\n        classes=1,\n    )\n\ndef build_deeplab():\n    return smp.DeepLabV3Plus(\n        encoder_name=\"resnet101\",\n        encoder_weights=\"imagenet\",\n        in_channels=3,\n        classes=1,\n    )\n\n# ===============================\n# Train / Val loops (WITH TQDM)\n# ===============================\ndef train_one_epoch(model, loader, optimizer, epoch, name):\n    model.train()\n    total_loss = 0.0\n\n    pbar = tqdm(\n        loader,\n        desc=f\"{name} | Epoch {epoch}\",\n        leave=False\n    )\n\n    for imgs, masks in pbar:\n        imgs = imgs.to(DEVICE)\n        masks = masks.to(DEVICE).unsqueeze(1)\n\n        optimizer.zero_grad()\n        logits = model(imgs)\n        loss = criterion(logits, masks)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n\n    return total_loss / len(loader)\n\n@torch.no_grad()\ndef validate(model, loader):\n    model.eval()\n    dices = []\n\n    for imgs, masks in loader:\n        imgs = imgs.to(DEVICE)\n        masks = masks.to(DEVICE).unsqueeze(1)\n\n        logits = model(imgs)\n        probs = torch.sigmoid(logits)\n        dices.append(dice_coeff(probs, masks).item())\n\n    return float(np.mean(dices))\n\n# ===============================\n# Training wrapper\n# ===============================\ndef train_model(name, model):\n    model = model.to(DEVICE)\n\n    optimizer = AdamW(\n        model.parameters(),\n        lr=LR,\n        weight_decay=WEIGHT_DECAY\n    )\n\n    scheduler = CosineAnnealingLR(\n        optimizer,\n        T_max=EPOCHS\n    )\n\n    best_dice = 0.0\n    ckpt_path = f\"{name}_best.pt\"\n\n    for epoch in range(1, EPOCHS + 1):\n        tr_loss = train_one_epoch(model, train_loader, optimizer, epoch, name)\n        val_dice = validate(model, val_loader)\n        scheduler.step()\n\n        print(\n            f\"{name} | Epoch {epoch:02d} | \"\n            f\"TrainLoss {tr_loss:.4f} | ValDice {val_dice:.4f}\"\n        )\n\n        if val_dice > best_dice:\n            best_dice = val_dice\n            torch.save(model.state_dict(), ckpt_path)\n            print(f\">> Best {name} saved\")\n\n    print(f\"[DONE] {name} best Val Dice: {best_dice:.4f}\")\n    return ckpt_path, best_dice\n\n# ===============================\n# RUN\n# ===============================\nprint(\"\\n===== TRAINING UNET++ =====\")\nunetpp_model = build_unetpp()\nunetpp_ckpt, unetpp_dice = train_model(\"unetpp\", unetpp_model)\n\nprint(\"\\n===== TRAINING DEEPLAB =====\")\ndeeplab_model = build_deeplab()\ndeeplab_ckpt, deeplab_dice = train_model(\"deeplab\", deeplab_model)\n\nprint(\"\\n[STAGE 3 COMPLETE]\")\nprint(f\"UNet++  best Dice: {unetpp_dice:.4f}\")\nprint(f\"DeepLab best Dice: {deeplab_dice:.4f}\")\nprint(\"â†’ Ready for STAGE 4\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T03:15:20.669952Z","iopub.execute_input":"2026-02-06T03:15:20.670201Z","iopub.status.idle":"2026-02-06T04:13:33.484169Z","shell.execute_reply.started":"2026-02-06T03:15:20.670173Z","shell.execute_reply":"2026-02-06T04:13:33.483379Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Device: cuda\n[INFO] Train: 423 | Val: 75\n\n===== TRAINING UNET++ =====\nDownloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74.4M/74.4M [00:00<00:00, 79.4MB/s]\n                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 01 | TrainLoss 0.8767 | ValDice 0.7518\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 02 | TrainLoss 0.5676 | ValDice 0.7739\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 03 | TrainLoss 0.4537 | ValDice 0.7959\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 04 | TrainLoss 0.4096 | ValDice 0.7876\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 05 | TrainLoss 0.3673 | ValDice 0.7924\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 06 | TrainLoss 0.3487 | ValDice 0.8076\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 07 | TrainLoss 0.3372 | ValDice 0.8016\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 08 | TrainLoss 0.3122 | ValDice 0.8183\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 09 | TrainLoss 0.2784 | ValDice 0.8055\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 10 | TrainLoss 0.2749 | ValDice 0.8118\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 11 | TrainLoss 0.2498 | ValDice 0.8246\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 12 | TrainLoss 0.2471 | ValDice 0.8067\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 13 | TrainLoss 0.2385 | ValDice 0.8246\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 14 | TrainLoss 0.2271 | ValDice 0.8279\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 15 | TrainLoss 0.2228 | ValDice 0.8255\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 16 | TrainLoss 0.2068 | ValDice 0.8270\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 17 | TrainLoss 0.2149 | ValDice 0.8302\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 18 | TrainLoss 0.1990 | ValDice 0.8272\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 19 | TrainLoss 0.1935 | ValDice 0.8225\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 20 | TrainLoss 0.1977 | ValDice 0.8273\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 21 | TrainLoss 0.1775 | ValDice 0.8268\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 22 | TrainLoss 0.1875 | ValDice 0.8285\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 23 | TrainLoss 0.1836 | ValDice 0.8271\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 24 | TrainLoss 0.1758 | ValDice 0.8288\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 25 | TrainLoss 0.1731 | ValDice 0.8280\n[DONE] unetpp best Val Dice: 0.8302\n\n===== TRAINING DEEPLAB =====\nDownloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:00<00:00, 315MB/s] \n                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 01 | TrainLoss 0.8111 | ValDice 0.7229\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 02 | TrainLoss 0.6238 | ValDice 0.7414\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 03 | TrainLoss 0.5546 | ValDice 0.7076\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 04 | TrainLoss 0.5302 | ValDice 0.7506\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 05 | TrainLoss 0.4937 | ValDice 0.7206\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 06 | TrainLoss 0.4759 | ValDice 0.7237\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 07 | TrainLoss 0.4796 | ValDice 0.7606\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 08 | TrainLoss 0.4417 | ValDice 0.7726\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 09 | TrainLoss 0.4253 | ValDice 0.7765\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 10 | TrainLoss 0.4094 | ValDice 0.7522\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 11 | TrainLoss 0.3796 | ValDice 0.7749\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 12 | TrainLoss 0.3650 | ValDice 0.7684\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 13 | TrainLoss 0.3522 | ValDice 0.7815\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 14 | TrainLoss 0.3171 | ValDice 0.7844\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 15 | TrainLoss 0.3316 | ValDice 0.7895\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 16 | TrainLoss 0.3085 | ValDice 0.7727\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 17 | TrainLoss 0.2832 | ValDice 0.7948\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 18 | TrainLoss 0.2654 | ValDice 0.8135\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 19 | TrainLoss 0.2633 | ValDice 0.7900\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 20 | TrainLoss 0.2538 | ValDice 0.8062\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 21 | TrainLoss 0.2359 | ValDice 0.8063\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 22 | TrainLoss 0.2298 | ValDice 0.8035\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 23 | TrainLoss 0.2337 | ValDice 0.8093\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 24 | TrainLoss 0.2279 | ValDice 0.8037\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 25 | TrainLoss 0.2333 | ValDice 0.8087\n[DONE] deeplab best Val Dice: 0.8135\n\n[STAGE 3 COMPLETE]\nUNet++  best Dice: 0.8302\nDeepLab best Dice: 0.8135\nâ†’ Ready for STAGE 4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Optimization, Validation & Refinement","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 4 â€” OPTIMIZATION, VALIDATION & REFINEMENT (REVISED)\n# ============================================================\n\nimport numpy as np\nfrom tqdm import tqdm\nimport cv2\nimport torch\nimport segmentation_models_pytorch as smp\n\n# ===============================\n# Load BEST model (UNet++)\n# ===============================\ndef load_unetpp():\n    model = smp.UnetPlusPlus(\n        encoder_name=\"efficientnet-b4\",\n        encoder_weights=None,\n        in_channels=3,\n        classes=1,\n    )\n    model.load_state_dict(torch.load(\"unetpp_best.pt\", map_location=DEVICE))\n    model.to(DEVICE)\n    model.eval()\n    return model\n\nmodel = load_unetpp()\nprint(\"[INFO] UNet++ best model loaded\")\n\n# ===============================\n# Dice metric\n# ===============================\n@torch.no_grad()\ndef dice_coeff(preds, targets, eps=1e-7):\n    inter = (preds * targets).sum()\n    union = preds.sum() + targets.sum()\n    return (2 * inter + eps) / (union + eps)\n\n# ===============================\n# Post-process (RECALL FRIENDLY)\n# ===============================\ndef post_process(prob, thr, min_area):\n    mask = (prob > thr).astype(np.uint8)\n\n    # morphology closing ringan (same as STAGE 5)\n    kernel = np.ones((3, 3), np.uint8)\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, 8)\n    out = np.zeros_like(mask)\n\n    for i in range(1, num_labels):\n        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n            out[labels == i] = 1\n\n    return out\n\n# ===============================\n# Validation sweep (LB-aware)\n# ===============================\nthresholds = np.arange(0.26, 0.38, 0.02)   # ðŸ”½ lebih rendah\nmin_areas  = [20, 30, 40, 60, 80]          # ðŸ”½ lebih kecil\n\nrecords = []\n\nprint(\"\\n[OPTIMIZATION] LB-aware sweep...\")\n\nval_dataset = PotholeDataset(\n    val_imgs_tr,\n    val_msks_tr,\n    transforms=val_tfms\n)\n\nval_loader = torch.utils.data.DataLoader(\n    val_dataset,\n    batch_size=1,\n    shuffle=False\n)\n\nfor thr in thresholds:\n    for min_area in min_areas:\n        dices = []\n        empty_cnt = 0\n        comp_counts = []\n\n        for img, mask in val_loader:\n            img = img.to(DEVICE)\n            gt = mask.numpy()[0]\n\n            with torch.no_grad():\n                prob = torch.sigmoid(model(img)).cpu().numpy()[0, 0]\n\n            pred = post_process(prob, thr, min_area)\n\n            if pred.sum() == 0:\n                empty_cnt += 1\n\n            # count components\n            n_comp = cv2.connectedComponents(pred.astype(np.uint8))[0] - 1\n            comp_counts.append(n_comp)\n\n            dices.append(dice_coeff(pred, gt).item())\n\n        records.append({\n            \"thr\": thr,\n            \"min_area\": min_area,\n            \"dice\": np.mean(dices),\n            \"empty_ratio\": empty_cnt / len(val_loader),\n            \"mean_components\": np.mean(comp_counts)\n        })\n\n        print(\n            f\"thr={thr:.2f} | area={min_area:3d} | \"\n            f\"Dice={np.mean(dices):.4f} | \"\n            f\"Empty={empty_cnt/len(val_loader):.2%}\"\n        )\n\n# ===============================\n# Select BEST LB-friendly config\n# ===============================\ndf = np.array(records)\n\n# rule:\n# - Dice >= 95% of best\n# - Empty ratio < 20%\nbest_dice = max(r[\"dice\"] for r in records)\n\ncandidates = [\n    r for r in records\n    if r[\"dice\"] >= 0.95 * best_dice and r[\"empty_ratio\"] < 0.20\n]\n\nbest_cfg = max(candidates, key=lambda r: r[\"dice\"])\n\nprint(\"\\n[BEST LB-FRIENDLY CONFIG]\")\nprint(f\"Threshold : {best_cfg['thr']:.2f}\")\nprint(f\"Min area  : {best_cfg['min_area']}\")\nprint(f\"Val Dice  : {best_cfg['dice']:.4f}\")\nprint(f\"Empty %   : {best_cfg['empty_ratio']:.2%}\")\nprint(f\"Mean comps: {best_cfg['mean_components']:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T05:01:06.137150Z","iopub.execute_input":"2026-02-06T05:01:06.137489Z","iopub.status.idle":"2026-02-06T05:04:35.542145Z","shell.execute_reply.started":"2026-02-06T05:01:06.137462Z","shell.execute_reply":"2026-02-06T05:04:35.541424Z"}},"outputs":[{"name":"stdout","text":"[INFO] UNet++ best model loaded\n\n[OPTIMIZATION] LB-aware sweep...\nthr=0.26 | area= 20 | Dice=0.7581 | Empty=4.00%\nthr=0.26 | area= 30 | Dice=0.7581 | Empty=4.00%\nthr=0.26 | area= 40 | Dice=0.7581 | Empty=4.00%\nthr=0.26 | area= 60 | Dice=0.7582 | Empty=4.00%\nthr=0.26 | area= 80 | Dice=0.7508 | Empty=6.67%\nthr=0.28 | area= 20 | Dice=0.7581 | Empty=4.00%\nthr=0.28 | area= 30 | Dice=0.7581 | Empty=4.00%\nthr=0.28 | area= 40 | Dice=0.7582 | Empty=4.00%\nthr=0.28 | area= 60 | Dice=0.7582 | Empty=4.00%\nthr=0.28 | area= 80 | Dice=0.7511 | Empty=6.67%\nthr=0.30 | area= 20 | Dice=0.7576 | Empty=4.00%\nthr=0.30 | area= 30 | Dice=0.7576 | Empty=4.00%\nthr=0.30 | area= 40 | Dice=0.7576 | Empty=4.00%\nthr=0.30 | area= 60 | Dice=0.7509 | Empty=6.67%\nthr=0.30 | area= 80 | Dice=0.7510 | Empty=6.67%\nthr=0.32 | area= 20 | Dice=0.7573 | Empty=4.00%\nthr=0.32 | area= 30 | Dice=0.7573 | Empty=4.00%\nthr=0.32 | area= 40 | Dice=0.7573 | Empty=4.00%\nthr=0.32 | area= 60 | Dice=0.7509 | Empty=6.67%\nthr=0.32 | area= 80 | Dice=0.7509 | Empty=6.67%\nthr=0.34 | area= 20 | Dice=0.7570 | Empty=4.00%\nthr=0.34 | area= 30 | Dice=0.7570 | Empty=4.00%\nthr=0.34 | area= 40 | Dice=0.7570 | Empty=4.00%\nthr=0.34 | area= 60 | Dice=0.7509 | Empty=6.67%\nthr=0.34 | area= 80 | Dice=0.7430 | Empty=8.00%\nthr=0.36 | area= 20 | Dice=0.7563 | Empty=4.00%\nthr=0.36 | area= 30 | Dice=0.7563 | Empty=4.00%\nthr=0.36 | area= 40 | Dice=0.7563 | Empty=4.00%\nthr=0.36 | area= 60 | Dice=0.7509 | Empty=6.67%\nthr=0.36 | area= 80 | Dice=0.7429 | Empty=8.00%\n\n[BEST LB-FRIENDLY CONFIG]\nThreshold : 0.26\nMin area  : 60\nVal Dice  : 0.7582\nEmpty %   : 4.00%\nMean comps: 2.89\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Inference, Encoding & Submission","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 5 â€” STRUCTURAL ENSEMBLE INFERENCE & SUBMISSION\n# FINAL â€” ANTI pandas COLLISION\n# ============================================================\n\nimport numpy as np\nimport pandas as pandas\nimport torch\nimport cv2\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport segmentation_models_pytorch as smp\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nTEST_IMG_DIR = DATA_ROOT / \"test\" / \"images\"\nOUT_SUB = \"/kaggle/working/submission.csv\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# === FROM STAGE 4 ===\nTHR_U = 0.26\nTHR_D = 0.32\nMIN_AREA = 60\n\nINPUT_SIZE = 512\n\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD  = (0.229, 0.224, 0.225)\n\nprint(\"[CONFIG]\")\nprint(\"thr_unetpp :\", THR_U)\nprint(\"thr_deeplab:\", THR_D)\nprint(\"min_area  :\", MIN_AREA)\n\n# -----------------------------\n# LOAD MODELS\n# -----------------------------\nunetpp = smp.UnetPlusPlus(\n    encoder_name=\"efficientnet-b4\",\n    encoder_weights=None,\n    in_channels=3,\n    classes=1,\n).to(DEVICE)\n\ndeeplab = smp.DeepLabV3Plus(\n    encoder_name=\"resnet101\",\n    encoder_weights=None,\n    in_channels=3,\n    classes=1,\n).to(DEVICE)\n\nunetpp.load_state_dict(torch.load(\"/kaggle/working/unetpp_best.pt\", map_location=DEVICE))\ndeeplab.load_state_dict(torch.load(\"/kaggle/working/deeplab_best.pt\", map_location=DEVICE))\n\nunetpp.eval()\ndeeplab.eval()\n\nprint(\"[INFO] Models loaded\")\n\n# -----------------------------\n# RLE ENCODER (OFFICIAL)\n# -----------------------------\ndef encode_rle(mask: np.ndarray) -> str:\n    binary = (mask == 1).astype(np.uint8)\n    pixels = binary.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[0::2]\n    return \" \".join(str(x) for x in runs)\n\n# -----------------------------\n# POSTPROCESS\n# -----------------------------\ndef remove_small_objects(mask, min_area):\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n        mask.astype(np.uint8), connectivity=8\n    )\n    clean = np.zeros_like(mask, dtype=np.uint8)\n    for i in range(1, num_labels):\n        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n            clean[labels == i] = 1\n    return clean\n\n# -----------------------------\n# LOAD TEST FILES\n# -----------------------------\ntest_images = sorted(TEST_IMG_DIR.glob(\"*.jpg\"))\nprint(\"[INFO] Test images:\", len(test_images))\nassert len(test_images) == 295, \"TEST IMAGE COUNT BUKAN 295\"\n\n# -----------------------------\n# INFERENCE + H-FLIP TTA\n# -----------------------------\nrecords = []\n\nwith torch.no_grad():\n    for img_path in tqdm(test_images, desc=\"Structural Ensemble Inference\"):\n        img_name = img_path.name\n\n        img = cv2.imread(str(img_path))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        h0, w0 = img.shape[:2]\n\n        img_r = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE)).astype(\"float32\") / 255.0\n        for c in range(3):\n            img_r[..., c] = (img_r[..., c] - IMAGENET_MEAN[c]) / IMAGENET_STD[c]\n\n        x = torch.from_numpy(img_r.transpose(2,0,1)).unsqueeze(0).to(DEVICE)\n        x_flip = torch.flip(x, dims=[3])\n\n        pu = torch.sigmoid(unetpp(x))\n        pd = torch.sigmoid(deeplab(x))\n\n        pu_f = torch.flip(torch.sigmoid(unetpp(x_flip)), dims=[3])\n        pd_f = torch.flip(torch.sigmoid(deeplab(x_flip)), dims=[3])\n\n        pu = ((pu + pu_f) / 2.0)[0, 0].cpu().numpy()\n        pd = ((pd + pd_f) / 2.0)[0, 0].cpu().numpy()\n\n        mask_u = (pu > THR_U).astype(np.uint8)\n\n        if mask_u.sum() == 0:\n            pred = np.zeros((h0, w0), dtype=np.uint8)\n        else:\n            mask_d = (pd > THR_D).astype(np.uint8)\n            mask_d = remove_small_objects(mask_d, MIN_AREA)\n            mask_d = cv2.dilate(mask_d, np.ones((3,3), np.uint8))\n\n            pred = mask_u & mask_d\n            pred = cv2.resize(pred, (w0, h0), interpolation=cv2.INTER_NEAREST)\n\n        rle = \"\" if pred.sum() == 0 else encode_rle(pred)\n\n        records.append({\n            \"ImageId\": img_name,\n            \"rle\": rle\n        })\n\n# -----------------------------\n# SAVE SUBMISSION (SAFE)\n# -----------------------------\ndf_sub = pandas.DataFrame(records, columns=[\"ImageId\", \"rle\"])\ndf_sub.to_csv(OUT_SUB, index=False)\n\nprint(\"\\n[STAGE 5 COMPLETE â€” SUBMISSION VALID]\")\nprint(\"Saved to:\", OUT_SUB)\nprint(\"Rows:\", len(df_sub))\nprint(\"Empty RLE:\", (df_sub[\"rle\"] == \"\").sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T05:54:29.226654Z","iopub.execute_input":"2026-02-06T05:54:29.227502Z","iopub.status.idle":"2026-02-06T05:55:24.981141Z","shell.execute_reply.started":"2026-02-06T05:54:29.227467Z","shell.execute_reply":"2026-02-06T05:55:24.980279Z"}},"outputs":[{"name":"stdout","text":"[CONFIG]\nthr_unetpp : 0.26\nthr_deeplab: 0.32\nmin_area  : 60\n[INFO] Models loaded\n[INFO] Test images: 295\n","output_type":"stream"},{"name":"stderr","text":"Structural Ensemble Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 295/295 [00:54<00:00,  5.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[STAGE 5 COMPLETE â€” SUBMISSION VALID]\nSaved to: /kaggle/working/submission.csv\nRows: 295\nEmpty RLE: 4\n","output_type":"stream"}],"execution_count":24}]}