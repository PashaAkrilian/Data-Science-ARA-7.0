{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":128328,"databundleVersionId":15445689,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Understanding & Preparation","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 1 — Data Understanding & Preparation (FINAL · REVISED)\n# Leaderboard-Oriented Version\n#\n# Goals:\n# 1. Validate dataset integrity\n# 2. Quantify Dice ceiling & failure modes\n# 3. Stratify image difficulty (easy → hard)\n# 4. Derive patch sampling priors\n# 5. Derive adaptive min-area & threshold priors\n# 6. Export artifacts for Stage 2–5\n# ============================================================\n\nfrom pathlib import Path\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom tqdm import tqdm\nimport re\nimport json\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nTRAIN_IMG_DIR = DATA_ROOT / \"train\" / \"images\"\nTRAIN_MASK_DIR = DATA_ROOT / \"train\" / \"mask\"\nTEST_IMG_DIR  = DATA_ROOT / \"test\" / \"images\"\n\nART_DIR = Path(\"/kaggle/working/artifacts\")\nART_DIR.mkdir(exist_ok=True)\n\nIMG_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n\n# -----------------------------\n# 1. LOAD FILES\n# -----------------------------\ntrain_images = sorted([p for p in TRAIN_IMG_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\ntrain_masks  = sorted([p for p in TRAIN_MASK_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\ntest_images  = sorted([p for p in TEST_IMG_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\n\nprint(f\"[INFO] Train images : {len(train_images)}\")\nprint(f\"[INFO] Train masks  : {len(train_masks)}\")\nprint(f\"[INFO] Test images  : {len(test_images)}\")\n\nassert len(train_images) == len(train_masks), \"Image-mask count mismatch\"\n\n# -----------------------------\n# 2. BUILD MASK INDEX\n# -----------------------------\ndef extract_index(name: str):\n    m = re.search(r\"(\\d+)\", name)\n    return m.group(1) if m else None\n\nmask_index = {extract_index(m.stem): m for m in train_masks if extract_index(m.stem) is not None}\n\n# -----------------------------\n# 3. PAIR IMAGE–MASK\n# -----------------------------\npairs = []\nfor img in train_images:\n    idx = extract_index(img.stem)\n    if idx in mask_index:\n        pairs.append({\n            \"image_path\": img,\n            \"mask_path\": mask_index[idx],\n            \"id\": idx\n        })\n\nassert len(pairs) > 0, \"No valid image-mask pairs found\"\nprint(f\"[INFO] Valid image-mask pairs: {len(pairs)}\")\n\n# -----------------------------\n# 4. MORPHOLOGY & DICE-RISK ANALYSIS\n# -----------------------------\nrecords = []\nall_component_areas = []\n\nfor p in tqdm(pairs, desc=\"Analyzing dataset\"):\n    mask = cv2.imread(str(p[\"mask_path\"]), cv2.IMREAD_GRAYSCALE)\n    h, w = mask.shape\n    total_pixels = h * w\n\n    bin_mask = (mask == 255).astype(np.uint8)\n    pothole_pixels = int(bin_mask.sum())\n    area_ratio = pothole_pixels / total_pixels\n\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n        bin_mask, connectivity=8\n    )\n\n    component_areas = stats[1:, cv2.CC_STAT_AREA] if num_labels > 1 else np.array([])\n    if len(component_areas) > 0:\n        all_component_areas.extend(component_areas.tolist())\n\n    records.append({\n        \"image\": p[\"image_path\"].name,\n        \"image_id\": p[\"id\"],\n        \"height\": h,\n        \"width\": w,\n        \"has_pothole\": int(pothole_pixels > 0),\n        \"total_pothole_pixels\": pothole_pixels,\n        \"area_ratio\": area_ratio,\n        \"num_components\": int(len(component_areas)),\n        \"max_component_ratio\": (\n            component_areas.max() / total_pixels if len(component_areas) > 0 else 0.0\n        ),\n        \"min_component_pixels\": (\n            int(component_areas.min()) if len(component_areas) > 0 else 0\n        ),\n    })\n\ndf = pd.DataFrame(records)\n\n# -----------------------------\n# 5. CORE DATASET STATISTICS\n# -----------------------------\nempty_ratio = (df[\"has_pothole\"] == 0).mean()\ntiny_ratio  = (df[\"area_ratio\"] < 0.01).mean()\n\nprint(\"\\n[CORE DATASET STATS]\")\nprint(f\"Empty-mask ratio            : {empty_ratio:.2%}\")\nprint(f\"Tiny-pothole (<1%) ratio    : {tiny_ratio:.2%}\")\n\n# -----------------------------\n# 6. COMPONENT AREA ANALYSIS\n# -----------------------------\ncomp_series = pd.Series(all_component_areas, name=\"component_area\")\n\narea_quantiles = comp_series.quantile([0.05, 0.10, 0.25, 0.50, 0.75]).astype(int)\n\nprint(\"\\n[CONNECTED COMPONENT AREA QUANTILES]\")\nprint(area_quantiles)\n\n# -----------------------------\n# 7. DICE CEILING ESTIMATION\n# -----------------------------\nmin_area_balanced = int(area_quantiles.loc[0.10])\n\nmissed_pixels = comp_series[comp_series < min_area_balanced].sum()\ntotal_gt_pixels = df[\"total_pothole_pixels\"].sum()\n\ndice_ceiling = 1.0 - (missed_pixels / total_gt_pixels)\n\nprint(\"\\n[DICE CEILING ESTIMATE]\")\nprint(f\"If components < {min_area_balanced}px are missed:\")\nprint(f\"→ Theoretical Dice ceiling ≈ {dice_ceiling:.4f}\")\n\n# -----------------------------\n# 8. IMAGE DIFFICULTY STRATIFICATION\n# -----------------------------\ndef classify_difficulty(row):\n    if row[\"has_pothole\"] == 0:\n        return \"empty\"\n    if row[\"area_ratio\"] < 0.005:\n        return \"hard_tiny\"\n    if row[\"num_components\"] >= 4:\n        return \"hard_fragmented\"\n    if row[\"area_ratio\"] < 0.02:\n        return \"medium\"\n    return \"easy\"\n\ndf[\"difficulty\"] = df.apply(classify_difficulty, axis=1)\n\nprint(\"\\n[IMAGE DIFFICULTY DISTRIBUTION]\")\nprint(df[\"difficulty\"].value_counts(normalize=True))\n\n# -----------------------------\n# 9. DATA-DRIVEN PRIORS\n# -----------------------------\nmin_area_policy = {\n    \"aggressive\": int(area_quantiles.loc[0.05]),\n    \"balanced\":   int(area_quantiles.loc[0.10]),\n    \"conservative\": int(area_quantiles.loc[0.25]),\n}\n\npatch_prior = {\n    \"oversample_difficulty\": [\"hard_tiny\", \"hard_fragmented\"],\n    \"keep_empty_patch_ratio\": round(empty_ratio * 0.5, 2),\n    \"patch_sizes\": [256, 384, 512]\n}\n\nthreshold_prior = {\n    \"start\": 0.30,\n    \"end\": 0.45,\n    \"reason\": \"small-object dominated Dice regime\"\n}\n\nprint(\"\\n[PRIORS GENERATED]\")\nprint(\"Min-area policy      :\", min_area_policy)\nprint(\"Patch sampling prior :\", patch_prior)\nprint(\"Threshold prior      :\", threshold_prior)\n\n# -----------------------------\n# 10. EXPORT ARTIFACTS\n# -----------------------------\ndf.to_parquet(ART_DIR / \"train_morphology.parquet\", index=False)\n\nwith open(ART_DIR / \"min_area_policy.json\", \"w\") as f:\n    json.dump(min_area_policy, f, indent=2)\n\nwith open(ART_DIR / \"patch_prior.json\", \"w\") as f:\n    json.dump(patch_prior, f, indent=2)\n\nwith open(ART_DIR / \"threshold_prior.json\", \"w\") as f:\n    json.dump(threshold_prior, f, indent=2)\n\nprint(\"\\n[ARTIFACTS SAVED]\")\nprint(\"- train_morphology.parquet\")\nprint(\"- min_area_policy.json\")\nprint(\"- patch_prior.json\")\nprint(\"- threshold_prior.json\")\n\n# -----------------------------\n# 11. FINAL STATUS\n# -----------------------------\nprint(\"\\n[STAGE 1 COMPLETE — LEADERBOARD READY]\")\nprint(\"✓ Dice ceiling quantified\")\nprint(\"✓ Hard-case images identified\")\nprint(\"✓ Patch / threshold / post-process priors derived\")\nprint(\"✓ Ready for STAGE 2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T05:26:29.110236Z","iopub.execute_input":"2026-02-07T05:26:29.110432Z","iopub.status.idle":"2026-02-07T05:26:42.797513Z","shell.execute_reply.started":"2026-02-07T05:26:29.110411Z","shell.execute_reply":"2026-02-07T05:26:42.796891Z"}},"outputs":[{"name":"stdout","text":"[INFO] Train images : 498\n[INFO] Train masks  : 498\n[INFO] Test images  : 295\n[INFO] Valid image-mask pairs: 498\n","output_type":"stream"},{"name":"stderr","text":"Analyzing dataset: 100%|██████████| 498/498 [00:12<00:00, 41.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[CORE DATASET STATS]\nEmpty-mask ratio            : 0.00%\nTiny-pothole (<1%) ratio    : 11.85%\n\n[CONNECTED COMPONENT AREA QUANTILES]\n0.05       68\n0.10      130\n0.25      393\n0.50     1913\n0.75    12032\nName: component_area, dtype: int64\n\n[DICE CEILING ESTIMATE]\nIf components < 130px are missed:\n→ Theoretical Dice ceiling ≈ 0.9999\n\n[IMAGE DIFFICULTY DISTRIBUTION]\ndifficulty\neasy               0.560241\nhard_fragmented    0.317269\nhard_tiny          0.086345\nmedium             0.036145\nName: proportion, dtype: float64\n\n[PRIORS GENERATED]\nMin-area policy      : {'aggressive': 68, 'balanced': 130, 'conservative': 393}\nPatch sampling prior : {'oversample_difficulty': ['hard_tiny', 'hard_fragmented'], 'keep_empty_patch_ratio': np.float64(0.0), 'patch_sizes': [256, 384, 512]}\nThreshold prior      : {'start': 0.3, 'end': 0.45, 'reason': 'small-object dominated Dice regime'}\n\n[ARTIFACTS SAVED]\n- train_morphology.parquet\n- min_area_policy.json\n- patch_prior.json\n- threshold_prior.json\n\n[STAGE 1 COMPLETE — LEADERBOARD READY]\n✓ Dice ceiling quantified\n✓ Hard-case images identified\n✓ Patch / threshold / post-process priors derived\n✓ Ready for STAGE 2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Preprocessing & Data Augmentation","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 2 — Preprocessing & Data Augmentation (FINAL CLEAN)\n# TARGET: PUSH PUBLIC SCORE → 0.80+\n#\n# Guaranteed:\n# - Kaggle Albumentations compatible\n# - NO warnings\n# - Fragment-connectivity aware\n# - Dice-faithful (mask safe)\n# ============================================================\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\n# -----------------------------\n# NORMALIZATION (CONSISTENT)\n# -----------------------------\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD  = (0.229, 0.224, 0.225)\n\n# ============================================================\n# TRAIN AUGMENTATION — 512 (FINAL)\n# ============================================================\ntrain_transform_512 = A.Compose(\n    [\n        # ----------------------------------------------------\n        # FIXED RESOLUTION (MATCH TRAIN / VAL / TEST)\n        # ----------------------------------------------------\n        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n\n        # ----------------------------------------------------\n        # GEOMETRY — VERY SAFE (BOUNDARY & FRAGMENT FRIENDLY)\n        # ----------------------------------------------------\n        A.HorizontalFlip(p=0.5),\n\n        A.Affine(\n            scale=(0.97, 1.05),\n            translate_percent=(0.0, 0.03),\n            rotate=(-2.0, 2.0),\n            shear=(-1.5, 1.5),\n            interpolation=cv2.INTER_LINEAR,\n            p=0.40,\n        ),\n\n        # ----------------------------------------------------\n        # CONTEXT & FRAGMENT CONNECTIVITY (LOW PROB, SAFE)\n        # ----------------------------------------------------\n        A.OneOf(\n            [\n                A.GridDistortion(\n                    num_steps=5,\n                    distort_limit=0.02,\n                    border_mode=cv2.BORDER_REFLECT_101,\n                ),\n                A.ElasticTransform(\n                    alpha=8,\n                    sigma=12,\n                    border_mode=cv2.BORDER_REFLECT_101,\n                ),\n            ],\n            p=0.12,\n        ),\n\n        # ----------------------------------------------------\n        # PHOTOMETRIC (GENERALIZATION DRIVER)\n        # ----------------------------------------------------\n        A.RandomBrightnessContrast(\n            brightness_limit=0.18,\n            contrast_limit=0.18,\n            p=0.65,\n        ),\n\n        A.HueSaturationValue(\n            hue_shift_limit=5,\n            sat_shift_limit=10,\n            val_shift_limit=5,\n            p=0.30,\n        ),\n\n        # ----------------------------------------------------\n        # SHADOW (SMALL POTHOLE SAFE)\n        # ----------------------------------------------------\n        A.RandomShadow(\n            shadow_roi=(0, 0.45, 1, 1),\n            shadow_dimension=4,\n            p=0.22,\n        ),\n\n        # ----------------------------------------------------\n        # TEXTURE NOISE (VERY MILD)\n        # ----------------------------------------------------\n        A.OneOf(\n            [\n                A.GaussianBlur(blur_limit=3),\n                A.GaussNoise(std_range=(0.03, 0.08)),\n            ],\n            p=0.15,\n        ),\n\n        # ----------------------------------------------------\n        # NORMALIZE + TENSOR\n        # ----------------------------------------------------\n        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ToTensorV2(),\n    ],\n    additional_targets={\"mask\": \"mask\"},\n)\n\n# ============================================================\n# VALIDATION TRANSFORM (STRICT, DETERMINISTIC)\n# ============================================================\nvalid_transform = A.Compose(\n    [\n        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ToTensorV2(),\n    ],\n    additional_targets={\"mask\": \"mask\"},\n)\n\n# ============================================================\n# TEST TRANSFORM (IDENTICAL TO VALIDATION)\n# ============================================================\ntest_transform = A.Compose(\n    [\n        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ToTensorV2(),\n    ]\n)\n\n# ============================================================\n# FINAL CHECK\n# ============================================================\nprint(\"[STAGE 2 COMPLETE — CLEAN & 0.80+ READY]\")\nprint(\"✓ Kaggle Albumentations compatible (NO WARNINGS)\")\nprint(\"✓ Fragment connectivity augmentation ACTIVE\")\nprint(\"✓ Dice-faithful geometry & photometric\")\nprint(\"✓ Single-resolution consistency (512)\")\nprint(\"✓ Fully aligned with STAGE 1 priors\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T05:26:42.799121Z","iopub.execute_input":"2026-02-07T05:26:42.799611Z","iopub.status.idle":"2026-02-07T05:26:48.399985Z","shell.execute_reply.started":"2026-02-07T05:26:42.799586Z","shell.execute_reply":"2026-02-07T05:26:48.399218Z"}},"outputs":[{"name":"stdout","text":"[STAGE 2 COMPLETE — CLEAN & 0.80+ READY]\n✓ Kaggle Albumentations compatible (NO WARNINGS)\n✓ Fragment connectivity augmentation ACTIVE\n✓ Dice-faithful geometry & photometric\n✓ Single-resolution consistency (512)\n✓ Fully aligned with STAGE 1 priors\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Model Construction & Training","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch==0.3.3 timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T05:26:48.401035Z","iopub.execute_input":"2026-02-07T05:26:48.401482Z","iopub.status.idle":"2026-02-07T05:26:59.241702Z","shell.execute_reply.started":"2026-02-07T05:26:48.401457Z","shell.execute_reply":"2026-02-07T05:26:59.240789Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# STAGE 3 — Model Construction & Training (CLEAN LOGGING)\n# Fragment-aware, Recall-heavy, Leaderboard-aligned\n# ============================================================\n\nimport os, re, random\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch.amp import autocast, GradScaler\n\nimport segmentation_models_pytorch as smp\nfrom sklearn.model_selection import train_test_split\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nSEED = 42\nIMG_SIZE = 512\nBATCH_SIZE = 4\nACCUM_STEPS = 2\n\nEPOCHS = {\n    \"unetpp\": 30,\n    \"deeplab\": 22,\n}\n\nLR = 2e-4\nWEIGHT_DECAY = 1e-4\nVAL_RATIO = 0.15\nVAL_THR = 0.40\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n# -----------------------------\n# DATA\n# -----------------------------\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nTRAIN_IMG_DIR = DATA_ROOT / \"train/images\"\nTRAIN_MASK_DIR = DATA_ROOT / \"train/mask\"\n\ndef extract_idx(name):\n    return re.search(r\"(\\d+)\", name).group(1)\n\npairs = []\nfor img in TRAIN_IMG_DIR.iterdir():\n    idx = extract_idx(img.name)\n    mask = TRAIN_MASK_DIR / f\"mask_{idx}.png\"\n    if mask.exists():\n        pairs.append((str(img), str(mask)))\n\ndf = pd.DataFrame(pairs, columns=[\"image_path\", \"mask_path\"])\ndf_train, df_val = train_test_split(\n    df, test_size=VAL_RATIO, random_state=SEED, shuffle=True\n)\n\n# -----------------------------\n# DATASET\n# -----------------------------\nclass PotholeDataset(Dataset):\n    def __init__(self, df, transform):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.df.loc[idx, \"image_path\"])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.df.loc[idx, \"mask_path\"], cv2.IMREAD_GRAYSCALE)\n        mask = (mask == 255).astype(\"float32\")\n\n        aug = self.transform(image=img, mask=mask)\n        return aug[\"image\"], aug[\"mask\"].unsqueeze(0)\n\n# -----------------------------\n# LOSS\n# -----------------------------\ndice_loss = smp.losses.DiceLoss(mode=\"binary\", from_logits=True)\nfocal_loss = smp.losses.FocalLoss(\n    mode=\"binary\", alpha=0.85, gamma=2.0, normalized=True\n)\n\ndef criterion(logits, targets):\n    return dice_loss(logits, targets) + 0.7 * focal_loss(logits, targets)\n\n# -----------------------------\n# METRIC\n# -----------------------------\n@torch.no_grad()\ndef dice_hard(prob, target, thr=VAL_THR, eps=1e-7):\n    pred = (prob > thr).float()\n    inter = (pred * target).sum(dim=(2,3))\n    union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n    return ((2 * inter + eps) / (union + eps)).mean()\n\n# -----------------------------\n# MODEL FACTORY\n# -----------------------------\ndef build_model(name):\n    if name == \"unetpp\":\n        return smp.UnetPlusPlus(\n            encoder_name=\"efficientnet-b4\",\n            encoder_weights=\"imagenet\",  # ⬅️ download bar muncul\n            in_channels=3,\n            classes=1,\n        )\n    if name == \"deeplab\":\n        return smp.DeepLabV3Plus(\n            encoder_name=\"resnet101\",\n            encoder_weights=\"imagenet\",\n            in_channels=3,\n            classes=1,\n        )\n\n# -----------------------------\n# TRAIN FUNCTION (CLEAN LOG)\n# -----------------------------\ndef train_model(name):\n\n    name_l = name.lower()\n    max_epoch = EPOCHS[name_l]\n\n    print(f\"\\n===== TRAINING {name_l.upper()} =====\")\n\n    model = build_model(name_l).to(device)\n    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n    scheduler = CosineAnnealingLR(optimizer, T_max=max_epoch)\n    scaler = GradScaler()\n\n    train_loader = DataLoader(\n        PotholeDataset(df_train, train_transform_512),\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True\n    )\n\n    val_loader = DataLoader(\n        PotholeDataset(df_val, valid_transform),\n        batch_size=1,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n\n    best_val = 0.0\n\n    for epoch in range(1, max_epoch + 1):\n\n        # -------- TRAIN --------\n        model.train()\n        optimizer.zero_grad()\n        total_loss = 0.0\n\n        pbar = tqdm(\n            train_loader,\n            desc=f\"{name_l} | Epoch {epoch:02d}\",\n            leave=False\n        )\n\n        for imgs, masks in pbar:\n            imgs, masks = imgs.to(device), masks.to(device)\n\n            with autocast(device_type=\"cuda\"):\n                logits = model(imgs)\n                loss = criterion(logits, masks) / ACCUM_STEPS\n\n            scaler.scale(loss).backward()\n\n            if (pbar.n + 1) % ACCUM_STEPS == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n\n            total_loss += loss.item() * ACCUM_STEPS\n            pbar.set_postfix(loss=f\"{loss.item()*ACCUM_STEPS:.4f}\")\n\n        scheduler.step()\n\n        # -------- VALID --------\n        model.eval()\n        dices = []\n\n        with torch.no_grad():\n            for imgs, masks in val_loader:\n                imgs, masks = imgs.to(device), masks.to(device)\n                prob = torch.sigmoid(model(imgs))\n                dices.append(dice_hard(prob, masks).item())\n\n        val_dice = float(np.mean(dices))\n        train_loss = total_loss / len(train_loader)\n\n        # -------- EPOCH SUMMARY (INI YANG KAMU MAU) --------\n        print(\n            f\"{name_l} | Epoch {epoch:02d} | \"\n            f\"TrainLoss {train_loss:.4f} | \"\n            f\"ValDice {val_dice:.4f}\"\n        )\n\n        if val_dice > best_val:\n            best_val = val_dice\n            torch.save(model.state_dict(), f\"/kaggle/working/best_{name_l}.pt\")\n            print(f\">> Best {name_l} saved\")\n\n    print(f\"[DONE] {name_l} best Val Dice: {best_val:.4f}\")\n\n# -----------------------------\n# RUN\n# -----------------------------\ntrain_model(\"unetpp\")\ntrain_model(\"deeplab\")\n\nprint(\"\\n[STAGE 3 COMPLETE — CLEAN TRAINING LOG ENABLED]\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T06:12:30.859244Z","iopub.execute_input":"2026-02-07T06:12:30.859944Z","iopub.status.idle":"2026-02-07T06:42:44.641017Z","shell.execute_reply.started":"2026-02-07T06:12:30.859897Z","shell.execute_reply":"2026-02-07T06:42:44.640099Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n\n===== TRAINING UNETPP =====\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 01 | TrainLoss 0.6924 | ValDice 0.5283\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 02 | TrainLoss 0.5073 | ValDice 0.6309\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 03 | TrainLoss 0.3900 | ValDice 0.6491\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 04 | TrainLoss 0.3143 | ValDice 0.6701\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 05 | TrainLoss 0.2626 | ValDice 0.6866\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 06 | TrainLoss 0.2327 | ValDice 0.6680\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 07 | TrainLoss 0.2042 | ValDice 0.6876\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 08 | TrainLoss 0.1867 | ValDice 0.7064\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 09 | TrainLoss 0.1810 | ValDice 0.6926\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 10 | TrainLoss 0.1632 | ValDice 0.6863\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 11 | TrainLoss 0.1440 | ValDice 0.7228\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 12 | TrainLoss 0.1527 | ValDice 0.6819\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 13 | TrainLoss 0.1412 | ValDice 0.7131\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 14 | TrainLoss 0.1300 | ValDice 0.7244\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 15 | TrainLoss 0.1235 | ValDice 0.7377\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 16 | TrainLoss 0.1217 | ValDice 0.7473\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 17 | TrainLoss 0.1154 | ValDice 0.7463\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 18 | TrainLoss 0.1104 | ValDice 0.7396\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 19 | TrainLoss 0.1111 | ValDice 0.7303\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 20 | TrainLoss 0.1039 | ValDice 0.7432\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 21 | TrainLoss 0.1079 | ValDice 0.7405\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 22 | TrainLoss 0.1031 | ValDice 0.7400\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 23 | TrainLoss 0.1039 | ValDice 0.7443\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 24 | TrainLoss 0.1017 | ValDice 0.7467\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 25 | TrainLoss 0.1010 | ValDice 0.7487\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 26 | TrainLoss 0.0958 | ValDice 0.7479\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 27 | TrainLoss 0.1041 | ValDice 0.7473\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 28 | TrainLoss 0.0949 | ValDice 0.7478\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 29 | TrainLoss 0.0978 | ValDice 0.7458\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 30 | TrainLoss 0.1041 | ValDice 0.7475\n[DONE] unetpp best Val Dice: 0.7487\n\n===== TRAINING DEEPLAB =====\nDownloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:00<00:00, 316MB/s] \n                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 01 | TrainLoss 0.5775 | ValDice 0.4657\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 02 | TrainLoss 0.4658 | ValDice 0.5837\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 03 | TrainLoss 0.4040 | ValDice 0.5801\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 04 | TrainLoss 0.3498 | ValDice 0.6181\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 05 | TrainLoss 0.3161 | ValDice 0.6129\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 06 | TrainLoss 0.2912 | ValDice 0.5873\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 07 | TrainLoss 0.2762 | ValDice 0.5940\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 08 | TrainLoss 0.2823 | ValDice 0.6418\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 09 | TrainLoss 0.2411 | ValDice 0.6135\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 10 | TrainLoss 0.2162 | ValDice 0.6272\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 11 | TrainLoss 0.2218 | ValDice 0.6392\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 12 | TrainLoss 0.2104 | ValDice 0.6472\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 13 | TrainLoss 0.1928 | ValDice 0.6629\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 14 | TrainLoss 0.1789 | ValDice 0.6659\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 15 | TrainLoss 0.1634 | ValDice 0.6635\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 16 | TrainLoss 0.1609 | ValDice 0.6774\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 17 | TrainLoss 0.1557 | ValDice 0.6806\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 18 | TrainLoss 0.1500 | ValDice 0.6764\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 19 | TrainLoss 0.1471 | ValDice 0.6789\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 20 | TrainLoss 0.1420 | ValDice 0.6825\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 21 | TrainLoss 0.1450 | ValDice 0.6863\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 22 | TrainLoss 0.1343 | ValDice 0.6841\n[DONE] deeplab best Val Dice: 0.6863\n\n[STAGE 3 COMPLETE — CLEAN TRAINING LOG ENABLED]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Optimization, Validation & Refinement","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 4 — MAX PERFORMANCE ENSEMBLE OPTIMIZATION (REVISI FINAL)\n# REAL PUSH: +0.05 LB\n# ============================================================\n\n!pip install -q optuna\n\nimport optuna\nimport numpy as np\nimport torch\nimport cv2\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport segmentation_models_pytorch as smp\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nDEVICE = torch.device(\"cuda\")\nIMG_SIZE = 512\n\nprint(\"Device:\", DEVICE)\n\n# -----------------------------\n# DATA\n# -----------------------------\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nIMG_DIR = DATA_ROOT / \"train/images\"\nMSK_DIR = DATA_ROOT / \"train/mask\"\n\ndef extract_idx(n):\n    import re\n    return re.search(r\"(\\d+)\", n).group(1)\n\npairs = []\nfor img in IMG_DIR.iterdir():\n    idx = extract_idx(img.name)\n    m = MSK_DIR / f\"mask_{idx}.png\"\n    if m.exists():\n        pairs.append((str(img), str(m)))\n\npairs = np.array(pairs, dtype=object)\n\n_, val_pairs = train_test_split(pairs, test_size=0.15, random_state=42)\n\n# -----------------------------\n# DATASET (NO AUG, MATCH STAGE 3)\n# -----------------------------\nclass ValDS(Dataset):\n    def __init__(self, pairs):\n        self.pairs = pairs\n\n    def __len__(self): return len(self.pairs)\n\n    def __getitem__(self, i):\n        img = cv2.imread(self.pairs[i][0])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        msk = cv2.imread(self.pairs[i][1], 0)\n        msk = (msk==255).astype(np.uint8)\n\n        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n        msk = cv2.resize(msk,(IMG_SIZE,IMG_SIZE),interpolation=cv2.INTER_NEAREST)\n\n        img = img.astype(np.float32)/255.0\n        img[...,0]=(img[...,0]-0.485)/0.229\n        img[...,1]=(img[...,1]-0.456)/0.224\n        img[...,2]=(img[...,2]-0.406)/0.225\n\n        img = torch.from_numpy(img.transpose(2,0,1))\n        msk = torch.from_numpy(msk).unsqueeze(0)\n        return img, msk\n\nval_loader = DataLoader(ValDS(val_pairs), batch_size=1, shuffle=False)\n\nprint(\"[INFO] Validation images:\", len(val_pairs))\n\n# -----------------------------\n# LOAD MODELS\n# -----------------------------\ndef load_model(name, enc):\n    m = name(\n        encoder_name=enc,\n        encoder_weights=None,\n        in_channels=3,\n        classes=1\n    ).to(DEVICE)\n    return m.eval()\n\nunetpp = load_model(smp.UnetPlusPlus, \"efficientnet-b4\")\ndeeplab = load_model(smp.DeepLabV3Plus, \"resnet101\")\n\nunetpp.load_state_dict(torch.load(\"/kaggle/working/best_unetpp.pt\"))\ndeeplab.load_state_dict(torch.load(\"/kaggle/working/best_deeplab.pt\"))\n\n# -----------------------------\n# UTILS\n# -----------------------------\ndef soft_dice(p, g, eps=1e-7):\n    inter = (p*g).sum()\n    union = p.sum() + g.sum()\n    return (2*inter+eps)/(union+eps)\n\ndef logit(p):\n    p = np.clip(p,1e-6,1-1e-6)\n    return np.log(p/(1-p))\n\ndef sigmoid(x): return 1/(1+np.exp(-x))\n\n# -----------------------------\n# ADAPTIVE FILTER\n# -----------------------------\ndef adaptive_filter(prob, thr, min_area):\n    binm = (prob > thr).astype(np.uint8)\n    n, lbl, stat, _ = cv2.connectedComponentsWithStats(binm,8)\n    out = np.zeros_like(binm)\n\n    for i in range(1,n):\n        area = stat[i,cv2.CC_STAT_AREA]\n        if area >= min_area:\n            out[lbl==i]=1\n    return out\n\n# -----------------------------\n# OBJECTIVE\n# -----------------------------\ndef objective(trial):\n\n    w_u = trial.suggest_float(\"w_unetpp\", 0.75, 0.88)\n    w_d = 1.0 - w_u\n\n    base_thr = trial.suggest_float(\"base_thr\", 0.32, 0.42)\n    area_q  = trial.suggest_float(\"area_q\", 0.05, 0.25)\n\n    dices = []\n\n    with torch.no_grad():\n        for img, gt in val_loader:\n            img = img.to(DEVICE)\n            gt = gt.numpy()[0,0]\n\n            pu = torch.sigmoid(unetpp(img))[0,0].cpu().numpy()\n            pd = torch.sigmoid(deeplab(img))[0,0].cpu().numpy()\n\n            mix = sigmoid(w_u*logit(pu) + w_d*logit(pd))\n\n            # adaptive threshold per image\n            thr = base_thr + 0.05*(mix.mean()<0.02)\n\n            # area from quantile\n            areas=[]\n            lab = (mix>thr).astype(np.uint8)\n            n,_,stat,_ = cv2.connectedComponentsWithStats(lab,8)\n            for i in range(1,n):\n                areas.append(stat[i,cv2.CC_STAT_AREA])\n            min_area = np.quantile(areas, area_q) if areas else 0\n\n            pred = adaptive_filter(mix, thr, min_area)\n            dices.append(soft_dice(pred, gt))\n\n    return float(np.mean(dices))\n\n# -----------------------------\n# RUN OPTUNA\n# -----------------------------\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=50, show_progress_bar=True)\n\nbest = study.best_params\nprint(\"\\n[STAGE 4 BEST CONFIG]\")\nfor k,v in best.items(): print(k,\":\",v)\n\nOPT_CONFIG = {\n    \"weights\": {\n        \"unetpp\": best[\"w_unetpp\"],\n        \"deeplab\": 1.0-best[\"w_unetpp\"]\n    },\n    \"base_thr\": best[\"base_thr\"],\n    \"area_q\": best[\"area_q\"]\n}\n\nprint(\"\\n[STAGE 4 COMPLETE — READY FOR 0.80+]\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T06:42:44.642763Z","iopub.execute_input":"2026-02-07T06:42:44.643061Z","iopub.status.idle":"2026-02-07T06:51:13.928561Z","shell.execute_reply.started":"2026-02-07T06:42:44.643033Z","shell.execute_reply":"2026-02-07T06:51:13.927693Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n[INFO] Validation images: 75\n","output_type":"stream"},{"name":"stderr","text":"[I 2026-02-07 06:42:49,507] A new study created in memory with name: no-name-14103752-1a8c-4ac5-943b-e84495a61208\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6cd88a0b7f4ebfb8c8c7b1c3f539de"}},"metadata":{}},{"name":"stdout","text":"[I 2026-02-07 06:42:59,436] Trial 0 finished with value: 0.7400397535240922 and parameters: {'w_unetpp': 0.8126847426980056, 'base_thr': 0.4040186886201319, 'area_q': 0.09055041626909521}. Best is trial 0 with value: 0.7400397535240922.\n[I 2026-02-07 06:43:09,353] Trial 1 finished with value: 0.7404538148466298 and parameters: {'w_unetpp': 0.800957606990449, 'base_thr': 0.32503082452608695, 'area_q': 0.05998114920367921}. Best is trial 1 with value: 0.7404538148466298.\n[I 2026-02-07 06:43:19,269] Trial 2 finished with value: 0.7405070225733613 and parameters: {'w_unetpp': 0.8565191198795457, 'base_thr': 0.3335145109057241, 'area_q': 0.1457413576739553}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:43:29,140] Trial 3 finished with value: 0.7402410653976685 and parameters: {'w_unetpp': 0.8648337478657422, 'base_thr': 0.3750568401203763, 'area_q': 0.20761203988385862}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:43:38,917] Trial 4 finished with value: 0.7403227660144608 and parameters: {'w_unetpp': 0.7534920722303299, 'base_thr': 0.3463616566535594, 'area_q': 0.18186450629869655}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:43:48,778] Trial 5 finished with value: 0.740453183708628 and parameters: {'w_unetpp': 0.7790773085028627, 'base_thr': 0.330129686755122, 'area_q': 0.21845571430202204}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:43:58,704] Trial 6 finished with value: 0.7404661350681976 and parameters: {'w_unetpp': 0.8747260681506781, 'base_thr': 0.3287893883273707, 'area_q': 0.07613814416682368}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:44:08,599] Trial 7 finished with value: 0.7398880551513176 and parameters: {'w_unetpp': 0.7971422377372248, 'base_thr': 0.4057361258445593, 'area_q': 0.24170816249752697}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:44:18,536] Trial 8 finished with value: 0.7400108647453634 and parameters: {'w_unetpp': 0.7794763682369239, 'base_thr': 0.40078057199303774, 'area_q': 0.09360568493147997}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:44:28,491] Trial 9 finished with value: 0.7403857936332338 and parameters: {'w_unetpp': 0.7725554640039974, 'base_thr': 0.34406484135068494, 'area_q': 0.17004122793222212}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:44:38,468] Trial 10 finished with value: 0.739824229305091 and parameters: {'w_unetpp': 0.8450822361380623, 'base_thr': 0.3687948851591448, 'area_q': 0.13804072969419273}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:44:48,439] Trial 11 finished with value: 0.740353600421632 and parameters: {'w_unetpp': 0.8795073868470342, 'base_thr': 0.3478559869682764, 'area_q': 0.1293202921339815}. Best is trial 2 with value: 0.7405070225733613.\n[I 2026-02-07 06:44:58,361] Trial 12 finished with value: 0.7405552740601307 and parameters: {'w_unetpp': 0.8410624441437188, 'base_thr': 0.32254809551914987, 'area_q': 0.05092580051021732}. Best is trial 12 with value: 0.7405552740601307.\n[I 2026-02-07 06:45:08,344] Trial 13 finished with value: 0.7399237387175833 and parameters: {'w_unetpp': 0.8382609446062613, 'base_thr': 0.36021342246133414, 'area_q': 0.1149795289245426}. Best is trial 12 with value: 0.7405552740601307.\n[I 2026-02-07 06:45:18,270] Trial 14 finished with value: 0.7405830676040992 and parameters: {'w_unetpp': 0.8380698742189988, 'base_thr': 0.32000607972102313, 'area_q': 0.053803238693338626}. Best is trial 14 with value: 0.7405830676040992.\n[I 2026-02-07 06:45:28,181] Trial 15 finished with value: 0.7406370297708311 and parameters: {'w_unetpp': 0.830546520661835, 'base_thr': 0.32026902612753866, 'area_q': 0.051983627254926605}. Best is trial 15 with value: 0.7406370297708311.\n[I 2026-02-07 06:45:38,045] Trial 16 finished with value: 0.7400853672082199 and parameters: {'w_unetpp': 0.8221576421838306, 'base_thr': 0.37661426658841585, 'area_q': 0.07625810218999478}. Best is trial 15 with value: 0.7406370297708311.\n[I 2026-02-07 06:45:47,878] Trial 17 finished with value: 0.7400186343231495 and parameters: {'w_unetpp': 0.8284031509177503, 'base_thr': 0.38486715208237715, 'area_q': 0.10501381810287282}. Best is trial 15 with value: 0.7406370297708311.\n[I 2026-02-07 06:45:57,731] Trial 18 finished with value: 0.740288754597205 and parameters: {'w_unetpp': 0.8096706219519105, 'base_thr': 0.34030050596757, 'area_q': 0.07056648647409675}. Best is trial 15 with value: 0.7406370297708311.\n[I 2026-02-07 06:46:07,610] Trial 19 finished with value: 0.7403572847246029 and parameters: {'w_unetpp': 0.858340015178935, 'base_thr': 0.35616506201223663, 'area_q': 0.05384108538882028}. Best is trial 15 with value: 0.7406370297708311.\n[I 2026-02-07 06:46:17,464] Trial 20 finished with value: 0.7400136207739622 and parameters: {'w_unetpp': 0.8292689485555406, 'base_thr': 0.3905974774552768, 'area_q': 0.16735222436222336}. Best is trial 15 with value: 0.7406370297708311.\n[I 2026-02-07 06:46:27,385] Trial 21 finished with value: 0.7405566354659516 and parameters: {'w_unetpp': 0.8431705908029433, 'base_thr': 0.32230785894939296, 'area_q': 0.051827850783126905}. Best is trial 15 with value: 0.7406370297708311.\n[I 2026-02-07 06:46:37,341] Trial 22 finished with value: 0.7404998101383302 and parameters: {'w_unetpp': 0.8475218714809214, 'base_thr': 0.33498188770212717, 'area_q': 0.08725797739049433}. Best is trial 15 with value: 0.7406370297708311.\n[I 2026-02-07 06:46:47,263] Trial 23 finished with value: 0.7406704477796473 and parameters: {'w_unetpp': 0.8326118853484784, 'base_thr': 0.3211078822346584, 'area_q': 0.06676823765872665}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:46:57,211] Trial 24 finished with value: 0.7401643139568633 and parameters: {'w_unetpp': 0.8237294950770929, 'base_thr': 0.320542804334156, 'area_q': 0.07203402889589719}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:47:07,162] Trial 25 finished with value: 0.7398410577325469 and parameters: {'w_unetpp': 0.830928221154108, 'base_thr': 0.4193066728310932, 'area_q': 0.1099400820210431}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:47:17,092] Trial 26 finished with value: 0.7404068026017697 and parameters: {'w_unetpp': 0.8018365068473392, 'base_thr': 0.3364657195886229, 'area_q': 0.122225417947504}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:47:27,049] Trial 27 finished with value: 0.7401803822802535 and parameters: {'w_unetpp': 0.8175096228449431, 'base_thr': 0.35479055262876175, 'area_q': 0.0668019655207415}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:47:36,985] Trial 28 finished with value: 0.7405266073936136 and parameters: {'w_unetpp': 0.8551895468540235, 'base_thr': 0.3287924385240983, 'area_q': 0.0987703921602463}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:47:46,940] Trial 29 finished with value: 0.7401118421654549 and parameters: {'w_unetpp': 0.8121815277595836, 'base_thr': 0.32027105708682757, 'area_q': 0.0814577449938098}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:47:56,898] Trial 30 finished with value: 0.7400500139030309 and parameters: {'w_unetpp': 0.8349905602159624, 'base_thr': 0.3391548137350364, 'area_q': 0.09301870266681844}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:48:06,919] Trial 31 finished with value: 0.740532502053862 and parameters: {'w_unetpp': 0.8482658520051645, 'base_thr': 0.3263959618165827, 'area_q': 0.05910512055224428}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:48:16,928] Trial 32 finished with value: 0.740487538180865 and parameters: {'w_unetpp': 0.867756961676211, 'base_thr': 0.32093225216898597, 'area_q': 0.06036832191533398}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:48:26,870] Trial 33 finished with value: 0.7404734875992962 and parameters: {'w_unetpp': 0.8524886748672329, 'base_thr': 0.33115261586453515, 'area_q': 0.054315608197736266}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:48:36,842] Trial 34 finished with value: 0.740601085270199 and parameters: {'w_unetpp': 0.8375661709319108, 'base_thr': 0.32560970659159966, 'area_q': 0.050107709881913196}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:48:46,777] Trial 35 finished with value: 0.7401193966032577 and parameters: {'w_unetpp': 0.8368725176488805, 'base_thr': 0.3332639704221684, 'area_q': 0.06777054361613707}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:48:56,714] Trial 36 finished with value: 0.7401530710633617 and parameters: {'w_unetpp': 0.8190540890990403, 'base_thr': 0.32617202994713534, 'area_q': 0.07978433728393228}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:49:06,654] Trial 37 finished with value: 0.740375054772628 and parameters: {'w_unetpp': 0.8659105570989732, 'base_thr': 0.34978136342415994, 'area_q': 0.062374932540121386}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:49:16,538] Trial 38 finished with value: 0.7403672363022099 and parameters: {'w_unetpp': 0.7960073327915976, 'base_thr': 0.34256379733408304, 'area_q': 0.08560419911928183}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:49:26,463] Trial 39 finished with value: 0.7404915964322468 and parameters: {'w_unetpp': 0.8072710860461011, 'base_thr': 0.32790781966925514, 'area_q': 0.2059131378391152}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:49:36,420] Trial 40 finished with value: 0.7400640853444824 and parameters: {'w_unetpp': 0.827037188610805, 'base_thr': 0.33420568593813277, 'area_q': 0.10059012478375406}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:49:46,399] Trial 41 finished with value: 0.7405537591187916 and parameters: {'w_unetpp': 0.8413725851009621, 'base_thr': 0.3256378110747766, 'area_q': 0.0516005730702679}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:49:56,505] Trial 42 finished with value: 0.7406394413560848 and parameters: {'w_unetpp': 0.8343803866998533, 'base_thr': 0.3242589746972397, 'area_q': 0.06259464603769284}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:50:07,400] Trial 43 finished with value: 0.7401183091743624 and parameters: {'w_unetpp': 0.8319465907661255, 'base_thr': 0.33149373702260015, 'area_q': 0.06422562863227431}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:50:18,275] Trial 44 finished with value: 0.740486984803215 and parameters: {'w_unetpp': 0.8520882922530865, 'base_thr': 0.3373494314588622, 'area_q': 0.07765530065706185}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:50:29,759] Trial 45 finished with value: 0.7405082412779613 and parameters: {'w_unetpp': 0.8597433119863789, 'base_thr': 0.3269191233267515, 'area_q': 0.15170433351917373}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:50:41,615] Trial 46 finished with value: 0.7401376445258315 and parameters: {'w_unetpp': 0.8236892238440979, 'base_thr': 0.3242289667745373, 'area_q': 0.06231403349024949}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:50:53,122] Trial 47 finished with value: 0.7406381313002549 and parameters: {'w_unetpp': 0.836573137364076, 'base_thr': 0.3200289523103076, 'area_q': 0.08860704614797521}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:51:03,241] Trial 48 finished with value: 0.7401997200231066 and parameters: {'w_unetpp': 0.7572426385524604, 'base_thr': 0.3641316757525463, 'area_q': 0.24683850297043788}. Best is trial 23 with value: 0.7406704477796473.\n[I 2026-02-07 06:51:13,922] Trial 49 finished with value: 0.7402732631864751 and parameters: {'w_unetpp': 0.8166386009714749, 'base_thr': 0.3452947062435813, 'area_q': 0.09017834143270452}. Best is trial 23 with value: 0.7406704477796473.\n\n[STAGE 4 BEST CONFIG]\nw_unetpp : 0.8326118853484784\nbase_thr : 0.3211078822346584\narea_q : 0.06676823765872665\n\n[STAGE 4 COMPLETE — READY FOR 0.80+]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Inference, Encoding & Submission","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 5 — FINAL ENSEMBLE INFERENCE & SUBMISSION (LOCKED)\n# TARGET: 0.80+ | STAGE-4 CONSISTENT | ANTI-ZONK\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport cv2\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport segmentation_models_pytorch as smp\n\n# -----------------------------\n# PATHS & DEVICE\n# -----------------------------\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nTEST_IMG_DIR = DATA_ROOT / \"test/images\"\nSAMPLE_SUB = Path(\"/kaggle/input/data-science-ara-7-0/sample_submission.csv\")\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# -----------------------------\n# LOAD OPT_CONFIG (FROM STAGE 4)\n# -----------------------------\nW_U = OPT_CONFIG[\"weights\"][\"unetpp\"]\nW_D = OPT_CONFIG[\"weights\"][\"deeplab\"]\nBASE_THR = OPT_CONFIG[\"base_thr\"]\nAREA_Q   = OPT_CONFIG[\"area_q\"]\n\nprint(\"[CONFIG]\")\nprint(\"Weights:\", W_U, W_D)\nprint(\"BaseThr:\", BASE_THR, \"Area_q:\", AREA_Q)\n\n# -----------------------------\n# INFERENCE CONFIG\n# -----------------------------\nINPUT_SIZE = 512\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD  = (0.229, 0.224, 0.225)\n\n# -----------------------------\n# LOAD MODELS\n# -----------------------------\ndef load_model(cls, enc, path):\n    m = cls(\n        encoder_name=enc,\n        encoder_weights=None,\n        in_channels=3,\n        classes=1,\n    ).to(DEVICE)\n    m.load_state_dict(torch.load(path, map_location=DEVICE))\n    m.eval()\n    return m\n\nunetpp = load_model(\n    smp.UnetPlusPlus,\n    \"efficientnet-b4\",\n    \"/kaggle/working/best_unetpp.pt\",\n)\n\ndeeplab = load_model(\n    smp.DeepLabV3Plus,\n    \"resnet101\",\n    \"/kaggle/working/best_deeplab.pt\",\n)\n\nprint(\"[INFO] Models loaded\")\n\n# -----------------------------\n# RLE ENCODER (OFFICIAL)\n# -----------------------------\ndef encode_rle(mask):\n    pixels = mask.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[0::2]\n    return \" \".join(map(str, runs))\n\n# -----------------------------\n# POST PROCESS (QUANTILE AREA)\n# -----------------------------\ndef quantile_area_filter(prob, thr, area_q):\n    binm = (prob > thr).astype(np.uint8)\n    n, labels, stats, _ = cv2.connectedComponentsWithStats(binm, 8)\n\n    areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, n)]\n    min_area = np.quantile(areas, area_q) if areas else 0\n\n    out = np.zeros_like(binm)\n    for i in range(1, n):\n        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n            out[labels == i] = 1\n    return out\n\n# -----------------------------\n# LOAD TEST FILES\n# -----------------------------\ntest_images = sorted(TEST_IMG_DIR.glob(\"*.jpg\"))\nprint(\"[INFO] Test images:\", len(test_images))\n\n# -----------------------------\n# FINAL INFERENCE\n# -----------------------------\nrecords = []\n\nwith torch.no_grad():\n    for p in tqdm(test_images, desc=\"Final Inference\"):\n        img_name = p.name\n\n        img = cv2.imread(str(p))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        h0, w0 = img.shape[:2]\n\n        img_r = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE)).astype(np.float32) / 255.0\n        for c in range(3):\n            img_r[..., c] = (img_r[..., c] - IMAGENET_MEAN[c]) / IMAGENET_STD[c]\n\n        x = torch.from_numpy(img_r.transpose(2, 0, 1)).unsqueeze(0).to(DEVICE)\n        x_f = torch.flip(x, dims=[3])\n\n        # --- LOGIT ENSEMBLE + H-FLIP ---\n        lu = (unetpp(x) + torch.flip(unetpp(x_f), [3])) / 2\n        ld = (deeplab(x) + torch.flip(deeplab(x_f), [3])) / 2\n\n        prob = torch.sigmoid(W_U * lu + W_D * ld)[0, 0].cpu().numpy()\n        prob = cv2.resize(prob, (w0, h0), interpolation=cv2.INTER_LINEAR)\n\n        # ---- VERY LIGHT SMOOTH (OPTIONAL) ----\n        prob = cv2.GaussianBlur(prob, (3, 3), 0)\n\n        # ---- SMART THRESHOLD (ANTI-ZONK) ----\n        thr = BASE_THR\n        m, mx = prob.mean(), prob.max()\n\n        if m < 0.012 and mx < 0.30:      # clean road\n            thr += 0.05\n        elif m > 0.07:                   # heavy damage\n            thr -= 0.03\n\n        thr = np.clip(thr, 0.30, 0.50)\n\n        # ---- POST PROCESS ----\n        pred = quantile_area_filter(prob, thr, AREA_Q)\n\n        rle = \"\" if pred.sum() == 0 else encode_rle(pred)\n        records.append({\"ImageId\": img_name, \"rle\": rle})\n\n# -----------------------------\n# BUILD SUBMISSION\n# -----------------------------\ndf_sub = pd.DataFrame(records)\ndf_sample = pd.read_csv(SAMPLE_SUB)\ndf_sub = df_sub[df_sample.columns.tolist()]\n\nOUT_SUB = \"/kaggle/working/submission.csv\"\ndf_sub.to_csv(OUT_SUB, index=False)\n\nprint(\"\\n[STAGE 5 COMPLETE — SUBMISSION READY]\")\nprint(\"Saved:\", OUT_SUB)\nprint(\"Rows:\", len(df_sub))\nprint(\"Empty masks:\", (df_sub[\"rle\"] == \"\").sum())\nprint(df_sub.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-07T06:51:13.929578Z","iopub.execute_input":"2026-02-07T06:51:13.929870Z","iopub.status.idle":"2026-02-07T06:52:18.983330Z","shell.execute_reply.started":"2026-02-07T06:51:13.929845Z","shell.execute_reply":"2026-02-07T06:52:18.982719Z"}},"outputs":[{"name":"stdout","text":"[CONFIG]\nWeights: 0.8326118853484784 0.1673881146515216\nBaseThr: 0.3211078822346584 Area_q: 0.06676823765872665\n[INFO] Models loaded\n[INFO] Test images: 295\n","output_type":"stream"},{"name":"stderr","text":"Final Inference: 100%|██████████| 295/295 [01:03<00:00,  4.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[STAGE 5 COMPLETE — SUBMISSION READY]\nSaved: /kaggle/working/submission.csv\nRows: 295\nEmpty masks: 0\n        ImageId                                                rle\n0  test_001.jpg  76684 6 76692 3 76983 14 77003 2 77281 17 7730...\n1  test_002.jpg  107663 1 108381 4 109100 6 109820 7 110540 7 1...\n2  test_003.jpg  381115 6 383379 4 383409 9 385672 11 385702 13...\n3  test_004.jpg  16622 2 16921 3 17220 5 17520 6 17819 7 18119 ...\n4  test_005.jpg  50229 6 50526 11 50824 14 51123 17 51423 18 51...\n","output_type":"stream"}],"execution_count":10}]}