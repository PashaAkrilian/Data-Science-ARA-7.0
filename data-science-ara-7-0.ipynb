{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dae41fb",
   "metadata": {
    "papermill": {
     "duration": 0.003262,
     "end_time": "2026-02-08T00:34:30.536419",
     "exception": false,
     "start_time": "2026-02-08T00:34:30.533157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Understanding & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f47ec43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:34:30.542872Z",
     "iopub.status.busy": "2026-02-08T00:34:30.542616Z",
     "iopub.status.idle": "2026-02-08T00:34:51.604324Z",
     "shell.execute_reply": "2026-02-08T00:34:51.603527Z"
    },
    "papermill": {
     "duration": 21.067197,
     "end_time": "2026-02-08T00:34:51.606290",
     "exception": false,
     "start_time": "2026-02-08T00:34:30.539093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Paired samples: 498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE 1 Analysis: 100%|██████████| 498/498 [00:18<00:00, 26.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DICE CEILING — OBJECT-AWARE]\n",
      "optimistic  : Dice ≤ 0.975\n",
      "realistic   : Dice ≤ 0.901\n",
      "pessimistic : Dice ≤ 0.750\n",
      "\n",
      "[STAGE 1 COMPLETE — 0.80-READY]\n",
      "✓ Object-aware Dice ceiling (REALISTIC)\n",
      "✓ Difficulty score stabilized\n",
      "✓ Safe sampling priors (no over-forcing)\n",
      "✓ Directly feeds Stage 3 curriculum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 1 — Data Understanding & Preparation (REVISION FULL)\n",
    "# OBJECT-AWARE · DICE-REALISTIC · TRAINING-DRIVEN\n",
    "#\n",
    "# OUTPUT:\n",
    "# - stage1_profile.parquet\n",
    "# - stage1_priors.json\n",
    "#\n",
    "# FEEDS:\n",
    "# - Stage 3 sampling\n",
    "# - loss weighting\n",
    "# - threshold & postprocess policy\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re, json\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "TRAIN_IMG_DIR = DATA_ROOT / \"train/images\"\n",
    "TRAIN_MASK_DIR = DATA_ROOT / \"train/mask\"\n",
    "\n",
    "ART_DIR = Path(\"/kaggle/working/artifacts\")\n",
    "ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# UTIL\n",
    "# -----------------------------\n",
    "def extract_index(name: str):\n",
    "    m = re.search(r\"(\\d+)\", name)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "# -----------------------------\n",
    "# PAIR IMAGE–MASK\n",
    "# -----------------------------\n",
    "pairs = []\n",
    "mask_index = {extract_index(p.stem): p for p in TRAIN_MASK_DIR.iterdir()}\n",
    "\n",
    "for img in TRAIN_IMG_DIR.iterdir():\n",
    "    idx = extract_index(img.stem)\n",
    "    if idx in mask_index:\n",
    "        pairs.append((img, mask_index[idx], idx))\n",
    "\n",
    "print(f\"[INFO] Paired samples: {len(pairs)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# ANALYSIS\n",
    "# -----------------------------\n",
    "records = []\n",
    "all_component_areas = []\n",
    "all_component_counts = []\n",
    "\n",
    "for img_p, mask_p, idx in tqdm(pairs, desc=\"STAGE 1 Analysis\"):\n",
    "    mask = cv2.imread(str(mask_p), cv2.IMREAD_GRAYSCALE)\n",
    "    h, w = mask.shape\n",
    "    total_px = h * w\n",
    "\n",
    "    bin_mask = (mask == 255).astype(np.uint8)\n",
    "    fg_px = bin_mask.sum()\n",
    "    area_ratio = fg_px / total_px\n",
    "\n",
    "    num, labels, stats, centroids = cv2.connectedComponentsWithStats(bin_mask, 8)\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA] if num > 1 else np.array([])\n",
    "    centers = centroids[1:] if num > 1 else np.empty((0,2))\n",
    "\n",
    "    # ---- object statistics ----\n",
    "    n_comp = len(areas)\n",
    "    min_area = int(areas.min()) if n_comp else 0\n",
    "    mean_area = float(areas.mean()) if n_comp else 0.0\n",
    "\n",
    "    # ---- boundary complexity ----\n",
    "    edges = cv2.Canny(bin_mask * 255, 50, 150)\n",
    "    boundary_ratio = edges.sum() / max(fg_px, 1)\n",
    "\n",
    "    # ---- fragmentation ----\n",
    "    mean_dist = 0.0\n",
    "    if len(centers) > 1:\n",
    "        d = cdist(centers, centers)\n",
    "        mean_dist = float(d[d > 0].mean())\n",
    "\n",
    "    # ---- OBJECT-AWARE difficulty (0–1) ----\n",
    "    difficulty = (\n",
    "        0.40 * (area_ratio < 0.008) +\n",
    "        0.30 * (n_comp >= 3) +\n",
    "        0.20 * (boundary_ratio > 0.10) +\n",
    "        0.10 * (mean_dist > 120)\n",
    "    )\n",
    "    difficulty = float(np.clip(difficulty, 0, 1))\n",
    "\n",
    "    all_component_areas.extend(areas.tolist())\n",
    "    all_component_counts.append(n_comp)\n",
    "\n",
    "    records.append({\n",
    "        \"image_id\": idx,\n",
    "        \"image\": img_p.name,\n",
    "        \"has_pothole\": int(fg_px > 0),\n",
    "        \"area_ratio\": area_ratio,\n",
    "        \"num_components\": n_comp,\n",
    "        \"min_component_px\": min_area,\n",
    "        \"mean_component_px\": mean_area,\n",
    "        \"boundary_ratio\": boundary_ratio,\n",
    "        \"mean_component_dist\": mean_dist,\n",
    "        \"difficulty_score\": difficulty\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# ============================================================\n",
    "# OBJECT-AWARE DICE CEILING (REALISTIC)\n",
    "# ============================================================\n",
    "comp = pd.Series(all_component_areas)\n",
    "\n",
    "q = comp.quantile([0.05, 0.10, 0.25]).astype(int)\n",
    "\n",
    "# assume model misses smallest K% objects entirely\n",
    "miss_ratio = {\n",
    "    \"5%\": comp[comp < q.loc[0.05]].count() / len(comp),\n",
    "    \"10%\": comp[comp < q.loc[0.10]].count() / len(comp),\n",
    "    \"25%\": comp[comp < q.loc[0.25]].count() / len(comp),\n",
    "}\n",
    "\n",
    "# empirical ceiling assumption\n",
    "dice_ceiling = {\n",
    "    \"optimistic\": 1.0 - miss_ratio[\"5%\"] * 0.5,\n",
    "    \"realistic\": 1.0 - miss_ratio[\"10%\"],\n",
    "    \"pessimistic\": 1.0 - miss_ratio[\"25%\"],\n",
    "}\n",
    "\n",
    "print(\"\\n[DICE CEILING — OBJECT-AWARE]\")\n",
    "for k, v in dice_ceiling.items():\n",
    "    print(f\"{k:<12}: Dice ≤ {v:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING PRIORS (SAFE & EFFECTIVE)\n",
    "# ============================================================\n",
    "df[\"sampling_weight\"] = (\n",
    "    1.0 +\n",
    "    1.2 * df[\"difficulty_score\"] +\n",
    "    0.3 * (df[\"has_pothole\"] == 0)\n",
    ").clip(0.7, 2.2)\n",
    "\n",
    "priors = {\n",
    "    \"dice_ceiling\": dice_ceiling,\n",
    "    \"min_area_px\": {\n",
    "        \"aggressive\": int(q.loc[0.05]),\n",
    "        \"balanced\": int(q.loc[0.10]),\n",
    "        \"safe\": int(q.loc[0.25]),\n",
    "    },\n",
    "    \"sampling\": {\n",
    "        \"difficulty_boost\": 1.2,\n",
    "        \"empty_boost\": 0.3,\n",
    "        \"max_weight\": 2.2\n",
    "    },\n",
    "    \"object_ratio_target\": [0.65, 0.80],\n",
    "    \"threshold\": {\n",
    "        \"search_range\": [0.30, 0.45],\n",
    "        \"default_start\": 0.35\n",
    "    },\n",
    "    \"loss_policy\": {\n",
    "        \"phase1\": \"dice + focal(alpha=0.7)\",\n",
    "        \"phase2\": \"dice + focal(0.3) + boundary(0.05)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# EXPORT\n",
    "# ============================================================\n",
    "df.to_parquet(ART_DIR / \"stage1_profile.parquet\", index=False)\n",
    "\n",
    "with open(ART_DIR / \"stage1_priors.json\", \"w\") as f:\n",
    "    json.dump(priors, f, indent=2)\n",
    "\n",
    "print(\"\\n[STAGE 1 COMPLETE — 0.80-READY]\")\n",
    "print(\"✓ Object-aware Dice ceiling (REALISTIC)\")\n",
    "print(\"✓ Difficulty score stabilized\")\n",
    "print(\"✓ Safe sampling priors (no over-forcing)\")\n",
    "print(\"✓ Directly feeds Stage 3 curriculum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e4627",
   "metadata": {
    "papermill": {
     "duration": 0.005928,
     "end_time": "2026-02-08T00:34:51.618684",
     "exception": false,
     "start_time": "2026-02-08T00:34:51.612756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing & Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7455ab50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:34:51.631940Z",
     "iopub.status.busy": "2026-02-08T00:34:51.631405Z",
     "iopub.status.idle": "2026-02-08T00:34:57.367204Z",
     "shell.execute_reply": "2026-02-08T00:34:57.366377Z"
    },
    "papermill": {
     "duration": 5.744161,
     "end_time": "2026-02-08T00:34:57.368735",
     "exception": false,
     "start_time": "2026-02-08T00:34:51.624574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STAGE 2 FINAL — CONVNEXT READY]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 2 — Preprocessing & Data Augmentation (FINAL · CONVNEXT)\n",
    "# ============================================================\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN TRANSFORM — 512x512 (CONVNEXT-SAFE)\n",
    "# ============================================================\n",
    "train_transform_512 = A.Compose(\n",
    "    [\n",
    "        # -------------------------\n",
    "        # FIXED RESOLUTION\n",
    "        # -------------------------\n",
    "        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n",
    "\n",
    "        # -------------------------\n",
    "        # GEOMETRY — ULTRA STABLE\n",
    "        # -------------------------\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        A.Affine(\n",
    "            scale=(0.995, 1.025),          # ⬅️ lebih sempit\n",
    "            translate_percent=(0.0, 0.015),\n",
    "            rotate=(-1.0, 1.0),\n",
    "            shear=(-0.8, 0.8),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            p=0.25,\n",
    "        ),\n",
    "\n",
    "        # -------------------------\n",
    "        # SHAPE CONTINUITY (SINGLE ONLY)\n",
    "        # -------------------------\n",
    "        A.GridDistortion(\n",
    "            num_steps=5,\n",
    "            distort_limit=0.010,\n",
    "            border_mode=cv2.BORDER_REFLECT_101,\n",
    "            p=0.06,\n",
    "        ),\n",
    "\n",
    "        # -------------------------\n",
    "        # CONFUSER-AWARE PHOTOMETRIC\n",
    "        # -------------------------\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.14,\n",
    "                    contrast_limit=0.16,\n",
    "                ),\n",
    "                A.RandomGamma(gamma_limit=(92, 110)),\n",
    "            ],\n",
    "            p=0.50,\n",
    "        ),\n",
    "\n",
    "        A.HueSaturationValue(\n",
    "            hue_shift_limit=3,\n",
    "            sat_shift_limit=6,\n",
    "            val_shift_limit=3,\n",
    "            p=0.20,\n",
    "        ),\n",
    "\n",
    "        # -------------------------\n",
    "        # SHADOW — REDUCED (IMPORTANT)\n",
    "        # -------------------------\n",
    "        A.RandomShadow(\n",
    "            shadow_roi=(0, 0.40, 1, 1),\n",
    "            shadow_dimension=4,\n",
    "            p=0.10,   # ⬅️ DITURUNKAN\n",
    "        ),\n",
    "\n",
    "        # -------------------------\n",
    "        # TEXTURE NOISE — VERY MILD\n",
    "        # -------------------------\n",
    "        A.GaussNoise(std_range=(0.015, 0.045), p=0.08),\n",
    "\n",
    "        # -------------------------\n",
    "        # NORMALIZE\n",
    "        # -------------------------\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    additional_targets={\"mask\": \"mask\"},\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# VALID / TEST (UNCHANGED)\n",
    "# ============================================================\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(512, 512),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    additional_targets={\"mask\": \"mask\"},\n",
    ")\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(512, 512),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"[STAGE 2 FINAL — CONVNEXT READY]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152c819",
   "metadata": {
    "papermill": {
     "duration": 0.006075,
     "end_time": "2026-02-08T00:34:57.381047",
     "exception": false,
     "start_time": "2026-02-08T00:34:57.374972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Construction & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699661a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:34:57.394979Z",
     "iopub.status.busy": "2026-02-08T00:34:57.394254Z",
     "iopub.status.idle": "2026-02-08T00:35:08.536918Z",
     "shell.execute_reply": "2026-02-08T00:35:08.536110Z"
    },
    "papermill": {
     "duration": 11.151267,
     "end_time": "2026-02-08T00:35:08.538691",
     "exception": false,
     "start_time": "2026-02-08T00:34:57.387424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q segmentation-models-pytorch==0.3.3 timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d5044a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:35:08.553441Z",
     "iopub.status.busy": "2026-02-08T00:35:08.553166Z",
     "iopub.status.idle": "2026-02-08T00:53:39.137462Z",
     "shell.execute_reply": "2026-02-08T00:53:39.136604Z"
    },
    "papermill": {
     "duration": 1110.707351,
     "end_time": "2026-02-08T00:53:39.252707",
     "exception": false,
     "start_time": "2026-02-08T00:35:08.545356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "[INFO] train: 423 val: 75\n",
      "Downloading: \"https://github.com/huggingface/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b4-74ee3bed.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b4-74ee3bed.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74.4M/74.4M [00:00<00:00, 114MB/s]\n",
      "/tmp/ipykernel_24/2071541751.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== TRAINING STABLE =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/106 [00:00<?, ?it/s]/tmp/ipykernel_24/2071541751.py:163: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.2313 @ thr=0.50\n",
      "Epoch 01 | ValDice 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.3294 @ thr=0.50\n",
      "Epoch 02 | ValDice 0.3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.4342 @ thr=0.50\n",
      "Epoch 03 | ValDice 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.4663 @ thr=0.50\n",
      "Epoch 04 | ValDice 0.4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.5017 @ thr=0.50\n",
      "Epoch 05 | ValDice 0.5017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.5333 @ thr=0.50\n",
      "Epoch 06 | ValDice 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.5525 @ thr=0.50\n",
      "Epoch 07 | ValDice 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | ValDice 0.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.5781 @ thr=0.50\n",
      "Epoch 09 | ValDice 0.5781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.5800 @ thr=0.50\n",
      "Epoch 10 | ValDice 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | ValDice 0.5727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.5804 @ thr=0.50\n",
      "Epoch 12 | ValDice 0.5804\n",
      ">> Unfreeze encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.5898 @ thr=0.50\n",
      "Epoch 13 | ValDice 0.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.5949 @ thr=0.50\n",
      "Epoch 14 | ValDice 0.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.6223 @ thr=0.50\n",
      "Epoch 15 | ValDice 0.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | ValDice 0.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.6276 @ thr=0.50\n",
      "Epoch 17 | ValDice 0.6276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | ValDice 0.6147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | ValDice 0.6233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | ValDice 0.6205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | ValDice 0.6235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | ValDice 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.6358 @ thr=0.50\n",
      "Epoch 23 | ValDice 0.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | ValDice 0.6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | ValDice 0.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | ValDice 0.6261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> BEST | Dice 0.6371 @ thr=0.50\n",
      "Epoch 27 | ValDice 0.6371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | ValDice 0.6370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | ValDice 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | ValDice 0.6264\n",
      "\n",
      "[DONE] BEST DICE 0.6371\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 3 — UNET++ + TIMM-EFFICIENTNET-B4\n",
    "# STABLE · NO COLLAPSE · BUG-FREE\n",
    "# ============================================================\n",
    "\n",
    "import os, re, random, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "IMG_SIZE = 512\n",
    "BATCH = 4\n",
    "ACCUM = 3                 # effective batch = 12\n",
    "EPOCHS = 30\n",
    "FREEZE_EPOCHS = 12\n",
    "LR = 5e-5                 # STABLE LR\n",
    "WD = 1e-4\n",
    "VAL_RATIO = 0.15\n",
    "THR_RANGE = np.linspace(0.25, 0.50, 11)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# DATA\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "IMG_DIR = DATA_ROOT / \"train/images\"\n",
    "MSK_DIR = DATA_ROOT / \"train/mask\"\n",
    "\n",
    "pairs = []\n",
    "for img in IMG_DIR.iterdir():\n",
    "    idx = re.search(r\"(\\d+)\", img.name).group(1)\n",
    "    m = MSK_DIR / f\"mask_{idx}.png\"\n",
    "    if m.exists():\n",
    "        pairs.append((str(img), str(m)))\n",
    "\n",
    "df = pd.DataFrame(pairs, columns=[\"img\", \"mask\"])\n",
    "df_tr, df_va = train_test_split(df, test_size=VAL_RATIO, random_state=SEED)\n",
    "\n",
    "print(\"[INFO] train:\", len(df_tr), \"val:\", len(df_va))\n",
    "\n",
    "# -----------------------------\n",
    "# DATASET (FIXED)\n",
    "# -----------------------------\n",
    "class DS(Dataset):\n",
    "    def __init__(self, df, tfm):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tfm = tfm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img_path = self.df.loc[i, \"img\"]\n",
    "        msk_path = self.df.loc[i, \"mask\"]\n",
    "\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        msk = (cv2.imread(msk_path, 0) == 255).astype(\"float32\")\n",
    "\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        msk = cv2.resize(msk, (IMG_SIZE, IMG_SIZE), cv2.INTER_NEAREST)\n",
    "\n",
    "        out = self.tfm(image=img, mask=msk)\n",
    "        return out[\"image\"], out[\"mask\"].unsqueeze(0)\n",
    "\n",
    "# -----------------------------\n",
    "# LOSSES\n",
    "# -----------------------------\n",
    "def dice_loss(l, t):\n",
    "    p = torch.sigmoid(l)\n",
    "    inter = (p * t).sum()\n",
    "    return 1 - (2*inter + 1e-7)/(p.sum() + t.sum() + 1e-7)\n",
    "\n",
    "def focal_loss(l, t):\n",
    "    return F.binary_cross_entropy_with_logits(l, t)\n",
    "\n",
    "def boundary_loss(l, t):\n",
    "    p = torch.sigmoid(l)\n",
    "    k = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]],\n",
    "                     device=l.device).float().view(1,1,3,3)\n",
    "    ep = F.conv2d(p, k, padding=1).abs()\n",
    "    et = F.conv2d(t, k, padding=1).abs()\n",
    "    return F.l1_loss(ep, et)\n",
    "\n",
    "def criterion(l, t, epoch):\n",
    "    base = dice_loss(l,t) + 0.5*focal_loss(l,t)\n",
    "    if epoch >= 10:\n",
    "        return base + 0.1*boundary_loss(l,t)\n",
    "    return base\n",
    "\n",
    "# -----------------------------\n",
    "# METRIC\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def dice_eval(p, g, thr):\n",
    "    if g.sum()==0:\n",
    "        return 1.0 if p.max()<thr else 0.0\n",
    "    b = (p > thr).float()\n",
    "    inter = (b*g).sum()\n",
    "    return float((2*inter + 1e-7)/(b.sum()+g.sum()+1e-7))\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL\n",
    "# -----------------------------\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"timm-efficientnet-b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "for p in model.encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "opt = AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "sch = CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "scaler = GradScaler()\n",
    "\n",
    "tr_ds = DS(df_tr, train_transform_512)\n",
    "va_ds = DS(df_va, valid_transform)\n",
    "\n",
    "tr_ld = DataLoader(tr_ds, BATCH, shuffle=True, num_workers=2, pin_memory=True)\n",
    "va_ld = DataLoader(va_ds, 1, shuffle=False)\n",
    "\n",
    "best = 0.0\n",
    "best_thr = 0.4\n",
    "\n",
    "print(\"\\n===== TRAINING STABLE =====\")\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "\n",
    "    if ep == FREEZE_EPOCHS+1:\n",
    "        print(\">> Unfreeze encoder\")\n",
    "        for p in model.encoder.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    for i,(x,y) in enumerate(tqdm(tr_ld, leave=False)):\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        with autocast():\n",
    "            l = model(x)\n",
    "            loss = criterion(l,y,ep)/ACCUM\n",
    "        scaler.scale(loss).backward()\n",
    "        if (i+1)%ACCUM==0:\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            opt.zero_grad()\n",
    "\n",
    "    sch.step()\n",
    "\n",
    "    model.eval()\n",
    "    scores = {t:[] for t in THR_RANGE}\n",
    "    with torch.no_grad():\n",
    "        for x,y in va_ld:\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            p = torch.sigmoid(model(x))\n",
    "            for t in THR_RANGE:\n",
    "                scores[t].append(dice_eval(p,y,t))\n",
    "\n",
    "    cur_thr, cur_val = max(\n",
    "        ((t,np.mean(v)) for t,v in scores.items()),\n",
    "        key=lambda x:x[1]\n",
    "    )\n",
    "\n",
    "    if cur_val > best:\n",
    "        best = cur_val\n",
    "        best_thr = cur_thr\n",
    "        torch.save(model.state_dict(), \"/kaggle/working/best_unetpp.pt\")\n",
    "        print(f\">> BEST | Dice {best:.4f} @ thr={best_thr:.2f}\")\n",
    "\n",
    "    print(f\"Epoch {ep:02d} | ValDice {cur_val:.4f}\")\n",
    "\n",
    "print(f\"\\n[DONE] BEST DICE {best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7f19a",
   "metadata": {
    "papermill": {
     "duration": 0.108312,
     "end_time": "2026-02-08T00:53:39.475934",
     "exception": false,
     "start_time": "2026-02-08T00:53:39.367622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimization, Validation & Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cea2190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:53:39.697448Z",
     "iopub.status.busy": "2026-02-08T00:53:39.696646Z",
     "iopub.status.idle": "2026-02-08T00:56:53.283591Z",
     "shell.execute_reply": "2026-02-08T00:56:53.282786Z"
    },
    "papermill": {
     "duration": 193.882408,
     "end_time": "2026-02-08T00:56:53.468663",
     "exception": false,
     "start_time": "2026-02-08T00:53:39.586255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "[INFO] Validation samples: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 00:53:43,999] A new study created in memory with name: no-name-13dce3d1-6d72-4b28-aa77-349a2ec4c870\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25afedb9dd3446cdab66b7dd3dfc34ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2026-02-08 00:53:50,450] Trial 0 finished with value: 0.632981106837851 and parameters: {'thr': 0.45719634761420547, 'min_area': 100, 'empty_thr': 0.02889349300028172}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:53:56,681] Trial 1 finished with value: 0.6232572641224685 and parameters: {'thr': 0.37032090287276687, 'min_area': 200, 'empty_thr': 0.019192367288616372}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:54:02,933] Trial 2 finished with value: 0.6328215224604353 and parameters: {'thr': 0.45447017500268205, 'min_area': 160, 'empty_thr': 0.017990198822264252}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:54:09,161] Trial 3 finished with value: 0.6299471191116696 and parameters: {'thr': 0.42414452264475877, 'min_area': 160, 'empty_thr': 0.022567771083660808}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:54:15,543] Trial 4 finished with value: 0.6308345195201548 and parameters: {'thr': 0.43383765928640416, 'min_area': 180, 'empty_thr': 0.024758169795930075}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:54:21,928] Trial 5 finished with value: 0.6265986647672052 and parameters: {'thr': 0.3978717103004689, 'min_area': 140, 'empty_thr': 0.02777451277059835}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:54:28,240] Trial 6 finished with value: 0.6216969035000468 and parameters: {'thr': 0.36552523012099664, 'min_area': 180, 'empty_thr': 0.02287634418962063}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:54:34,490] Trial 7 finished with value: 0.6216659911994123 and parameters: {'thr': 0.36626629126905746, 'min_area': 180, 'empty_thr': 0.017859800498718808}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:54:40,750] Trial 8 finished with value: 0.6275853732564881 and parameters: {'thr': 0.4040574030892531, 'min_area': 180, 'empty_thr': 0.02098700962810064}. Best is trial 0 with value: 0.632981106837851.\n",
      "[I 2026-02-08 00:54:46,997] Trial 9 finished with value: 0.6340002593370941 and parameters: {'thr': 0.46424964387049167, 'min_area': 200, 'empty_thr': 0.018590473307433457}. Best is trial 9 with value: 0.6340002593370941.\n",
      "[I 2026-02-08 00:54:53,250] Trial 10 finished with value: 0.6351301775889934 and parameters: {'thr': 0.4794650820894594, 'min_area': 120, 'empty_thr': 0.033089404656960406}. Best is trial 10 with value: 0.6351301775889934.\n",
      "[I 2026-02-08 00:54:59,483] Trial 11 finished with value: 0.6349573566399563 and parameters: {'thr': 0.47779230515043014, 'min_area': 120, 'empty_thr': 0.03368804140769875}. Best is trial 10 with value: 0.6351301775889934.\n",
      "[I 2026-02-08 00:55:05,907] Trial 12 finished with value: 0.6349327817072895 and parameters: {'thr': 0.47747877173532793, 'min_area': 120, 'empty_thr': 0.03452206413999987}. Best is trial 10 with value: 0.6351301775889934.\n",
      "[I 2026-02-08 00:55:12,240] Trial 13 finished with value: 0.6349801734543303 and parameters: {'thr': 0.47891886421090185, 'min_area': 100, 'empty_thr': 0.03488734702909541}. Best is trial 10 with value: 0.6351301775889934.\n",
      "[I 2026-02-08 00:55:18,639] Trial 14 finished with value: 0.6313652024623261 and parameters: {'thr': 0.4399394427709924, 'min_area': 100, 'empty_thr': 0.031247952020638924}. Best is trial 10 with value: 0.6351301775889934.\n",
      "[I 2026-02-08 00:55:25,011] Trial 15 finished with value: 0.6351608688158508 and parameters: {'thr': 0.4797183396856195, 'min_area': 120, 'empty_thr': 0.03142493728133388}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:55:31,358] Trial 16 finished with value: 0.6319978505884923 and parameters: {'thr': 0.4470011082187722, 'min_area': 120, 'empty_thr': 0.03095397752481702}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:55:37,670] Trial 17 finished with value: 0.6283699061128154 and parameters: {'thr': 0.41480952065720095, 'min_area': 140, 'empty_thr': 0.027944786159591666}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:55:44,044] Trial 18 finished with value: 0.6250786856849575 and parameters: {'thr': 0.38619426721373235, 'min_area': 120, 'empty_thr': 0.032165975505622696}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:55:50,287] Trial 19 finished with value: 0.6338589892360857 and parameters: {'thr': 0.4641502568066536, 'min_area': 140, 'empty_thr': 0.015153315476116688}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:55:56,545] Trial 20 finished with value: 0.6195013345911885 and parameters: {'thr': 0.3526222932442227, 'min_area': 120, 'empty_thr': 0.0303922062915513}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:02,756] Trial 21 finished with value: 0.6349777582465088 and parameters: {'thr': 0.4788492894775918, 'min_area': 100, 'empty_thr': 0.03315893990098113}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:08,974] Trial 22 finished with value: 0.6336839576237007 and parameters: {'thr': 0.4655694500256217, 'min_area': 100, 'empty_thr': 0.03444506691282809}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:15,193] Trial 23 finished with value: 0.6342907372359019 and parameters: {'thr': 0.47155743862600746, 'min_area': 100, 'empty_thr': 0.029919363914311714}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:21,571] Trial 24 finished with value: 0.6319834996542201 and parameters: {'thr': 0.4456730968718788, 'min_area': 120, 'empty_thr': 0.026110805194826295}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:27,973] Trial 25 finished with value: 0.632839944729599 and parameters: {'thr': 0.4554032935302406, 'min_area': 140, 'empty_thr': 0.032584651377435055}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:34,361] Trial 26 finished with value: 0.6304061785986806 and parameters: {'thr': 0.4294499023238141, 'min_area': 100, 'empty_thr': 0.03475401552548957}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:40,707] Trial 27 finished with value: 0.6342915546750986 and parameters: {'thr': 0.47082430291375865, 'min_area': 120, 'empty_thr': 0.03250959272173482}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:46,926] Trial 28 finished with value: 0.6350823121477113 and parameters: {'thr': 0.4799789908532121, 'min_area': 140, 'empty_thr': 0.029259014676297955}. Best is trial 15 with value: 0.6351608688158508.\n",
      "[I 2026-02-08 00:56:53,277] Trial 29 finished with value: 0.6331844310391826 and parameters: {'thr': 0.45860304815569103, 'min_area': 160, 'empty_thr': 0.029026359155927123}. Best is trial 15 with value: 0.6351608688158508.\n",
      "\n",
      "[STAGE 4 BEST CONFIG]\n",
      "thr: 0.4797183396856195\n",
      "min_area: 120\n",
      "empty_thr: 0.03142493728133388\n",
      "\n",
      "[STAGE 4 COMPLETE — READY FOR STAGE 5]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 4 — THRESHOLD & POSTPROCESS OPTIMIZATION (FINAL)\n",
    "# MATCH STAGE 3 · SAM-FRIENDLY · 80+ READY\n",
    "# ============================================================\n",
    "\n",
    "!pip install -q optuna segmentation-models-pytorch\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 512\n",
    "VAL_RATIO = 0.15\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# -----------------------------\n",
    "# DATA\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "IMG_DIR = DATA_ROOT / \"train/images\"\n",
    "MSK_DIR = DATA_ROOT / \"train/mask\"\n",
    "\n",
    "pairs = []\n",
    "for img in IMG_DIR.iterdir():\n",
    "    idx = img.stem.split(\"_\")[-1]\n",
    "    m = MSK_DIR / f\"mask_{idx}.png\"\n",
    "    if m.exists():\n",
    "        pairs.append((str(img), str(m)))\n",
    "\n",
    "pairs = np.array(pairs, dtype=object)\n",
    "_, val_pairs = train_test_split(pairs, test_size=VAL_RATIO, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# DATASET (MATCH STAGE 3)\n",
    "# -----------------------------\n",
    "class ValDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = cv2.cvtColor(cv2.imread(self.pairs[i][0]), cv2.COLOR_BGR2RGB)\n",
    "        gt  = (cv2.imread(self.pairs[i][1], 0) == 255).astype(np.uint8)\n",
    "\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        gt  = cv2.resize(gt, (IMG_SIZE, IMG_SIZE), cv2.INTER_NEAREST)\n",
    "\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img[...,0] = (img[...,0] - 0.485) / 0.229\n",
    "        img[...,1] = (img[...,1] - 0.456) / 0.224\n",
    "        img[...,2] = (img[...,2] - 0.406) / 0.225\n",
    "\n",
    "        img = torch.from_numpy(img.transpose(2,0,1))\n",
    "        gt  = torch.from_numpy(gt)\n",
    "\n",
    "        return img, gt\n",
    "\n",
    "val_loader = DataLoader(ValDataset(val_pairs), batch_size=1, shuffle=False)\n",
    "print(\"[INFO] Validation samples:\", len(val_pairs))\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD MODEL (SAME AS STAGE 3)\n",
    "# -----------------------------\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"timm-efficientnet-b4\",\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/best_unetpp.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# METRIC\n",
    "# -----------------------------\n",
    "def dice_empty_aware(pred, gt, eps=1e-7):\n",
    "    if gt.sum() == 0:\n",
    "        return 1.0 if pred.sum() == 0 else 0.0\n",
    "    inter = (pred * gt).sum()\n",
    "    return float((2*inter + eps) / (pred.sum() + gt.sum() + eps))\n",
    "\n",
    "# -----------------------------\n",
    "# POSTPROCESS\n",
    "# -----------------------------\n",
    "def postprocess(prob, thr, min_area):\n",
    "    binm = (prob > thr).astype(np.uint8)\n",
    "    binm = cv2.morphologyEx(binm, cv2.MORPH_CLOSE, np.ones((3,3), np.uint8))\n",
    "\n",
    "    n, lbl, stat, _ = cv2.connectedComponentsWithStats(binm, 8)\n",
    "    out = np.zeros_like(binm)\n",
    "    for i in range(1, n):\n",
    "        if stat[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            out[lbl == i] = 1\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# OPTUNA OBJECTIVE (FINAL)\n",
    "# -----------------------------\n",
    "def objective(trial):\n",
    "\n",
    "    thr = trial.suggest_float(\"thr\", 0.35, 0.48)\n",
    "    min_area = trial.suggest_int(\"min_area\", 100, 200, step=20)\n",
    "    empty_thr = trial.suggest_float(\"empty_thr\", 0.015, 0.035)\n",
    "\n",
    "    dices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, gt in val_loader:\n",
    "            img = img.to(DEVICE)\n",
    "            gt  = gt.numpy()[0]\n",
    "\n",
    "            logits = model(img)\n",
    "            logits = F.interpolate(\n",
    "                logits, size=(IMG_SIZE, IMG_SIZE),\n",
    "                mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "            prob = torch.sigmoid(logits)[0,0].cpu().numpy()\n",
    "\n",
    "            if prob.max() < empty_thr:\n",
    "                pred = np.zeros_like(gt)\n",
    "            else:\n",
    "                pred = postprocess(prob, thr, min_area)\n",
    "\n",
    "            dices.append(dice_empty_aware(pred, gt))\n",
    "\n",
    "    return float(np.mean(dices))\n",
    "\n",
    "# -----------------------------\n",
    "# RUN OPTUNA\n",
    "# -----------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "OPT_CONFIG = study.best_params\n",
    "print(\"\\n[STAGE 4 BEST CONFIG]\")\n",
    "for k,v in OPT_CONFIG.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\n[STAGE 4 COMPLETE — READY FOR STAGE 5]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2debc20",
   "metadata": {
    "papermill": {
     "duration": 0.109692,
     "end_time": "2026-02-08T00:56:53.689222",
     "exception": false,
     "start_time": "2026-02-08T00:56:53.579530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference, Encoding & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be255f07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T00:56:53.913572Z",
     "iopub.status.busy": "2026-02-08T00:56:53.912880Z",
     "iopub.status.idle": "2026-02-08T00:57:15.456451Z",
     "shell.execute_reply": "2026-02-08T00:57:15.455509Z"
    },
    "papermill": {
     "duration": 21.65625,
     "end_time": "2026-02-08T00:57:15.458024",
     "exception": false,
     "start_time": "2026-02-08T00:56:53.801774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "[CONFIG] 0.4797183396856195 120 0.03142493728133388\n",
      "[INFO] UNet++ loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [00:20<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] rows: 295 empty: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_001.jpg</td>\n",
       "      <td>2542 4 2841 6 3140 8 3439 9 3738 11 4038 12 43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_002.jpg</td>\n",
       "      <td>4548 12 5266 16 5986 17 6706 19 7424 26 8144 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_003.jpg</td>\n",
       "      <td>2236217 11 2238512 15 2240807 18 2243102 20 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_004.jpg</td>\n",
       "      <td>7750 5 8043 2 8049 7 8342 3 8349 8 8641 16 894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_005.jpg</td>\n",
       "      <td>41815 1 42115 1 42414 6 42714 6 43014 6 43314 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ImageId                                                rle\n",
       "0  test_001.jpg  2542 4 2841 6 3140 8 3439 9 3738 11 4038 12 43...\n",
       "1  test_002.jpg  4548 12 5266 16 5986 17 6706 19 7424 26 8144 2...\n",
       "2  test_003.jpg  2236217 11 2238512 15 2240807 18 2243102 20 22...\n",
       "3  test_004.jpg  7750 5 8043 2 8049 7 8342 3 8349 8 8641 16 894...\n",
       "4  test_005.jpg  41815 1 42115 1 42414 6 42714 6 43014 6 43314 ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 5 — FINAL INFERENCE (LB-SAFE · 80+ READY)\n",
    "# MATCH STAGE 3 & 4 EXACTLY\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS & DEVICE\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "TEST_IMG_DIR = DATA_ROOT / \"test/images\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD OPT CONFIG\n",
    "# -----------------------------\n",
    "THR        = float(OPT_CONFIG[\"thr\"])\n",
    "MIN_AREA  = int(OPT_CONFIG[\"min_area\"])\n",
    "EMPTY_THR = float(OPT_CONFIG[\"empty_thr\"])\n",
    "\n",
    "print(\"[CONFIG]\", THR, MIN_AREA, EMPTY_THR)\n",
    "\n",
    "# -----------------------------\n",
    "# INFERENCE CONFIG (MATCH STAGE 3)\n",
    "# -----------------------------\n",
    "INPUT_SIZE = 512\n",
    "MEAN = (0.485, 0.456, 0.406)\n",
    "STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD MODEL (SAME AS STAGE 3)\n",
    "# -----------------------------\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"timm-efficientnet-b4\",   # ✅ HARUS SAMA\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ").to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(\"/kaggle/working/best_unetpp.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "print(\"[INFO] UNet++ loaded\")\n",
    "\n",
    "# -----------------------------\n",
    "# RLE ENCODER\n",
    "# -----------------------------\n",
    "def encode_rle(mask):\n",
    "    pixels = mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[0::2]\n",
    "    return \" \".join(str(x) for x in runs)\n",
    "\n",
    "# -----------------------------\n",
    "# POSTPROCESS (SAM-FRIENDLY)\n",
    "# -----------------------------\n",
    "def postprocess(prob):\n",
    "    binm = (prob > THR).astype(np.uint8)\n",
    "\n",
    "    # ONLY light closing — DO NOT OPEN\n",
    "    binm = cv2.morphologyEx(\n",
    "        binm, cv2.MORPH_CLOSE, np.ones((3,3), np.uint8)\n",
    "    )\n",
    "\n",
    "    n, labels, stats, _ = cv2.connectedComponentsWithStats(binm, 8)\n",
    "    out = np.zeros_like(binm)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= MIN_AREA:\n",
    "            out[labels == i] = 1\n",
    "\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# FINAL INFERENCE\n",
    "# -----------------------------\n",
    "records = []\n",
    "test_images = sorted(TEST_IMG_DIR.glob(\"*.jpg\"))\n",
    "assert len(test_images) == 295\n",
    "\n",
    "with torch.no_grad():\n",
    "    for p in tqdm(test_images):\n",
    "        img = cv2.cvtColor(cv2.imread(str(p)), cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        img_r = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE)).astype(np.float32) / 255.0\n",
    "        for c in range(3):\n",
    "            img_r[...,c] = (img_r[...,c] - MEAN[c]) / STD[c]\n",
    "\n",
    "        x = torch.from_numpy(img_r.transpose(2,0,1)).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        # ---- MODEL ----\n",
    "        logits = model(x)\n",
    "        logits = F.interpolate(\n",
    "            logits, size=(INPUT_SIZE, INPUT_SIZE),\n",
    "            mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "        prob = torch.sigmoid(logits)[0,0].cpu().numpy()\n",
    "\n",
    "        prob = cv2.resize(prob, (w, h))\n",
    "\n",
    "        if prob.max() < EMPTY_THR:\n",
    "            pred = np.zeros((h,w), np.uint8)\n",
    "        else:\n",
    "            pred = postprocess(prob)\n",
    "\n",
    "        rle = \"\" if pred.sum() == 0 else encode_rle(pred)\n",
    "        records.append({\"ImageId\": p.name, \"rle\": rle})\n",
    "\n",
    "# -----------------------------\n",
    "# SAVE SUBMISSION\n",
    "# -----------------------------\n",
    "df = pd.DataFrame(records).sort_values(\"ImageId\").reset_index(drop=True)\n",
    "df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "\n",
    "print(\"[DONE] rows:\", len(df), \"empty:\", (df.rle==\"\").sum())\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 15445689,
     "sourceId": 128328,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 100857,
     "modelInstanceId": 76172,
     "sourceId": 90860,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1370.872636,
   "end_time": "2026-02-08T00:57:18.604978",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-08T00:34:27.732342",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "25afedb9dd3446cdab66b7dd3dfc34ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4c1fea37eccc4a4db5da3ea414205595",
        "IPY_MODEL_de6057a41f544c039253c4d2aaecc3fe",
        "IPY_MODEL_a3c064c1128848009f63c6cdc22ec13a"
       ],
       "layout": "IPY_MODEL_d0a63e4d9c704a22892ad9438ee12465",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4c1fea37eccc4a4db5da3ea414205595": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d2bf480385ed44ec8102f46555d141f5",
       "placeholder": "​",
       "style": "IPY_MODEL_fb48ea8b13f8447ba3fa06cfa3e5ef1f",
       "tabbable": null,
       "tooltip": null,
       "value": "Best trial: 15. Best value: 0.635161: 100%"
      }
     },
     "58c20a14ebd141ee99c927867fe9afa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6754e018311343fbb32eaf2889296eed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a3c064c1128848009f63c6cdc22ec13a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ce480f4f2b7d4c3582a74532acb26892",
       "placeholder": "​",
       "style": "IPY_MODEL_cd5c366f1598431faed739814940ba80",
       "tabbable": null,
       "tooltip": null,
       "value": " 30/30 [03:09&lt;00:00,  6.32s/it]"
      }
     },
     "cd5c366f1598431faed739814940ba80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ce480f4f2b7d4c3582a74532acb26892": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0a63e4d9c704a22892ad9438ee12465": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2bf480385ed44ec8102f46555d141f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de6057a41f544c039253c4d2aaecc3fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6754e018311343fbb32eaf2889296eed",
       "max": 30.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_58c20a14ebd141ee99c927867fe9afa7",
       "tabbable": null,
       "tooltip": null,
       "value": 30.0
      }
     },
     "fb48ea8b13f8447ba3fa06cfa3e5ef1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
