{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37b26cb",
   "metadata": {
    "papermill": {
     "duration": 0.003014,
     "end_time": "2026-02-05T04:07:41.190564",
     "exception": false,
     "start_time": "2026-02-05T04:07:41.187550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Understanding & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede35d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T04:07:41.196358Z",
     "iopub.status.busy": "2026-02-05T04:07:41.196061Z",
     "iopub.status.idle": "2026-02-05T04:08:07.736564Z",
     "shell.execute_reply": "2026-02-05T04:08:07.735159Z"
    },
    "papermill": {
     "duration": 26.545623,
     "end_time": "2026-02-05T04:08:07.738318",
     "exception": false,
     "start_time": "2026-02-05T04:07:41.192695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train images : 498\n",
      "[INFO] Train masks  : 498\n",
      "[INFO] Test images  : 295\n",
      "[INFO] Valid image-mask pairs: 498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing dataset: 100%|██████████| 498/498 [00:25<00:00, 19.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INSIGHT] Pothole presence:\n",
      "has_pothole\n",
      "1    498\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[INSIGHT] Pothole area ratio summary:\n",
      "count    498.000000\n",
      "mean       0.134860\n",
      "std        0.128772\n",
      "min        0.000235\n",
      "10%        0.007938\n",
      "25%        0.040943\n",
      "50%        0.091678\n",
      "75%        0.193834\n",
      "90%        0.329536\n",
      "max        0.674005\n",
      "Name: area_ratio, dtype: float64\n",
      "\n",
      "[INSIGHT] Images by pothole size category:\n",
      "area_ratio\n",
      "large         344\n",
      "medium         80\n",
      "very_small     43\n",
      "small          31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[FEASIBILITY CHECK]\n",
      "Images with pothole <1% area: 11.85%\n",
      "Pothole size distribution is favorable for higher Dice\n",
      "\n",
      "[INFO] Final training samples: 498\n",
      "\n",
      "[STAGE 1 COMPLETE — STRATEGIC]\n",
      "Dataset validated\n",
      "Structural bias diagnosed\n",
      "Upper-bound Dice feasibility assessed\n",
      "Ready to proceed with informed strategy to STAGE 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 1 — Data Understanding & Preparation (STRATEGIC REVISION)\n",
    "# Added:\n",
    "# - Pothole area ratio analysis\n",
    "# - Small vs large pothole distribution\n",
    "# - Data bias diagnosis (ALL-positive training set)\n",
    "# - Early feasibility signal for Dice ~0.90\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "TRAIN_IMG_DIR = DATA_ROOT / \"train\" / \"images\"\n",
    "TRAIN_MASK_DIR = DATA_ROOT / \"train\" / \"mask\"\n",
    "TEST_IMG_DIR  = DATA_ROOT / \"test\" / \"images\"\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "\n",
    "# -----------------------------\n",
    "# 1. LOAD FILES\n",
    "# -----------------------------\n",
    "train_images = sorted([p for p in TRAIN_IMG_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\n",
    "train_masks  = sorted([p for p in TRAIN_MASK_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\n",
    "test_images  = sorted([p for p in TEST_IMG_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\n",
    "\n",
    "print(f\"[INFO] Train images : {len(train_images)}\")\n",
    "print(f\"[INFO] Train masks  : {len(train_masks)}\")\n",
    "print(f\"[INFO] Test images  : {len(test_images)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. BUILD MASK INDEX\n",
    "# -----------------------------\n",
    "def extract_index(name: str):\n",
    "    m = re.search(r\"(\\d+)\", name)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "mask_index = {}\n",
    "for m in train_masks:\n",
    "    idx = extract_index(m.stem)\n",
    "    if idx is not None:\n",
    "        mask_index[idx] = m\n",
    "\n",
    "# -----------------------------\n",
    "# 3. PAIR IMAGE–MASK\n",
    "# -----------------------------\n",
    "pairs = []\n",
    "for img in train_images:\n",
    "    idx = extract_index(img.stem)\n",
    "    if idx in mask_index:\n",
    "        pairs.append({\n",
    "            \"image_path\": img,\n",
    "            \"mask_path\": mask_index[idx],\n",
    "            \"id\": idx\n",
    "        })\n",
    "\n",
    "assert len(pairs) > 0, \"No valid image-mask pairs found\"\n",
    "print(f\"[INFO] Valid image-mask pairs: {len(pairs)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. SANITY + STRUCTURAL ANALYSIS\n",
    "# -----------------------------\n",
    "records = []\n",
    "\n",
    "for p in tqdm(pairs, desc=\"Analyzing dataset\"):\n",
    "    img = cv2.imread(str(p[\"image_path\"]))\n",
    "    mask = cv2.imread(str(p[\"mask_path\"]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    assert img is not None\n",
    "    assert mask is not None\n",
    "    assert img.shape[:2] == mask.shape\n",
    "\n",
    "    h, w = mask.shape\n",
    "    total_pixels = h * w\n",
    "    pothole_pixels = (mask == 255).sum()\n",
    "    area_ratio = pothole_pixels / total_pixels\n",
    "\n",
    "    records.append({\n",
    "        \"image\": p[\"image_path\"].name,\n",
    "        \"height\": h,\n",
    "        \"width\": w,\n",
    "        \"pothole_pixels\": pothole_pixels,\n",
    "        \"area_ratio\": area_ratio,\n",
    "        \"has_pothole\": int(pothole_pixels > 0)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. CRITICAL DATASET INSIGHTS\n",
    "# -----------------------------\n",
    "print(\"\\n[INSIGHT] Pothole presence:\")\n",
    "print(df[\"has_pothole\"].value_counts())\n",
    "\n",
    "print(\"\\n[INSIGHT] Pothole area ratio summary:\")\n",
    "print(df[\"area_ratio\"].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]))\n",
    "\n",
    "print(\"\\n[INSIGHT] Images by pothole size category:\")\n",
    "print(pd.cut(\n",
    "    df[\"area_ratio\"],\n",
    "    bins=[0, 0.005, 0.02, 0.05, 1.0],\n",
    "    labels=[\"very_small\", \"small\", \"medium\", \"large\"]\n",
    ").value_counts())\n",
    "\n",
    "# -----------------------------\n",
    "# 6. DATA-DRIVEN FEASIBILITY SIGNAL\n",
    "# -----------------------------\n",
    "small_ratio = (df[\"area_ratio\"] < 0.01).mean()\n",
    "\n",
    "print(\"\\n[FEASIBILITY CHECK]\")\n",
    "print(f\"Images with pothole <1% area: {small_ratio:.2%}\")\n",
    "\n",
    "if small_ratio > 0.5:\n",
    "    print(\"WARNING: Majority potholes are VERY SMALL\")\n",
    "    print(\"Dice ~0.90 will be EXTREMELY difficult due to boundary sensitivity\")\n",
    "else:\n",
    "    print(\"Pothole size distribution is favorable for higher Dice\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. FINAL MANIFEST\n",
    "# -----------------------------\n",
    "df_manifest = pd.DataFrame({\n",
    "    \"image_path\": [str(p[\"image_path\"]) for p in pairs],\n",
    "    \"mask_path\":  [str(p[\"mask_path\"]) for p in pairs],\n",
    "    \"id\":         [p[\"id\"] for p in pairs],\n",
    "})\n",
    "\n",
    "print(f\"\\n[INFO] Final training samples: {len(df_manifest)}\")\n",
    "\n",
    "print(\"\\n[STAGE 1 COMPLETE — STRATEGIC]\")\n",
    "print(\"Dataset validated\")\n",
    "print(\"Structural bias diagnosed\")\n",
    "print(\"Upper-bound Dice feasibility assessed\")\n",
    "print(\"Ready to proceed with informed strategy to STAGE 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5894467",
   "metadata": {
    "papermill": {
     "duration": 0.00641,
     "end_time": "2026-02-05T04:08:07.751459",
     "exception": false,
     "start_time": "2026-02-05T04:08:07.745049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing & Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd84774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T04:08:07.765264Z",
     "iopub.status.busy": "2026-02-05T04:08:07.764537Z",
     "iopub.status.idle": "2026-02-05T04:08:13.009889Z",
     "shell.execute_reply": "2026-02-05T04:08:13.009040Z"
    },
    "papermill": {
     "duration": 5.254162,
     "end_time": "2026-02-05T04:08:13.011575",
     "exception": false,
     "start_time": "2026-02-05T04:08:07.757413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STAGE 2 — FINAL PIPELINE READY]\n",
      "✔ Boundary-safe augmentations\n",
      "✔ Multi-scale training support (512 & 640)\n",
      "✔ Deterministic validation & test\n",
      "✔ Fully compatible with STAGE 3 top-score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/1110423978.py:27: UserWarning: Argument(s) 'mode' are not valid for transform Affine\n",
      "  A.Affine(\n",
      "/tmp/ipykernel_24/1110423978.py:76: UserWarning: Argument(s) 'mode' are not valid for transform Affine\n",
      "  A.Affine(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 2 — Preprocessing & Data Augmentation (FINAL PIPELINE)\n",
    "# Goal:\n",
    "# - Boundary-safe augmentation\n",
    "# - Multi-scale ready (512 & 640)\n",
    "# - Fully compatible with STAGE 3 top-score training\n",
    "# ============================================================\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "\n",
    "# -----------------------------\n",
    "# GLOBAL NORMALIZATION\n",
    "# -----------------------------\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "# ============================================================\n",
    "# 1. TRAIN AUGMENTATION — 512 (BASE CONTEXT)\n",
    "# ============================================================\n",
    "train_transform_512 = A.Compose(\n",
    "    [\n",
    "        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        A.Affine(\n",
    "            scale=(0.95, 1.10),\n",
    "            translate_percent=(0.0, 0.05),\n",
    "            rotate=(-3, 3),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            mode=cv2.BORDER_REFLECT_101,\n",
    "            p=0.5\n",
    "        ),\n",
    "\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.25,\n",
    "            contrast_limit=0.25,\n",
    "            p=0.7\n",
    "        ),\n",
    "\n",
    "        A.HueSaturationValue(\n",
    "            hue_shift_limit=8,\n",
    "            sat_shift_limit=15,\n",
    "            val_shift_limit=8,\n",
    "            p=0.4\n",
    "        ),\n",
    "\n",
    "        A.RandomShadow(\n",
    "            shadow_roi=(0, 0.4, 1, 1),\n",
    "            p=0.3\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.GaussianBlur(blur_limit=3),\n",
    "                A.GaussNoise(),\n",
    "            ],\n",
    "            p=0.2\n",
    "        ),\n",
    "\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    additional_targets={\"mask\": \"mask\"},\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 2. TRAIN AUGMENTATION — 640 (BOUNDARY & DETAIL)\n",
    "# ============================================================\n",
    "train_transform_640 = A.Compose(\n",
    "    [\n",
    "        A.Resize(640, 640, interpolation=cv2.INTER_LINEAR),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        A.Affine(\n",
    "            scale=(0.98, 1.05),          # lebih konservatif\n",
    "            translate_percent=(0.0, 0.03),\n",
    "            rotate=(-2, 2),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            mode=cv2.BORDER_REFLECT_101,\n",
    "            p=0.4\n",
    "        ),\n",
    "\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.20,\n",
    "            contrast_limit=0.20,\n",
    "            p=0.6\n",
    "        ),\n",
    "\n",
    "        A.HueSaturationValue(\n",
    "            hue_shift_limit=6,\n",
    "            sat_shift_limit=12,\n",
    "            val_shift_limit=6,\n",
    "            p=0.3\n",
    "        ),\n",
    "\n",
    "        A.RandomShadow(\n",
    "            shadow_roi=(0, 0.4, 1, 1),\n",
    "            p=0.25\n",
    "        ),\n",
    "\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    additional_targets={\"mask\": \"mask\"},\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 3. VALIDATION AUGMENTATION (DETERMINISTIC)\n",
    "# ============================================================\n",
    "valid_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    additional_targets={\"mask\": \"mask\"},\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 4. TEST AUGMENTATION (MATCH VALIDATION)\n",
    "# ============================================================\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n",
    "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5. SUMMARY\n",
    "# ============================================================\n",
    "print(\"[STAGE 2 — FINAL PIPELINE READY]\")\n",
    "print(\"✔ Boundary-safe augmentations\")\n",
    "print(\"✔ Multi-scale training support (512 & 640)\")\n",
    "print(\"✔ Deterministic validation & test\")\n",
    "print(\"✔ Fully compatible with STAGE 3 top-score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f65dab5",
   "metadata": {
    "papermill": {
     "duration": 0.006788,
     "end_time": "2026-02-05T04:08:13.024854",
     "exception": false,
     "start_time": "2026-02-05T04:08:13.018066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Construction & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f08df21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T04:08:13.038522Z",
     "iopub.status.busy": "2026-02-05T04:08:13.037887Z",
     "iopub.status.idle": "2026-02-05T04:08:23.461383Z",
     "shell.execute_reply": "2026-02-05T04:08:23.460412Z"
    },
    "papermill": {
     "duration": 10.432412,
     "end_time": "2026-02-05T04:08:23.463445",
     "exception": false,
     "start_time": "2026-02-05T04:08:13.031033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q segmentation-models-pytorch==0.3.3 timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a0bbcb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T04:08:23.479683Z",
     "iopub.status.busy": "2026-02-05T04:08:23.479365Z",
     "iopub.status.idle": "2026-02-05T04:35:42.723869Z",
     "shell.execute_reply": "2026-02-05T04:35:42.723000Z"
    },
    "papermill": {
     "duration": 1639.377336,
     "end_time": "2026-02-05T04:35:42.848063",
     "exception": false,
     "start_time": "2026-02-05T04:08:23.470727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74.4M/74.4M [00:00<00:00, 204MB/s]\n",
      "Epoch 1 [TRAIN]: 100%|██████████| 106/106 [00:42<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | ValDice 0.5689\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | ValDice 0.6530\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | ValDice 0.6660\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | ValDice 0.6750\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | ValDice 0.6902\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [TRAIN]: 100%|██████████| 106/106 [00:41<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | ValDice 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | ValDice 0.6974\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | ValDice 0.7017\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | ValDice 0.7046\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | ValDice 0.7131\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | ValDice 0.6956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | ValDice 0.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [TRAIN]: 100%|██████████| 106/106 [00:41<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | ValDice 0.7281\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | ValDice 0.7220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [TRAIN]: 100%|██████████| 106/106 [00:40<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | ValDice 0.7227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [TRAIN]: 100%|██████████| 106/106 [01:02<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | ValDice 0.7114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | ValDice 0.7297\n",
      ">> Best model saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | ValDice 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | ValDice 0.7140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | ValDice 0.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | ValDice 0.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | ValDice 0.7064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | ValDice 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 [TRAIN]: 100%|██████████| 106/106 [01:02<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | ValDice 0.7265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | ValDice 0.7236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | ValDice 0.7209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | ValDice 0.7249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | ValDice 0.7238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | ValDice 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 [TRAIN]: 100%|██████████| 106/106 [01:01<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | ValDice 0.7255\n",
      "\n",
      "[STAGE 3 COMPLETE — TOP SCORE ALIGNED]\n",
      "Best Validation Dice: 0.7297\n",
      "READY FOR STAGE 4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 3 — Model Construction & Training (TOP SCORE, ALIGNED)\n",
    "# Key upgrades:\n",
    "# - Multi-scale curriculum (512 → 640)\n",
    "# - Boundary-aware loss\n",
    "# - Fully aligned with STAGE 2 FINAL\n",
    "# ============================================================\n",
    "\n",
    "import os, re, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# -----------------------------\n",
    "# REPRODUCIBILITY\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# DATA\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "TRAIN_IMG_DIR = DATA_ROOT / \"train\" / \"images\"\n",
    "TRAIN_MASK_DIR = DATA_ROOT / \"train\" / \"mask\"\n",
    "\n",
    "def extract_idx(name):\n",
    "    return re.search(r\"(\\d+)\", name).group(1)\n",
    "\n",
    "pairs = []\n",
    "for img in TRAIN_IMG_DIR.iterdir():\n",
    "    idx = extract_idx(img.name)\n",
    "    mask = TRAIN_MASK_DIR / f\"mask_{idx}.png\"\n",
    "    if mask.exists():\n",
    "        pairs.append((str(img), str(mask)))\n",
    "\n",
    "df = pd.DataFrame(pairs, columns=[\"image_path\", \"mask_path\"])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_valid = train_test_split(df, test_size=0.15, random_state=SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# DATASET\n",
    "# -----------------------------\n",
    "class PotholeDataset(Dataset):\n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.df.loc[idx, \"image_path\"])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = cv2.imread(self.df.loc[idx, \"mask_path\"], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = (mask == 255).astype(\"float32\")\n",
    "\n",
    "        aug = self.transform(image=img, mask=mask)\n",
    "        img = aug[\"image\"]\n",
    "        mask = aug[\"mask\"].unsqueeze(0)\n",
    "        return img, mask\n",
    "\n",
    "# -----------------------------\n",
    "# VALIDATION LOADER (FIXED)\n",
    "# -----------------------------\n",
    "valid_loader = DataLoader(\n",
    "    PotholeDataset(df_valid, valid_transform),\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# MULTI-SCALE CURRICULUM\n",
    "# -----------------------------\n",
    "def get_train_transform(epoch):\n",
    "    # first half: context & stability\n",
    "    if epoch < 15:\n",
    "        return train_transform_512\n",
    "    # second half: boundary refinement\n",
    "    return train_transform_640\n",
    "\n",
    "# -----------------------------\n",
    "# MODEL\n",
    "# -----------------------------\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"efficientnet-b4\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ").to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# LOSS (BOUNDARY-AWARE)\n",
    "# -----------------------------\n",
    "dice_loss = smp.losses.DiceLoss(mode=\"binary\", from_logits=True)\n",
    "focal_loss = smp.losses.FocalLoss(mode=\"binary\", gamma=2.0)\n",
    "\n",
    "def boundary_loss(prob, target):\n",
    "    sobel = torch.tensor(\n",
    "        [[1,0,-1],[2,0,-2],[1,0,-1]],\n",
    "        device=prob.device\n",
    "    ).float().view(1,1,3,3)\n",
    "\n",
    "    prob_edge = torch.abs(\n",
    "        nn.functional.conv2d(prob, sobel, padding=1)\n",
    "    )\n",
    "    target_edge = torch.abs(\n",
    "        nn.functional.conv2d(target, sobel, padding=1)\n",
    "    )\n",
    "\n",
    "    return nn.functional.l1_loss(prob_edge, target_edge)\n",
    "\n",
    "def criterion(logits, target):\n",
    "    prob = torch.sigmoid(logits).clamp(1e-4, 1 - 1e-4)\n",
    "    return (\n",
    "        dice_loss(logits, target)\n",
    "        + 0.5 * focal_loss(logits, target)\n",
    "        + 0.3 * boundary_loss(prob, target)\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# OPTIMIZER\n",
    "# -----------------------------\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "# -----------------------------\n",
    "# METRIC\n",
    "# -----------------------------\n",
    "def dice_coef(prob, target, eps=1e-7):\n",
    "    pred = (prob > 0.5).float()\n",
    "    intersection = (pred * target).sum(dim=(2,3))\n",
    "    union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "    return ((2 * intersection + eps) / (union + eps)).mean()\n",
    "\n",
    "# -----------------------------\n",
    "# TRAINING LOOP\n",
    "# -----------------------------\n",
    "EPOCHS = 30\n",
    "best_dice = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        PotholeDataset(df_train, get_train_transform(epoch)),\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    for imgs, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1} [TRAIN]\"):\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_dice = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in valid_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            prob = torch.sigmoid(model(imgs))\n",
    "            val_dice += dice_coef(prob, masks).item()\n",
    "\n",
    "    val_dice /= len(valid_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | ValDice {val_dice:.4f}\")\n",
    "\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        torch.save(model.state_dict(), \"/kaggle/working/best_unetpp_effb4.pt\")\n",
    "        print(\">> Best model saved\")\n",
    "\n",
    "print(\"\\n[STAGE 3 COMPLETE — TOP SCORE ALIGNED]\")\n",
    "print(\"Best Validation Dice:\", round(best_dice, 4))\n",
    "print(\"READY FOR STAGE 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024fc0b",
   "metadata": {
    "papermill": {
     "duration": 0.118845,
     "end_time": "2026-02-05T04:35:43.087353",
     "exception": false,
     "start_time": "2026-02-05T04:35:42.968508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimization, Validation & Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b77c1cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T04:35:43.329559Z",
     "iopub.status.busy": "2026-02-05T04:35:43.328793Z",
     "iopub.status.idle": "2026-02-05T04:37:41.035558Z",
     "shell.execute_reply": "2026-02-05T04:37:41.034659Z"
    },
    "papermill": {
     "duration": 117.830308,
     "end_time": "2026-02-05T04:37:41.037150",
     "exception": false,
     "start_time": "2026-02-05T04:35:43.206842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-05 04:35:46,978] A new study created in memory with name: no-name-0b906a62-3736-4a8e-870b-c3157f29c981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Best model loaded for Optuna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-05 04:35:49,821] Trial 0 finished with value: 0.6950937324368889 and parameters: {'threshold': 0.3760305407879275, 'min_area': 700}. Best is trial 0 with value: 0.6950937324368889.\n",
      "[I 2026-02-05 04:35:52,600] Trial 1 finished with value: 0.6919575880308166 and parameters: {'threshold': 0.46298269680077875, 'min_area': 1100}. Best is trial 0 with value: 0.6950937324368889.\n",
      "[I 2026-02-05 04:35:55,367] Trial 2 finished with value: 0.7037913534620266 and parameters: {'threshold': 0.3915228893015128, 'min_area': 300}. Best is trial 2 with value: 0.7037913534620266.\n",
      "[I 2026-02-05 04:35:58,088] Trial 3 finished with value: 0.695539153554166 and parameters: {'threshold': 0.335954758620002, 'min_area': 500}. Best is trial 2 with value: 0.7037913534620266.\n",
      "[I 2026-02-05 04:36:00,806] Trial 4 finished with value: 0.6933610231767795 and parameters: {'threshold': 0.5389112626368613, 'min_area': 600}. Best is trial 2 with value: 0.7037913534620266.\n",
      "[I 2026-02-05 04:36:03,534] Trial 5 finished with value: 0.6935004107915733 and parameters: {'threshold': 0.53683412374981, 'min_area': 500}. Best is trial 2 with value: 0.7037913534620266.\n",
      "[I 2026-02-05 04:36:06,295] Trial 6 finished with value: 0.6901597990151406 and parameters: {'threshold': 0.4690743273679815, 'min_area': 1500}. Best is trial 2 with value: 0.7037913534620266.\n",
      "[I 2026-02-05 04:36:08,974] Trial 7 finished with value: 0.6931117846613215 and parameters: {'threshold': 0.4258048335970721, 'min_area': 1400}. Best is trial 2 with value: 0.7037913534620266.\n",
      "[I 2026-02-05 04:36:11,700] Trial 8 finished with value: 0.6943422688397147 and parameters: {'threshold': 0.3554825418971146, 'min_area': 900}. Best is trial 2 with value: 0.7037913534620266.\n",
      "[I 2026-02-05 04:36:14,496] Trial 9 finished with value: 0.6908009882781968 and parameters: {'threshold': 0.35208253539113804, 'min_area': 1500}. Best is trial 2 with value: 0.7037913534620266.\n",
      "[I 2026-02-05 04:36:17,383] Trial 10 finished with value: 0.7394598227747922 and parameters: {'threshold': 0.2521905406547911, 'min_area': 100}. Best is trial 10 with value: 0.7394598227747922.\n",
      "[I 2026-02-05 04:36:20,315] Trial 11 finished with value: 0.7393513228053178 and parameters: {'threshold': 0.25650715563053716, 'min_area': 100}. Best is trial 10 with value: 0.7394598227747922.\n",
      "[I 2026-02-05 04:36:23,212] Trial 12 finished with value: 0.7394564868383297 and parameters: {'threshold': 0.25185168942648545, 'min_area': 100}. Best is trial 10 with value: 0.7394598227747922.\n",
      "[I 2026-02-05 04:36:26,150] Trial 13 finished with value: 0.7393416246935066 and parameters: {'threshold': 0.2596748479861371, 'min_area': 100}. Best is trial 10 with value: 0.7394598227747922.\n",
      "[I 2026-02-05 04:36:29,024] Trial 14 finished with value: 0.7212898552778146 and parameters: {'threshold': 0.29647747955715265, 'min_area': 300}. Best is trial 10 with value: 0.7394598227747922.\n",
      "[I 2026-02-05 04:36:31,878] Trial 15 finished with value: 0.7212434005139897 and parameters: {'threshold': 0.2985661203514168, 'min_area': 300}. Best is trial 10 with value: 0.7394598227747922.\n",
      "[I 2026-02-05 04:36:34,796] Trial 16 finished with value: 0.6943531591303017 and parameters: {'threshold': 0.29809200551030857, 'min_area': 900}. Best is trial 10 with value: 0.7394598227747922.\n",
      "[I 2026-02-05 04:36:37,676] Trial 17 finished with value: 0.7394676696375577 and parameters: {'threshold': 0.2517684134212907, 'min_area': 100}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:36:40,548] Trial 18 finished with value: 0.7055358647091712 and parameters: {'threshold': 0.31062341959617934, 'min_area': 400}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:36:43,410] Trial 19 finished with value: 0.6921495597486272 and parameters: {'threshold': 0.4253902464541136, 'min_area': 1200}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:36:46,372] Trial 20 finished with value: 0.7259939102862162 and parameters: {'threshold': 0.321646609026927, 'min_area': 200}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:36:49,275] Trial 21 finished with value: 0.7394612928548268 and parameters: {'threshold': 0.250109051787753, 'min_area': 100}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:36:52,098] Trial 22 finished with value: 0.7270206759174538 and parameters: {'threshold': 0.2745972590939243, 'min_area': 200}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:36:55,046] Trial 23 finished with value: 0.7058466851450738 and parameters: {'threshold': 0.27947159060579235, 'min_area': 400}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:36:57,956] Trial 24 finished with value: 0.7389673977422431 and parameters: {'threshold': 0.28227991351024334, 'min_area': 100}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:00,836] Trial 25 finished with value: 0.7272939187572249 and parameters: {'threshold': 0.25009519828569543, 'min_area': 200}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:03,651] Trial 26 finished with value: 0.7054522577720911 and parameters: {'threshold': 0.3191401585461133, 'min_area': 400}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:06,574] Trial 27 finished with value: 0.6947599687881396 and parameters: {'threshold': 0.27411302386430203, 'min_area': 700}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:09,414] Trial 28 finished with value: 0.7251275629111299 and parameters: {'threshold': 0.33719709544355214, 'min_area': 200}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:12,227] Trial 29 finished with value: 0.6952605823863056 and parameters: {'threshold': 0.3730383533244464, 'min_area': 600}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:15,183] Trial 30 finished with value: 0.6927456646305518 and parameters: {'threshold': 0.5061442174100518, 'min_area': 800}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:18,021] Trial 31 finished with value: 0.739363913402928 and parameters: {'threshold': 0.2626575191572949, 'min_area': 100}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:20,914] Trial 32 finished with value: 0.7389066200128965 and parameters: {'threshold': 0.286802543325582, 'min_area': 100}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:23,758] Trial 33 finished with value: 0.7221034773162455 and parameters: {'threshold': 0.2541739291164221, 'min_area': 300}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:26,663] Trial 34 finished with value: 0.7272941108159068 and parameters: {'threshold': 0.2501047822722955, 'min_area': 200}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:29,533] Trial 35 finished with value: 0.705561052591371 and parameters: {'threshold': 0.2739159691930204, 'min_area': 500}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:32,384] Trial 36 finished with value: 0.7211592422431384 and parameters: {'threshold': 0.30709762085094083, 'min_area': 300}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:35,297] Trial 37 finished with value: 0.7392118368212256 and parameters: {'threshold': 0.26813513254693155, 'min_area': 100}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:38,159] Trial 38 finished with value: 0.6933301458902005 and parameters: {'threshold': 0.33015610910647186, 'min_area': 1100}. Best is trial 17 with value: 0.7394676696375577.\n",
      "[I 2026-02-05 04:37:41,030] Trial 39 finished with value: 0.705746788812574 and parameters: {'threshold': 0.2899603734253891, 'min_area': 400}. Best is trial 17 with value: 0.7394676696375577.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OPTUNA BEST CONFIG]\n",
      "{'threshold': 0.2517684134212907, 'min_area': 100}\n",
      "Best validation Dice: 0.7395\n",
      "\n",
      "[STAGE 4 COMPLETE — OPTUNA STRATEGIC]\n",
      "Decision-level optimization finished\n",
      "Ready for STAGE 5 (Inference & Submission)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 4 — Optimization, Validation & Refinement (OPTUNA)\n",
    "# Goal:\n",
    "# - Optimize decision-level parameters (threshold + post-process)\n",
    "# - Maximize validation Dice\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 0. INSTALL OPTUNA\n",
    "# -----------------------------\n",
    "!pip install -q optuna\n",
    "\n",
    "# -----------------------------\n",
    "# 1. IMPORTS\n",
    "# -----------------------------\n",
    "import optuna\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 2. CONFIG\n",
    "# -----------------------------\n",
    "MODEL_PATH = \"/kaggle/working/best_unetpp_effb4.pt\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "N_TRIALS = 40   # cukup untuk lonjakan besar, masih aman runtime\n",
    "\n",
    "# -----------------------------\n",
    "# 3. LOAD MODEL\n",
    "# -----------------------------\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(\"[INFO] Best model loaded for Optuna\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. HELPER FUNCTIONS\n",
    "# -----------------------------\n",
    "def dice_score(pred, target, eps=1e-7):\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum()\n",
    "    return (2 * intersection + eps) / (union + eps)\n",
    "\n",
    "def remove_small_objects(mask, min_area):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n",
    "        mask.astype(np.uint8), connectivity=8\n",
    "    )\n",
    "    clean = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            clean[labels == i] = 1\n",
    "    return clean\n",
    "\n",
    "# -----------------------------\n",
    "# 5. OPTUNA OBJECTIVE\n",
    "# -----------------------------\n",
    "def objective(trial):\n",
    "    threshold = trial.suggest_float(\"threshold\", 0.25, 0.55)\n",
    "    min_area  = trial.suggest_int(\"min_area\", 100, 1500, step=100)\n",
    "\n",
    "    dices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in valid_loader:\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            masks = masks.to(DEVICE)\n",
    "\n",
    "            probs = torch.sigmoid(model(imgs)).cpu().numpy()\n",
    "            gt = masks.cpu().numpy()\n",
    "\n",
    "            for i in range(probs.shape[0]):\n",
    "                pred = (probs[i, 0] > threshold).astype(np.uint8)\n",
    "                pred = remove_small_objects(pred, min_area)\n",
    "\n",
    "                dice = dice_score(pred, gt[i, 0])\n",
    "                dices.append(dice)\n",
    "\n",
    "    return float(np.mean(dices))\n",
    "\n",
    "# -----------------------------\n",
    "# 6. RUN OPTUNA\n",
    "# -----------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. BEST CONFIG\n",
    "# -----------------------------\n",
    "best_params = study.best_params\n",
    "best_dice = study.best_value\n",
    "\n",
    "print(\"\\n[OPTUNA BEST CONFIG]\")\n",
    "print(best_params)\n",
    "print(f\"Best validation Dice: {best_dice:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 8. SAVE CONFIG FOR STAGE 5\n",
    "# -----------------------------\n",
    "OPT_CONFIG = {\n",
    "    \"threshold\": best_params[\"threshold\"],\n",
    "    \"min_area\": best_params[\"min_area\"],\n",
    "}\n",
    "\n",
    "print(\"\\n[STAGE 4 COMPLETE — OPTUNA STRATEGIC]\")\n",
    "print(\"Decision-level optimization finished\")\n",
    "print(\"Ready for STAGE 5 (Inference & Submission)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e174a",
   "metadata": {
    "papermill": {
     "duration": 0.119974,
     "end_time": "2026-02-05T04:37:41.279717",
     "exception": false,
     "start_time": "2026-02-05T04:37:41.159743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference, Encoding & Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c9db4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T04:37:41.525841Z",
     "iopub.status.busy": "2026-02-05T04:37:41.525120Z",
     "iopub.status.idle": "2026-02-05T04:38:07.983862Z",
     "shell.execute_reply": "2026-02-05T04:38:07.983094Z"
    },
    "papermill": {
     "duration": 26.58297,
     "end_time": "2026-02-05T04:38:07.985333",
     "exception": false,
     "start_time": "2026-02-05T04:37:41.402363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Test images: 295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference + TTA: 100%|██████████| 295/295 [00:26<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STAGE 5 COMPLETE — STRATEGIC FINAL]\n",
      "Submission saved to: /kaggle/working/submission.csv\n",
      "Rows: 295\n",
      "Empty RLE: 0\n",
      "        ImageId                                                rle\n",
      "0  test_001.jpg  5242 3 5540 6 5840 7 6139 8 6439 8 6738 10 703...\n",
      "1  test_002.jpg  123508 3 124227 4 124947 5 125667 5 126387 5 1...\n",
      "2  test_003.jpg  1338525 4 1340821 4 1343117 4 1345413 4 134770...\n",
      "3  test_004.jpg  17820 3 18120 5 18420 5 18719 6 19019 7 19319 ...\n",
      "4  test_005.jpg  50529 6 50828 8 51126 12 51426 12 51726 14 517...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STAGE 5 — Inference, RLE Encoding & Submission (STRATEGIC FINAL)\n",
    "# Goal:\n",
    "# - Stabilize predictions (TTA)\n",
    "# - Use Optuna-optimized decision parameters\n",
    "# - Refine boundary for Dice maximization\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\n",
    "TEST_IMG_DIR = DATA_ROOT / \"test\" / \"images\"\n",
    "SAMPLE_SUB = Path(\"/kaggle/input/data-science-ara-7-0/sample_submission.csv\")\n",
    "\n",
    "MODEL_PATH = \"/kaggle/working/best_unetpp_effb4.pt\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BEST_THRESHOLD = OPT_CONFIG[\"threshold\"]\n",
    "MIN_AREA = OPT_CONFIG[\"min_area\"]\n",
    "INPUT_SIZE = 512\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD MODEL\n",
    "# -----------------------------\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "\n",
    "# -----------------------------\n",
    "# RLE ENCODER (OFFICIAL)\n",
    "# -----------------------------\n",
    "def encode_rle(mask: np.ndarray, pos_value: int = 255) -> str:\n",
    "    binary = (mask == pos_value).astype(np.uint8)\n",
    "    pixels = binary.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[0::2]\n",
    "    return \" \".join(str(x) for x in runs)\n",
    "\n",
    "# -----------------------------\n",
    "# POST-PROCESSING\n",
    "# -----------------------------\n",
    "def remove_small_objects(mask, min_area):\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n",
    "        mask.astype(np.uint8), connectivity=8\n",
    "    )\n",
    "    clean = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for i in range(1, num_labels):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n",
    "            clean[labels == i] = 1\n",
    "    return clean\n",
    "\n",
    "def fill_holes(mask):\n",
    "    return cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5,5), np.uint8))\n",
    "\n",
    "# -----------------------------\n",
    "# COLLECT TEST FILES\n",
    "# -----------------------------\n",
    "test_images = sorted(TEST_IMG_DIR.glob(\"*.jpg\"))\n",
    "print(\"[INFO] Test images:\", len(test_images))\n",
    "\n",
    "# -----------------------------\n",
    "# INFERENCE WITH LIGHT TTA\n",
    "# -----------------------------\n",
    "records = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_path in tqdm(test_images, desc=\"Inference + TTA\"):\n",
    "        img_name = img_path.name\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h0, w0 = img.shape[:2]\n",
    "\n",
    "        img_resized = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE))\n",
    "        img_resized = img_resized.astype(\"float32\") / 255.0\n",
    "\n",
    "        img_resized[..., 0] = (img_resized[..., 0] - 0.485) / 0.229\n",
    "        img_resized[..., 1] = (img_resized[..., 1] - 0.456) / 0.224\n",
    "        img_resized[..., 2] = (img_resized[..., 2] - 0.406) / 0.225\n",
    "\n",
    "        # original\n",
    "        x = torch.from_numpy(img_resized.transpose(2,0,1)).unsqueeze(0).to(DEVICE)\n",
    "        prob1 = torch.sigmoid(model(x))[0,0]\n",
    "\n",
    "        # horizontal flip TTA\n",
    "        x_flip = torch.flip(x, dims=[3])\n",
    "        prob2 = torch.sigmoid(model(x_flip))[0,0]\n",
    "        prob2 = torch.flip(prob2, dims=[1])\n",
    "\n",
    "        # average probability\n",
    "        prob = ((prob1 + prob2) / 2).cpu().numpy()\n",
    "\n",
    "        # threshold + refinement\n",
    "        pred = (prob > BEST_THRESHOLD).astype(np.uint8)\n",
    "        pred = remove_small_objects(pred, MIN_AREA)\n",
    "        pred = fill_holes(pred)\n",
    "\n",
    "        pred = cv2.resize(pred, (w0, h0), interpolation=cv2.INTER_NEAREST)\n",
    "        pred_255 = pred * 255\n",
    "\n",
    "        rle = \"\" if pred_255.sum() == 0 else encode_rle(pred_255)\n",
    "\n",
    "        records.append({\n",
    "            \"ImageId\": img_name,\n",
    "            \"rle\": rle\n",
    "        })\n",
    "\n",
    "# -----------------------------\n",
    "# BUILD SUBMISSION\n",
    "# -----------------------------\n",
    "df_sub = pd.DataFrame(records)\n",
    "df_sub = df_sub[pd.read_csv(SAMPLE_SUB).columns.tolist()]\n",
    "\n",
    "OUT_SUB = \"/kaggle/working/submission.csv\"\n",
    "df_sub.to_csv(OUT_SUB, index=False)\n",
    "\n",
    "print(\"\\n[STAGE 5 COMPLETE — STRATEGIC FINAL]\")\n",
    "print(\"Submission saved to:\", OUT_SUB)\n",
    "print(\"Rows:\", len(df_sub))\n",
    "print(\"Empty RLE:\", (df_sub[\"rle\"] == \"\").sum())\n",
    "print(df_sub.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15445689,
     "sourceId": 128328,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1832.929229,
   "end_time": "2026-02-05T04:38:11.693262",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-02-05T04:07:38.764033",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
