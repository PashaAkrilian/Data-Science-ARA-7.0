{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":128328,"databundleVersionId":15445689,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Understanding & Preparation","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 1 — Data Understanding & Preparation (FINAL LEADERBOARD)\n# Purpose:\n# - Validate dataset integrity\n# - Quantify Dice risk factors (empty / tiny objects)\n# - Extract morphology statistics for post-processing\n# - Produce data-driven priors for threshold & min-area\n# ============================================================\n\nfrom pathlib import Path\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom tqdm import tqdm\nimport re\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nTRAIN_IMG_DIR = DATA_ROOT / \"train\" / \"images\"\nTRAIN_MASK_DIR = DATA_ROOT / \"train\" / \"mask\"\nTEST_IMG_DIR  = DATA_ROOT / \"test\" / \"images\"\n\nIMG_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n\n# -----------------------------\n# 1. LOAD FILES\n# -----------------------------\ntrain_images = sorted([p for p in TRAIN_IMG_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\ntrain_masks  = sorted([p for p in TRAIN_MASK_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\ntest_images  = sorted([p for p in TEST_IMG_DIR.iterdir() if p.suffix.lower() in IMG_EXTS])\n\nprint(f\"[INFO] Train images : {len(train_images)}\")\nprint(f\"[INFO] Train masks  : {len(train_masks)}\")\nprint(f\"[INFO] Test images  : {len(test_images)}\")\n\n# -----------------------------\n# 2. BUILD MASK INDEX\n# -----------------------------\ndef extract_index(name: str):\n    m = re.search(r\"(\\d+)\", name)\n    return m.group(1) if m else None\n\nmask_index = {}\nfor m in train_masks:\n    idx = extract_index(m.stem)\n    if idx is not None:\n        mask_index[idx] = m\n\n# -----------------------------\n# 3. PAIR IMAGE–MASK\n# -----------------------------\npairs = []\nfor img in train_images:\n    idx = extract_index(img.stem)\n    if idx in mask_index:\n        pairs.append({\n            \"image_path\": img,\n            \"mask_path\": mask_index[idx],\n            \"id\": idx\n        })\n\nassert len(pairs) > 0, \"No valid image-mask pairs found\"\nprint(f\"[INFO] Valid image-mask pairs: {len(pairs)}\")\n\n# -----------------------------\n# 4. MORPHOLOGY & DICE-RISK ANALYSIS\n# -----------------------------\nrecords = []\nall_component_areas = []\n\nfor p in tqdm(pairs, desc=\"Analyzing dataset\"):\n    mask = cv2.imread(str(p[\"mask_path\"]), cv2.IMREAD_GRAYSCALE)\n    h, w = mask.shape\n    total_pixels = h * w\n\n    bin_mask = (mask == 255).astype(np.uint8)\n    pothole_pixels = bin_mask.sum()\n    area_ratio = pothole_pixels / total_pixels\n\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n        bin_mask, connectivity=8\n    )\n\n    component_areas = stats[1:, cv2.CC_STAT_AREA] if num_labels > 1 else []\n    if len(component_areas) > 0:\n        all_component_areas.extend(component_areas.tolist())\n\n    records.append({\n        \"image\": p[\"image_path\"].name,\n        \"height\": h,\n        \"width\": w,\n        \"has_pothole\": int(pothole_pixels > 0),\n        \"area_ratio\": area_ratio,\n        \"total_pothole_pixels\": pothole_pixels,\n        \"num_components\": len(component_areas),\n        \"max_component_ratio\": (\n            component_areas.max() / total_pixels if len(component_areas) > 0 else 0.0\n        ),\n        \"min_component_pixels\": (\n            component_areas.min() if len(component_areas) > 0 else 0\n        ),\n    })\n\ndf = pd.DataFrame(records)\n\n# -----------------------------\n# 5. CORE DATASET INSIGHTS\n# -----------------------------\nprint(\"\\n[INSIGHT] Pothole presence distribution:\")\nprint(df[\"has_pothole\"].value_counts())\n\nempty_ratio = (df[\"has_pothole\"] == 0).mean()\nprint(f\"\\n[INSIGHT] Empty-mask ratio: {empty_ratio:.2%}\")\n\nprint(\"\\n[INSIGHT] Pothole area ratio (% of image):\")\nprint(df[\"area_ratio\"].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]))\n\nprint(\"\\n[INSIGHT] Number of components per image:\")\nprint(df[\"num_components\"].describe())\n\nprint(\"\\n[INSIGHT] Dominant component ratio:\")\nprint(df[\"max_component_ratio\"].describe())\n\n# -----------------------------\n# 6. SMALL-OBJECT RISK (FP KILLER)\n# -----------------------------\ncomp_series = pd.Series(all_component_areas)\n\nprint(\"\\n[INSIGHT] Connected component area (pixels):\")\nprint(comp_series.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]))\n\nmin_area_candidate = int(comp_series.quantile(0.10))\nprint(f\"\\n[RECOMMENDATION] Candidate MIN_AREA (remove FP): ~{min_area_candidate} pixels\")\n\n# -----------------------------\n# 7. DICE FEASIBILITY SIGNAL\n# -----------------------------\ntiny_image_ratio = (df[\"area_ratio\"] < 0.01).mean()\n\nprint(\"\\n[FEASIBILITY CHECK]\")\nprint(f\"Images with pothole <1% area: {tiny_image_ratio:.2%}\")\n\nif tiny_image_ratio > 0.6:\n    feasibility = \"HARD (Dice ceiling tight)\"\nelif tiny_image_ratio > 0.4:\n    feasibility = \"MODERATE (needs strong post-processing)\"\nelse:\n    feasibility = \"FAVORABLE (0.80+ achievable)\"\n\nprint(f\"[FEASIBILITY STATUS] {feasibility}\")\n\n# -----------------------------\n# 8. THRESHOLD PRIOR (DATA-DRIVEN)\n# -----------------------------\nprint(\"\\n[THRESHOLD PRIOR]\")\nprint(\"Based on small-object dominance:\")\nprint(\"→ Start sweep in range: 0.30 – 0.45 (Dice-friendly)\")\n\n# -----------------------------\n# 9. FINAL MANIFEST\n# -----------------------------\ndf_manifest = pd.DataFrame({\n    \"image_path\": [str(p[\"image_path\"]) for p in pairs],\n    \"mask_path\":  [str(p[\"mask_path\"]) for p in pairs],\n    \"id\":         [p[\"id\"] for p in pairs],\n})\n\nprint(f\"\\n[INFO] Final training samples: {len(df_manifest)}\")\n\nprint(\"\\n[STAGE 1 COMPLETE — LEADERBOARD READY]\")\nprint(\"✓ Dataset validated\")\nprint(\"✓ Dice risk quantified\")\nprint(\"✓ Min-area & threshold priors extracted\")\nprint(\"✓ Ready for STAGE 2 (augmentation design)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T09:17:20.328842Z","iopub.execute_input":"2026-02-05T09:17:20.329113Z","iopub.status.idle":"2026-02-05T09:17:33.868564Z","shell.execute_reply.started":"2026-02-05T09:17:20.329090Z","shell.execute_reply":"2026-02-05T09:17:33.867850Z"}},"outputs":[{"name":"stdout","text":"[INFO] Train images : 498\n[INFO] Train masks  : 498\n[INFO] Test images  : 295\n[INFO] Valid image-mask pairs: 498\n","output_type":"stream"},{"name":"stderr","text":"Analyzing dataset: 100%|██████████| 498/498 [00:12<00:00, 40.52it/s]","output_type":"stream"},{"name":"stdout","text":"\n[INSIGHT] Pothole presence distribution:\nhas_pothole\n1    498\nName: count, dtype: int64\n\n[INSIGHT] Empty-mask ratio: 0.00%\n\n[INSIGHT] Pothole area ratio (% of image):\ncount    498.000000\nmean       0.134860\nstd        0.128772\nmin        0.000235\n10%        0.007938\n25%        0.040943\n50%        0.091678\n75%        0.193834\n90%        0.329536\nmax        0.674005\nName: area_ratio, dtype: float64\n\n[INSIGHT] Number of components per image:\ncount    498.000000\nmean       4.261044\nstd        6.239045\nmin        1.000000\n25%        1.000000\n50%        2.000000\n75%        5.000000\nmax       67.000000\nName: num_components, dtype: float64\n\n[INSIGHT] Dominant component ratio:\ncount    498.000000\nmean       0.112599\nstd        0.119287\nmin        0.000235\n25%        0.030156\n50%        0.066428\n75%        0.162189\nmax        0.636689\nName: max_component_ratio, dtype: float64\n\n[INSIGHT] Connected component area (pixels):\ncount    2.122000e+03\nmean     5.588544e+04\nstd      3.030841e+05\nmin      1.000000e+00\n10%      1.301000e+02\n25%      3.930000e+02\n50%      1.913000e+03\n75%      1.203275e+04\n90%      5.370160e+04\nmax      6.700584e+06\ndtype: float64\n\n[RECOMMENDATION] Candidate MIN_AREA (remove FP): ~130 pixels\n\n[FEASIBILITY CHECK]\nImages with pothole <1% area: 11.85%\n[FEASIBILITY STATUS] FAVORABLE (0.80+ achievable)\n\n[THRESHOLD PRIOR]\nBased on small-object dominance:\n→ Start sweep in range: 0.30 – 0.45 (Dice-friendly)\n\n[INFO] Final training samples: 498\n\n[STAGE 1 COMPLETE — LEADERBOARD READY]\n✓ Dataset validated\n✓ Dice risk quantified\n✓ Min-area & threshold priors extracted\n✓ Ready for STAGE 2 (augmentation design)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Preprocessing & Data Augmentation","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 2 — Preprocessing & Data Augmentation (FINAL LEADERBOARD)\n# Goal:\n# - Dice-safe augmentation (no boundary destruction)\n# - Robust to lighting, shadow, texture\n# - Resolution-aware (512 = context | 640 = boundary)\n# - Ensemble-compatible (UNet++ primary)\n# ============================================================\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\n# -----------------------------\n# GLOBAL NORMALIZATION\n# -----------------------------\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD  = (0.229, 0.224, 0.225)\n\n# ============================================================\n# 1. TRAIN AUGMENTATION — 512 (GENERALIZATION / CONTEXT)\n# ============================================================\ntrain_transform_512 = A.Compose(\n    [\n        # resize for context learning\n        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n\n        # geometry (SAFE for road scenes)\n        A.HorizontalFlip(p=0.5),\n        A.Affine(\n            scale=(0.95, 1.08),\n            translate_percent=(0.0, 0.04),\n            rotate=(-3, 3),\n            interpolation=cv2.INTER_LINEAR,\n            mode=cv2.BORDER_REFLECT_101,\n            p=0.5,\n        ),\n\n        # photometric (main generalization driver)\n        A.RandomBrightnessContrast(\n            brightness_limit=0.20,\n            contrast_limit=0.20,\n            p=0.7,\n        ),\n        A.HueSaturationValue(\n            hue_shift_limit=6,\n            sat_shift_limit=12,\n            val_shift_limit=6,\n            p=0.35,\n        ),\n\n        # realistic road shadow (lower half bias)\n        A.RandomShadow(\n            shadow_roi=(0, 0.5, 1, 1),\n            p=0.25,\n        ),\n\n        # VERY mild noise (anti-overfit, Dice-safe)\n        A.OneOf(\n            [\n                A.GaussianBlur(blur_limit=3),\n                A.GaussNoise(var_limit=(5.0, 20.0)),\n            ],\n            p=0.15,\n        ),\n\n        # normalize\n        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ToTensorV2(),\n    ],\n    additional_targets={\"mask\": \"mask\"},\n)\n\n# ============================================================\n# 2. TRAIN AUGMENTATION — 640 (BOUNDARY PRECISION)\n# ============================================================\ntrain_transform_640 = A.Compose(\n    [\n        # high-res for boundary refinement\n        A.Resize(640, 640, interpolation=cv2.INTER_LINEAR),\n\n        A.HorizontalFlip(p=0.5),\n        A.Affine(\n            scale=(0.98, 1.05),\n            translate_percent=(0.0, 0.03),\n            rotate=(-2, 2),\n            interpolation=cv2.INTER_LINEAR,\n            mode=cv2.BORDER_REFLECT_101,\n            p=0.4,\n        ),\n\n        # lighter photometric (keep edges clean)\n        A.RandomBrightnessContrast(\n            brightness_limit=0.15,\n            contrast_limit=0.15,\n            p=0.6,\n        ),\n        A.HueSaturationValue(\n            hue_shift_limit=4,\n            sat_shift_limit=10,\n            val_shift_limit=4,\n            p=0.25,\n        ),\n\n        # shadow allowed but weaker\n        A.RandomShadow(\n            shadow_roi=(0, 0.5, 1, 1),\n            p=0.20,\n        ),\n\n        # NO noise here (boundary critical)\n        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ToTensorV2(),\n    ],\n    additional_targets={\"mask\": \"mask\"},\n)\n\n# ============================================================\n# 3. VALIDATION TRANSFORM (STRICT & DETERMINISTIC)\n# ============================================================\nvalid_transform = A.Compose(\n    [\n        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ToTensorV2(),\n    ],\n    additional_targets={\"mask\": \"mask\"},\n)\n\n# ============================================================\n# 4. TEST TRANSFORM (MUST MATCH VALIDATION)\n# ============================================================\ntest_transform = A.Compose(\n    [\n        A.Resize(512, 512, interpolation=cv2.INTER_LINEAR),\n        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n        ToTensorV2(),\n    ]\n)\n\n# ============================================================\n# 5. FINAL CHECK\n# ============================================================\nprint(\"[STAGE 2 COMPLETE — LEADERBOARD READY]\")\nprint(\"✓ Dice-safe augmentations\")\nprint(\"✓ 512 = context & robustness\")\nprint(\"✓ 640 = boundary precision\")\nprint(\"✓ No destructive transforms\")\nprint(\"✓ Validation/Test deterministic\")\nprint(\"✓ Ready for STAGE 3 (model training)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T09:19:33.689336Z","iopub.execute_input":"2026-02-05T09:19:33.689873Z","iopub.status.idle":"2026-02-05T09:19:38.700219Z","shell.execute_reply.started":"2026-02-05T09:19:33.689830Z","shell.execute_reply":"2026-02-05T09:19:38.699527Z"}},"outputs":[{"name":"stdout","text":"[STAGE 2 COMPLETE — LEADERBOARD READY]\n✓ Dice-safe augmentations\n✓ 512 = context & robustness\n✓ 640 = boundary precision\n✓ No destructive transforms\n✓ Validation/Test deterministic\n✓ Ready for STAGE 3 (model training)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/1396755098.py:30: UserWarning: Argument(s) 'mode' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_55/1396755098.py:62: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n  A.GaussNoise(var_limit=(5.0, 20.0)),\n/tmp/ipykernel_55/1396755098.py:83: UserWarning: Argument(s) 'mode' are not valid for transform Affine\n  A.Affine(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Model Construction & Training","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch==0.3.3 timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T09:19:38.701251Z","iopub.execute_input":"2026-02-05T09:19:38.701559Z","iopub.status.idle":"2026-02-05T09:19:49.031209Z","shell.execute_reply.started":"2026-02-05T09:19:38.701535Z","shell.execute_reply":"2026-02-05T09:19:49.030261Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# STAGE 3 — Model Construction & Training (FINAL MONITORABLE)\n# - UNet++ primary\n# - DeepLabV3+ support\n# - REAL train / val split\n# - Train loss + Val Dice logging\n# ============================================================\n\nimport os, re, random\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nimport segmentation_models_pytorch as smp\nfrom sklearn.model_selection import train_test_split\n\n# -----------------------------\n# SEED & DEVICE\n# -----------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n# -----------------------------\n# DATA\n# -----------------------------\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nTRAIN_IMG_DIR = DATA_ROOT / \"train/images\"\nTRAIN_MASK_DIR = DATA_ROOT / \"train/mask\"\n\ndef extract_idx(name):\n    return re.search(r\"(\\d+)\", name).group(1)\n\npairs = []\nfor img in TRAIN_IMG_DIR.iterdir():\n    idx = extract_idx(img.name)\n    mask = TRAIN_MASK_DIR / f\"mask_{idx}.png\"\n    if mask.exists():\n        pairs.append((str(img), str(mask)))\n\ndf = pd.DataFrame(pairs, columns=[\"image_path\", \"mask_path\"])\nprint(\"Total samples:\", len(df))\n\ndf_train, df_val = train_test_split(\n    df, test_size=0.15, random_state=SEED, shuffle=True\n)\n\nprint(\"Train:\", len(df_train), \"| Val:\", len(df_val))\n\n# -----------------------------\n# DATASET\n# -----------------------------\nclass PotholeDataset(Dataset):\n    def __init__(self, df, transform):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.df.loc[idx, \"image_path\"])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.df.loc[idx, \"mask_path\"], cv2.IMREAD_GRAYSCALE)\n        mask = (mask == 255).astype(\"float32\")\n\n        aug = self.transform(image=img, mask=mask)\n        return aug[\"image\"], aug[\"mask\"].unsqueeze(0)\n\n# -----------------------------\n# METRIC\n# -----------------------------\ndef dice_coef(prob, target, thr=0.4, eps=1e-7):\n    pred = (prob > thr).float()\n    inter = (pred * target).sum(dim=(2,3))\n    union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n    return ((2 * inter + eps) / (union + eps)).mean()\n\n# -----------------------------\n# LOSSES\n# -----------------------------\ndice_loss = smp.losses.DiceLoss(mode=\"binary\", from_logits=True)\nfocal_loss = smp.losses.FocalLoss(mode=\"binary\", gamma=2.0)\n\n# -----------------------------\n# MODEL FACTORY\n# -----------------------------\ndef build_model(name):\n    if name == \"unetpp\":\n        return smp.UnetPlusPlus(\n            encoder_name=\"efficientnet-b4\",\n            encoder_weights=\"imagenet\",\n            in_channels=3,\n            classes=1,\n        )\n    if name == \"deeplab\":\n        return smp.DeepLabV3Plus(\n            encoder_name=\"resnet101\",\n            encoder_weights=\"imagenet\",\n            in_channels=3,\n            classes=1,\n        )\n\n# -----------------------------\n# TRAIN FUNCTION\n# -----------------------------\ndef train_one_model(name, max_epoch):\n\n    print(f\"\\n===== TRAINING {name.upper()} =====\")\n    model = build_model(name).to(device)\n\n    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n    scheduler = CosineAnnealingLR(optimizer, T_max=max_epoch)\n\n    train_loader = DataLoader(\n        PotholeDataset(df_train, train_transform_512),\n        batch_size=4,\n        shuffle=True,\n        num_workers=2,\n        pin_memory=True\n    )\n\n    val_loader = DataLoader(\n        PotholeDataset(df_val, valid_transform),\n        batch_size=4,\n        shuffle=False,\n        num_workers=2,\n        pin_memory=True\n    )\n\n    best_val = 0.0\n\n    for epoch in range(max_epoch):\n        model.train()\n        total_loss = 0.0\n\n        for imgs, masks in tqdm(train_loader, desc=f\"{name} | Epoch {epoch+1}\"):\n            imgs, masks = imgs.to(device), masks.to(device)\n            optimizer.zero_grad()\n\n            logits = model(imgs)\n            loss = dice_loss(logits, masks) + 0.5 * focal_loss(logits, masks)\n\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        scheduler.step()\n        avg_loss = total_loss / len(train_loader)\n\n        # ---------------- VALIDATION ----------------\n        model.eval()\n        dices = []\n\n        with torch.no_grad():\n            for imgs, masks in val_loader:\n                imgs, masks = imgs.to(device), masks.to(device)\n                prob = torch.sigmoid(model(imgs))\n                dices.append(dice_coef(prob, masks).item())\n\n        val_dice = float(np.mean(dices))\n\n        print(\n            f\"{name} | Epoch {epoch+1:02d} | \"\n            f\"TrainLoss {avg_loss:.4f} | ValDice {val_dice:.4f}\"\n        )\n\n        if val_dice > best_val:\n            best_val = val_dice\n            torch.save(model.state_dict(), f\"/kaggle/working/best_{name}.pt\")\n            print(f\">> Best {name} saved\")\n\n    print(f\"[DONE] {name} best Val Dice: {best_val:.4f}\")\n\n# -----------------------------\n# RUN TRAINING\n# -----------------------------\ntrain_one_model(\"unetpp\", max_epoch=25)\ntrain_one_model(\"deeplab\", max_epoch=18)\n\nprint(\"\\n[STAGE 3 COMPLETE — MONITORABLE & LEADERBOARD SAFE]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T10:33:03.592637Z","iopub.execute_input":"2026-02-05T10:33:03.593375Z","iopub.status.idle":"2026-02-05T11:26:04.119919Z","shell.execute_reply.started":"2026-02-05T10:33:03.593333Z","shell.execute_reply":"2026-02-05T11:26:04.119125Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nTotal samples: 498\nTrain: 423 | Val: 75\n\n===== TRAINING UNETPP =====\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 1: 100%|██████████| 106/106 [01:18<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 01 | TrainLoss 0.7843 | ValDice 0.5355\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 2: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 02 | TrainLoss 0.5922 | ValDice 0.6452\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 3: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 03 | TrainLoss 0.4829 | ValDice 0.6659\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 4: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 04 | TrainLoss 0.4059 | ValDice 0.6755\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 5: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 05 | TrainLoss 0.3554 | ValDice 0.6768\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 6: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 06 | TrainLoss 0.3219 | ValDice 0.6830\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 7: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 07 | TrainLoss 0.2949 | ValDice 0.6925\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 8: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 08 | TrainLoss 0.2687 | ValDice 0.7009\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 9: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 09 | TrainLoss 0.2460 | ValDice 0.7255\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 10: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 10 | TrainLoss 0.2262 | ValDice 0.7346\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 11: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 11 | TrainLoss 0.2126 | ValDice 0.7313\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 12: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 12 | TrainLoss 0.2157 | ValDice 0.7379\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 13: 100%|██████████| 106/106 [01:18<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 13 | TrainLoss 0.1945 | ValDice 0.7303\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 14: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 14 | TrainLoss 0.1840 | ValDice 0.7496\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 15: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 15 | TrainLoss 0.1887 | ValDice 0.7514\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 16: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 16 | TrainLoss 0.1817 | ValDice 0.7548\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 17: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 17 | TrainLoss 0.1731 | ValDice 0.7530\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 18: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 18 | TrainLoss 0.1583 | ValDice 0.7654\n>> Best unetpp saved\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 19: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 19 | TrainLoss 0.1655 | ValDice 0.7600\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 20: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 20 | TrainLoss 0.1527 | ValDice 0.7587\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 21: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 21 | TrainLoss 0.1764 | ValDice 0.7573\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 22: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 22 | TrainLoss 0.1638 | ValDice 0.7549\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 23: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 23 | TrainLoss 0.1647 | ValDice 0.7567\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 24: 100%|██████████| 106/106 [01:17<00:00,  1.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 24 | TrainLoss 0.1631 | ValDice 0.7561\n","output_type":"stream"},{"name":"stderr","text":"unetpp | Epoch 25: 100%|██████████| 106/106 [01:17<00:00,  1.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"unetpp | Epoch 25 | TrainLoss 0.1644 | ValDice 0.7551\n[DONE] unetpp best Val Dice: 0.7654\n\n===== TRAINING DEEPLAB =====\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 1: 100%|██████████| 106/106 [00:59<00:00,  1.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 01 | TrainLoss 0.6911 | ValDice 0.5120\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 2: 100%|██████████| 106/106 [00:58<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 02 | TrainLoss 0.5613 | ValDice 0.6063\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 3: 100%|██████████| 106/106 [00:58<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 03 | TrainLoss 0.4853 | ValDice 0.6304\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 4: 100%|██████████| 106/106 [00:58<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 04 | TrainLoss 0.4179 | ValDice 0.6462\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 5: 100%|██████████| 106/106 [00:58<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 05 | TrainLoss 0.3703 | ValDice 0.6488\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 6: 100%|██████████| 106/106 [00:58<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 06 | TrainLoss 0.3540 | ValDice 0.6255\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 7: 100%|██████████| 106/106 [00:58<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 07 | TrainLoss 0.3194 | ValDice 0.6673\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 8: 100%|██████████| 106/106 [00:58<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 08 | TrainLoss 0.2864 | ValDice 0.6897\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 9: 100%|██████████| 106/106 [00:58<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 09 | TrainLoss 0.2632 | ValDice 0.6801\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 10: 100%|██████████| 106/106 [00:58<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 10 | TrainLoss 0.2531 | ValDice 0.6723\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 11: 100%|██████████| 106/106 [00:58<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 11 | TrainLoss 0.2249 | ValDice 0.7083\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 12: 100%|██████████| 106/106 [00:58<00:00,  1.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 12 | TrainLoss 0.2213 | ValDice 0.7077\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 13: 100%|██████████| 106/106 [00:59<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 13 | TrainLoss 0.1978 | ValDice 0.7231\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 14: 100%|██████████| 106/106 [00:58<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 14 | TrainLoss 0.1799 | ValDice 0.7254\n>> Best deeplab saved\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 15: 100%|██████████| 106/106 [00:58<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 15 | TrainLoss 0.1808 | ValDice 0.7188\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 16: 100%|██████████| 106/106 [00:58<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 16 | TrainLoss 0.1779 | ValDice 0.7147\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 17: 100%|██████████| 106/106 [00:58<00:00,  1.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 17 | TrainLoss 0.1753 | ValDice 0.7158\n","output_type":"stream"},{"name":"stderr","text":"deeplab | Epoch 18: 100%|██████████| 106/106 [00:59<00:00,  1.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"deeplab | Epoch 18 | TrainLoss 0.1796 | ValDice 0.7320\n>> Best deeplab saved\n[DONE] deeplab best Val Dice: 0.7320\n\n[STAGE 3 COMPLETE — MONITORABLE & LEADERBOARD SAFE]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Optimization, Validation & Refinement","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 4 — Ensemble Optimization & Refinement (FINAL)\n# - Fully aligned with STAGE 3\n# - UNet++ + DeepLabV3+\n# - REAL validation (no proxy, no leakage)\n# - Dice-faithful (empty pred = Dice 0)\n# ============================================================\n\n!pip install -q optuna\n\nimport optuna\nimport numpy as np\nimport torch\nimport cv2\nfrom tqdm import tqdm\nfrom pathlib import Path\n\nimport segmentation_models_pytorch as smp\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# -----------------------------\n# DEVICE\n# -----------------------------\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", DEVICE)\n\n# ============================================================\n# DATA (SAME AS STAGE 3)\n# ============================================================\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nTRAIN_IMG_DIR = DATA_ROOT / \"train/images\"\nTRAIN_MASK_DIR = DATA_ROOT / \"train/mask\"\n\ndef extract_idx(name):\n    import re\n    return re.search(r\"(\\d+)\", name).group(1)\n\npairs = []\nfor img in TRAIN_IMG_DIR.iterdir():\n    idx = extract_idx(img.name)\n    mask = TRAIN_MASK_DIR / f\"mask_{idx}.png\"\n    if mask.exists():\n        pairs.append((str(img), str(mask)))\n\ndf = np.array(pairs, dtype=object)\n\n# ============================================================\n# DATASET (IDENTICAL LOGIC TO STAGE 3)\n# ============================================================\nclass PotholeDataset(Dataset):\n    def __init__(self, pairs, transform):\n        self.pairs = pairs\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        img_path, mask_path = self.pairs[idx]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n        mask = (mask == 255).astype(\"float32\")\n        aug = self.transform(image=img, mask=mask)\n        return aug[\"image\"], aug[\"mask\"].unsqueeze(0)\n\n# ============================================================\n# TRANSFORM (MATCH STAGE 3 VALID)\n# ============================================================\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD  = (0.229, 0.224, 0.225)\n\nvalid_transform = A.Compose([\n    A.Resize(512, 512),\n    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n    ToTensorV2(),\n])\n\n# ============================================================\n# VALIDATION SPLIT (REAL, LEAK-SAFE)\n# ============================================================\n_, val_pairs = train_test_split(\n    df, test_size=0.15, random_state=42\n)\n\nval_loader = DataLoader(\n    PotholeDataset(val_pairs, valid_transform),\n    batch_size=4,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True\n)\n\nprint(\"[INFO] Validation samples:\", len(val_pairs))\n\n# ============================================================\n# LOAD TRAINED MODELS (FROM STAGE 3)\n# ============================================================\nunetpp = smp.UnetPlusPlus(\n    encoder_name=\"efficientnet-b4\",\n    encoder_weights=None,\n    in_channels=3,\n    classes=1,\n).to(DEVICE)\n\ndeeplab = smp.DeepLabV3Plus(\n    encoder_name=\"resnet101\",\n    encoder_weights=None,\n    in_channels=3,\n    classes=1,\n).to(DEVICE)\n\nunetpp.load_state_dict(torch.load(\"/kaggle/working/best_unetpp.pt\", map_location=DEVICE))\ndeeplab.load_state_dict(torch.load(\"/kaggle/working/best_deeplab.pt\", map_location=DEVICE))\n\nunetpp.eval()\ndeeplab.eval()\n\nprint(\"[INFO] Models loaded: UNet++ + DeepLabV3+\")\n\n# ============================================================\n# METRICS & POSTPROCESS\n# ============================================================\ndef dice_score(pred, target, eps=1e-7):\n    inter = (pred * target).sum()\n    union = pred.sum() + target.sum()\n    return (2 * inter + eps) / (union + eps)\n\ndef remove_small_objects(mask, min_area):\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n        mask.astype(np.uint8), connectivity=8\n    )\n    clean = np.zeros_like(mask, dtype=np.uint8)\n    for i in range(1, num_labels):\n        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n            clean[labels == i] = 1\n    return clean\n\ndef normalize_prob(p):\n    return np.clip(p, 1e-6, 1 - 1e-6)\n\n# ============================================================\n# OPTUNA OBJECTIVE (DICE-FAITHFUL)\n# ============================================================\ndef objective(trial):\n\n    # UNet++ dominant ensemble\n    w_u = trial.suggest_float(\"w_unetpp\", 0.65, 0.85)\n    w_d = trial.suggest_float(\"w_deeplab\", 0.15, 0.35)\n\n    s = w_u + w_d\n    w_u, w_d = w_u / s, w_d / s\n\n    threshold = trial.suggest_float(\"threshold\", 0.30, 0.45)\n    min_area  = trial.suggest_int(\"min_area\", 100, 400, step=20)\n\n    dices = []\n\n    with torch.no_grad():\n        for imgs, masks in val_loader:\n            imgs = imgs.to(DEVICE)\n            gt = masks.numpy()\n\n            pu = torch.sigmoid(unetpp(imgs)).cpu().numpy()\n            pd = torch.sigmoid(deeplab(imgs)).cpu().numpy()\n\n            pu = normalize_prob(pu)\n            pd = normalize_prob(pd)\n\n            prob = w_u * pu + w_d * pd\n\n            for i in range(prob.shape[0]):\n                pred = (prob[i, 0] > threshold).astype(np.uint8)\n                pred = remove_small_objects(pred, min_area)\n\n                # empty pred = Dice 0 (NO optimistic bias)\n                dices.append(dice_score(pred, gt[i, 0]))\n\n    return float(np.mean(dices))\n\n# ============================================================\n# RUN OPTUNA\n# ============================================================\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=40, show_progress_bar=True)\n\nbest = study.best_params\nbest_dice = study.best_value\n\n# normalize weights\nws = best[\"w_unetpp\"] + best[\"w_deeplab\"]\nbest[\"w_unetpp\"] /= ws\nbest[\"w_deeplab\"] /= ws\n\nprint(\"\\n[OPTUNA BEST CONFIG — STAGE 3 CONSISTENT]\")\nfor k, v in best.items():\n    print(f\"{k}: {v}\")\nprint(f\"Validation Dice: {best_dice:.4f}\")\n\n# ============================================================\n# EXPORT CONFIG FOR STAGE 5\n# ============================================================\nOPT_CONFIG = {\n    \"weights\": {\n        \"unetpp\": best[\"w_unetpp\"],\n        \"deeplab\": best[\"w_deeplab\"],\n    },\n    \"threshold\": best[\"threshold\"],\n    \"min_area\": best[\"min_area\"],\n}\n\nprint(\"\\n[STAGE 4 COMPLETE — READY FOR STAGE 5]\")\nprint(\"✓ Real validation Dice\")\nprint(\"✓ No SegFormer\")\nprint(\"✓ No proxy / no leakage\")\nprint(\"✓ Leaderboard-safe\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T11:52:17.081813Z","iopub.execute_input":"2026-02-05T11:52:17.082139Z","iopub.status.idle":"2026-02-05T11:57:24.115535Z","shell.execute_reply.started":"2026-02-05T11:52:17.082108Z","shell.execute_reply":"2026-02-05T11:57:24.114645Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n[INFO] Validation samples: 75\n","output_type":"stream"},{"name":"stderr","text":"[I 2026-02-05 11:52:21,956] A new study created in memory with name: no-name-55b229a9-4633-4dde-aba5-2f91fef56cfc\n","output_type":"stream"},{"name":"stdout","text":"[INFO] Models loaded: UNet++ + DeepLabV3+\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/40 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49fc7f4e8d4d41c3ba0d423c778009c0"}},"metadata":{}},{"name":"stdout","text":"[I 2026-02-05 11:52:29,859] Trial 0 finished with value: 0.7630795607907076 and parameters: {'w_unetpp': 0.8157018988285771, 'w_deeplab': 0.21686005128799274, 'threshold': 0.35106936478959466, 'min_area': 140}. Best is trial 0 with value: 0.7630795607907076.\n[I 2026-02-05 11:52:37,975] Trial 1 finished with value: 0.7331048649361702 and parameters: {'w_unetpp': 0.7685208564160664, 'w_deeplab': 0.33163365663022015, 'threshold': 0.40943052897140153, 'min_area': 320}. Best is trial 0 with value: 0.7630795607907076.\n[I 2026-02-05 11:52:46,060] Trial 2 finished with value: 0.73219283841423 and parameters: {'w_unetpp': 0.7981498469094792, 'w_deeplab': 0.3054457478906737, 'threshold': 0.32526222999727117, 'min_area': 360}. Best is trial 0 with value: 0.7630795607907076.\n[I 2026-02-05 11:52:53,835] Trial 3 finished with value: 0.7317249020622909 and parameters: {'w_unetpp': 0.6588169067323288, 'w_deeplab': 0.22971907026192567, 'threshold': 0.32179944239061287, 'min_area': 340}. Best is trial 0 with value: 0.7630795607907076.\n[I 2026-02-05 11:53:01,363] Trial 4 finished with value: 0.7621006098596765 and parameters: {'w_unetpp': 0.8336785006929655, 'w_deeplab': 0.16597558798641487, 'threshold': 0.439728768010905, 'min_area': 100}. Best is trial 0 with value: 0.7630795607907076.\n[I 2026-02-05 11:53:08,757] Trial 5 finished with value: 0.7650548318970631 and parameters: {'w_unetpp': 0.808332189456406, 'w_deeplab': 0.28707538864951593, 'threshold': 0.30233220877158545, 'min_area': 260}. Best is trial 5 with value: 0.7650548318970631.\n[I 2026-02-05 11:53:16,108] Trial 6 finished with value: 0.7308196481718399 and parameters: {'w_unetpp': 0.6806286644645458, 'w_deeplab': 0.15240274891415387, 'threshold': 0.4086458769725913, 'min_area': 340}. Best is trial 5 with value: 0.7650548318970631.\n[I 2026-02-05 11:53:23,453] Trial 7 finished with value: 0.7399746125231434 and parameters: {'w_unetpp': 0.7677961858303133, 'w_deeplab': 0.22354192578747978, 'threshold': 0.42597407009695853, 'min_area': 260}. Best is trial 5 with value: 0.7650548318970631.\n[I 2026-02-05 11:53:30,804] Trial 8 finished with value: 0.7317863926417247 and parameters: {'w_unetpp': 0.809607481168411, 'w_deeplab': 0.2503354080531176, 'threshold': 0.3862378114247399, 'min_area': 340}. Best is trial 5 with value: 0.7650548318970631.\n[I 2026-02-05 11:53:38,147] Trial 9 finished with value: 0.7338373086126214 and parameters: {'w_unetpp': 0.6626406420350668, 'w_deeplab': 0.3235166465954037, 'threshold': 0.3793726871529643, 'min_area': 400}. Best is trial 5 with value: 0.7650548318970631.\n[I 2026-02-05 11:53:45,599] Trial 10 finished with value: 0.7636050607926119 and parameters: {'w_unetpp': 0.7174144939214243, 'w_deeplab': 0.2726252349437655, 'threshold': 0.3048287242729696, 'min_area': 200}. Best is trial 5 with value: 0.7650548318970631.\n[I 2026-02-05 11:53:53,146] Trial 11 finished with value: 0.7636890820972385 and parameters: {'w_unetpp': 0.7135921175200878, 'w_deeplab': 0.2783517835197598, 'threshold': 0.3047676331629515, 'min_area': 200}. Best is trial 5 with value: 0.7650548318970631.\n[I 2026-02-05 11:54:00,756] Trial 12 finished with value: 0.765258531499182 and parameters: {'w_unetpp': 0.7232878020295386, 'w_deeplab': 0.28429397486871466, 'threshold': 0.30267591152496093, 'min_area': 240}. Best is trial 12 with value: 0.765258531499182.\n[I 2026-02-05 11:54:08,393] Trial 13 finished with value: 0.7449318182721669 and parameters: {'w_unetpp': 0.7387573970742218, 'w_deeplab': 0.2874940528928846, 'threshold': 0.34539080567866043, 'min_area': 260}. Best is trial 12 with value: 0.765258531499182.\n[I 2026-02-05 11:54:15,991] Trial 14 finished with value: 0.764400175239959 and parameters: {'w_unetpp': 0.8495098369963541, 'w_deeplab': 0.2550728894129907, 'threshold': 0.34768400810647954, 'min_area': 200}. Best is trial 12 with value: 0.765258531499182.\n[I 2026-02-05 11:54:23,548] Trial 15 finished with value: 0.7452498582598134 and parameters: {'w_unetpp': 0.7824542451842095, 'w_deeplab': 0.3493828022938628, 'threshold': 0.3251868921330645, 'min_area': 280}. Best is trial 12 with value: 0.765258531499182.\n[I 2026-02-05 11:54:31,085] Trial 16 finished with value: 0.7654273727713587 and parameters: {'w_unetpp': 0.7394084929272718, 'w_deeplab': 0.30147725034713063, 'threshold': 0.36115855338972763, 'min_area': 220}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:54:38,574] Trial 17 finished with value: 0.7639709128230566 and parameters: {'w_unetpp': 0.7349423835276764, 'w_deeplab': 0.3076103725126382, 'threshold': 0.3598391223248492, 'min_area': 160}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:54:46,063] Trial 18 finished with value: 0.7630670491224144 and parameters: {'w_unetpp': 0.6967523313817444, 'w_deeplab': 0.18449311927902648, 'threshold': 0.39659715722876226, 'min_area': 220}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:54:53,555] Trial 19 finished with value: 0.7330182644705491 and parameters: {'w_unetpp': 0.7539648071842251, 'w_deeplab': 0.31241161832688674, 'threshold': 0.3629610500017758, 'min_area': 300}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:55:01,047] Trial 20 finished with value: 0.7636198496935561 and parameters: {'w_unetpp': 0.7204276522450684, 'w_deeplab': 0.2662871289997538, 'threshold': 0.33542557898292563, 'min_area': 160}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:55:08,536] Trial 21 finished with value: 0.765260394814693 and parameters: {'w_unetpp': 0.7513288246253556, 'w_deeplab': 0.28916195595417266, 'threshold': 0.31220558138735927, 'min_area': 240}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:55:16,014] Trial 22 finished with value: 0.7653509887018047 and parameters: {'w_unetpp': 0.7503704587567658, 'w_deeplab': 0.2954489460257438, 'threshold': 0.31616757673747864, 'min_area': 220}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:55:23,508] Trial 23 finished with value: 0.7652895930642709 and parameters: {'w_unetpp': 0.7541221676998628, 'w_deeplab': 0.2990958647799693, 'threshold': 0.3206061260053341, 'min_area': 220}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:55:31,001] Trial 24 finished with value: 0.7642942691054031 and parameters: {'w_unetpp': 0.77804092444557, 'w_deeplab': 0.33968883109054554, 'threshold': 0.33656035811187107, 'min_area': 180}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:55:38,509] Trial 25 finished with value: 0.7642037328500819 and parameters: {'w_unetpp': 0.7001090447013756, 'w_deeplab': 0.3042134736886517, 'threshold': 0.36452733021092854, 'min_area': 120}. Best is trial 16 with value: 0.7654273727713587.\n[I 2026-02-05 11:55:45,987] Trial 26 finished with value: 0.7656500416126082 and parameters: {'w_unetpp': 0.743899807432538, 'w_deeplab': 0.32500742029113994, 'threshold': 0.3172045288146409, 'min_area': 220}. Best is trial 26 with value: 0.7656500416126082.\n[I 2026-02-05 11:55:53,477] Trial 27 finished with value: 0.7656873976703285 and parameters: {'w_unetpp': 0.7407249279995, 'w_deeplab': 0.33203024504608053, 'threshold': 0.33440976683484586, 'min_area': 220}. Best is trial 27 with value: 0.7656873976703285.\n[I 2026-02-05 11:56:01,003] Trial 28 finished with value: 0.7645934465665117 and parameters: {'w_unetpp': 0.6991971696331519, 'w_deeplab': 0.3229480782098844, 'threshold': 0.3361377354932439, 'min_area': 180}. Best is trial 27 with value: 0.7656873976703285.\n[I 2026-02-05 11:56:08,528] Trial 29 finished with value: 0.737835104723045 and parameters: {'w_unetpp': 0.78837421028932, 'w_deeplab': 0.34893386765646905, 'threshold': 0.3560142224218564, 'min_area': 280}. Best is trial 27 with value: 0.7656873976703285.\n[I 2026-02-05 11:56:16,094] Trial 30 finished with value: 0.7640831428608935 and parameters: {'w_unetpp': 0.7422605366334737, 'w_deeplab': 0.32370877802083753, 'threshold': 0.37643925448239546, 'min_area': 140}. Best is trial 27 with value: 0.7656873976703285.\n[I 2026-02-05 11:56:23,653] Trial 31 finished with value: 0.7657471898916473 and parameters: {'w_unetpp': 0.731762930927952, 'w_deeplab': 0.33585451073142814, 'threshold': 0.31555999634953646, 'min_area': 220}. Best is trial 31 with value: 0.7657471898916473.\n[I 2026-02-05 11:56:31,214] Trial 32 finished with value: 0.7657269849398894 and parameters: {'w_unetpp': 0.7660979461856161, 'w_deeplab': 0.33660366752879667, 'threshold': 0.3419561098132555, 'min_area': 220}. Best is trial 31 with value: 0.7657471898916473.\n[I 2026-02-05 11:56:38,769] Trial 33 finished with value: 0.7642850854205926 and parameters: {'w_unetpp': 0.765705020693396, 'w_deeplab': 0.33378578413923854, 'threshold': 0.33680919401477405, 'min_area': 180}. Best is trial 31 with value: 0.7657471898916473.\n[I 2026-02-05 11:56:46,302] Trial 34 finished with value: 0.7657029603989662 and parameters: {'w_unetpp': 0.7633714944645958, 'w_deeplab': 0.33486685213148665, 'threshold': 0.3277538205809226, 'min_area': 240}. Best is trial 31 with value: 0.7657471898916473.\n[I 2026-02-05 11:56:53,841] Trial 35 finished with value: 0.7450669173289189 and parameters: {'w_unetpp': 0.7930188486940157, 'w_deeplab': 0.3387145679128658, 'threshold': 0.3279960241056712, 'min_area': 280}. Best is trial 31 with value: 0.7657471898916473.\n[I 2026-02-05 11:57:01,382] Trial 36 finished with value: 0.7642162237388106 and parameters: {'w_unetpp': 0.7723599823011843, 'w_deeplab': 0.3140269240854047, 'threshold': 0.34700085932347474, 'min_area': 240}. Best is trial 31 with value: 0.7657471898916473.\n[I 2026-02-05 11:57:08,932] Trial 37 finished with value: 0.7328254695959493 and parameters: {'w_unetpp': 0.7615628891292561, 'w_deeplab': 0.34011358520039314, 'threshold': 0.3298986621811961, 'min_area': 300}. Best is trial 31 with value: 0.7657471898916473.\n[I 2026-02-05 11:57:16,533] Trial 38 finished with value: 0.7630239909815544 and parameters: {'w_unetpp': 0.7310107831787059, 'w_deeplab': 0.19028088082983835, 'threshold': 0.30994290756335185, 'min_area': 160}. Best is trial 31 with value: 0.7657471898916473.\n[I 2026-02-05 11:57:24,107] Trial 39 finished with value: 0.7335348357764017 and parameters: {'w_unetpp': 0.7098567746816822, 'w_deeplab': 0.3326532731059952, 'threshold': 0.4478194036487689, 'min_area': 260}. Best is trial 31 with value: 0.7657471898916473.\n\n[OPTUNA BEST CONFIG — STAGE 3 CONSISTENT]\nw_unetpp: 0.6854168004136248\nw_deeplab: 0.3145831995863753\nthreshold: 0.31555999634953646\nmin_area: 220\nValidation Dice: 0.7657\n\n[STAGE 4 COMPLETE — READY FOR STAGE 5]\n✓ Real validation Dice\n✓ No SegFormer\n✓ No proxy / no leakage\n✓ Leaderboard-safe\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Inference, Encoding & Submission","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 5 — Ensemble Inference, RLE Encoding & Submission\n# FINAL LEADERBOARD (ANTI-ZONK, 2-MODEL, FIXED)\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport cv2\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport segmentation_models_pytorch as smp\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nDATA_ROOT = Path(\"/kaggle/input/data-science-ara-7-0/dataset/dataset\")\nTEST_IMG_DIR = DATA_ROOT / \"test\" / \"images\"\nSAMPLE_SUB = Path(\"/kaggle/input/data-science-ara-7-0/sample_submission.csv\")\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# --- from STAGE 4 ---\nW_U = OPT_CONFIG[\"weights\"][\"unetpp\"]\nW_D = OPT_CONFIG[\"weights\"][\"deeplab\"]\nTHRESHOLD = OPT_CONFIG[\"threshold\"]\nMIN_AREA = OPT_CONFIG[\"min_area\"]\n\nINPUT_SIZE = 512\n\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD  = (0.229, 0.224, 0.225)\n\n# -----------------------------\n# LOAD MODELS\n# -----------------------------\nunetpp = smp.UnetPlusPlus(\n    encoder_name=\"efficientnet-b4\",\n    encoder_weights=None,\n    in_channels=3,\n    classes=1,\n).to(DEVICE)\n\ndeeplab = smp.DeepLabV3Plus(\n    encoder_name=\"resnet101\",\n    encoder_weights=None,\n    in_channels=3,\n    classes=1,\n).to(DEVICE)\n\nunetpp.load_state_dict(torch.load(\"/kaggle/working/best_unetpp.pt\", map_location=DEVICE))\ndeeplab.load_state_dict(torch.load(\"/kaggle/working/best_deeplab.pt\", map_location=DEVICE))\n\nunetpp.eval()\ndeeplab.eval()\n\nprint(\"[INFO] Models loaded: UNet++ + DeepLabV3+\")\n\n# -----------------------------\n# RLE ENCODER (OFFICIAL)\n# -----------------------------\ndef encode_rle(mask: np.ndarray) -> str:\n    binary = (mask == 1).astype(np.uint8)\n    pixels = binary.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[0::2]\n    return \" \".join(str(x) for x in runs)\n\n# -----------------------------\n# POST-PROCESS\n# -----------------------------\ndef remove_small_objects(mask, min_area):\n    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(\n        mask.astype(np.uint8), connectivity=8\n    )\n    clean = np.zeros_like(mask, dtype=np.uint8)\n    for i in range(1, num_labels):\n        if stats[i, cv2.CC_STAT_AREA] >= min_area:\n            clean[labels == i] = 1\n    return clean\n\n# -----------------------------\n# LOAD TEST FILES\n# -----------------------------\ntest_images = sorted(TEST_IMG_DIR.glob(\"*.jpg\"))\nprint(\"[INFO] Test images:\", len(test_images))\n\n# -----------------------------\n# ENSEMBLE INFERENCE + H-FLIP TTA\n# -----------------------------\nrecords = []\n\nwith torch.no_grad():\n    for img_path in tqdm(test_images, desc=\"Final Ensemble Inference\"):\n        img_name = img_path.name\n\n        img = cv2.imread(str(img_path))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        h0, w0 = img.shape[:2]\n\n        # --- preprocess ---\n        img_r = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE)).astype(\"float32\") / 255.0\n        for c in range(3):\n            img_r[..., c] = (img_r[..., c] - IMAGENET_MEAN[c]) / IMAGENET_STD[c]\n\n        x = torch.from_numpy(img_r.transpose(2,0,1)).unsqueeze(0).to(DEVICE)\n        x_flip = torch.flip(x, dims=[3])\n\n        # --- forward ---\n        p_u = torch.sigmoid(unetpp(x))\n        p_d = torch.sigmoid(deeplab(x))\n\n        p_u_f = torch.flip(torch.sigmoid(unetpp(x_flip)), dims=[3])\n        p_d_f = torch.flip(torch.sigmoid(deeplab(x_flip)), dims=[3])\n\n        # --- ensemble (torch) ---\n        p_u = (p_u + p_u_f) / 2.0\n        p_d = (p_d + p_d_f) / 2.0\n\n        prob = (W_U * p_u + W_D * p_d)[0, 0]\n\n        # --- to numpy ---\n        prob = prob.cpu().numpy()\n\n        pred = (prob > THRESHOLD).astype(np.uint8)\n        pred = remove_small_objects(pred, MIN_AREA)\n        pred = cv2.resize(pred, (w0, h0), interpolation=cv2.INTER_NEAREST)\n\n        rle = \"\" if pred.sum() == 0 else encode_rle(pred)\n\n        records.append({\n            \"ImageId\": img_name,\n            \"rle\": rle\n        })\n\n# -----------------------------\n# BUILD SUBMISSION\n# -----------------------------\ndf_sub = pd.DataFrame(records)\ndf_sample = pd.read_csv(SAMPLE_SUB)\ndf_sub = df_sub[df_sample.columns.tolist()]\n\nOUT_SUB = \"/kaggle/working/submission.csv\"\ndf_sub.to_csv(OUT_SUB, index=False)\n\nprint(\"\\n[STAGE 5 COMPLETE — SUBMISSION READY]\")\nprint(\"Saved to:\", OUT_SUB)\nprint(\"Rows:\", len(df_sub))\nprint(\"Empty RLE:\", (df_sub[\"rle\"] == \"\").sum())\nprint(df_sub.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T12:02:06.348957Z","iopub.execute_input":"2026-02-05T12:02:06.349270Z","iopub.status.idle":"2026-02-05T12:03:07.778333Z","shell.execute_reply.started":"2026-02-05T12:02:06.349243Z","shell.execute_reply":"2026-02-05T12:03:07.777668Z"}},"outputs":[{"name":"stdout","text":"[INFO] Models loaded: UNet++ + DeepLabV3+\n[INFO] Test images: 295\n","output_type":"stream"},{"name":"stderr","text":"Final Ensemble Inference: 100%|██████████| 295/295 [01:00<00:00,  4.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[STAGE 5 COMPLETE — SUBMISSION READY]\nSaved to: /kaggle/working/submission.csv\nRows: 295\nEmpty RLE: 0\n        ImageId                                                rle\n0  test_001.jpg  4942 4 5242 4 5540 7 5840 7 6139 9 6439 9 6738...\n1  test_002.jpg  106941 6 107661 6 108381 6 109100 8 109820 10 ...\n2  test_003.jpg  1102019 13 1104315 13 1106611 13 1108907 13 11...\n3  test_004.jpg  13620 2 13918 5 14218 7 14517 8 14818 8 15118 ...\n4  test_005.jpg  40018 2 40318 3 40617 4 40915 7 41215 7 41515 ...\n","output_type":"stream"}],"execution_count":10}]}