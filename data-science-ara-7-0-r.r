{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Understanding & Preparation","metadata":{}},{"cell_type":"markdown","source":"Config & File Loading","metadata":{}},{"cell_type":"code","source":"suppressPackageStartupMessages({\n  library(torch)\n  library(luz)\n  library(torchvision)\n  library(tibble)\n  library(dplyr)\n  library(data.table)\n  library(magrittr)\n  library(imager)\n  library(progress)\n  library(caret)\n  library(mlr3)\n  library(mlr3learners)\n  library(mlr3tuning)\n  library(paradox)\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:48:31.378128Z","iopub.execute_input":"2026-02-16T13:48:31.379868Z","iopub.status.idle":"2026-02-16T13:48:31.393684Z","shell.execute_reply":"2026-02-16T13:48:31.391752Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"packages <- c(\n  \"torch\",\n  \"luz\",\n  \"torchvision\",\n  \"tibble\",\n  \"dplyr\",\n  \"data.table\",\n  \"magrittr\",\n  \"imager\",\n  \"progress\",\n  \"caret\",\n  \"mlr3\",\n  \"mlr3learners\",\n  \"mlr3tuning\",\n  \"paradox\"\n)\n\ninstalled <- rownames(installed.packages())\n\nfor (p in packages) {\n  if (!(p %in% installed)) {\n    install.packages(p)\n  }\n}\n\nlibrary(torch)\nlibrary(luz)\nlibrary(torchvision)\n\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(magrittr)\n\nlibrary(imager)\nlibrary(progress)\n\nlibrary(caret)\n\nlibrary(mlr3)\nlibrary(mlr3learners)\nlibrary(mlr3tuning)\nlibrary(paradox)\n\nSEED <- 42\nset.seed(SEED)\ntorch_manual_seed(SEED)\n\ndevice <- if (cuda_is_available()) torch_device(\"cuda\") else torch_device(\"cpu\")\ncat(\"Device:\", device$type, \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:48:34.757311Z","iopub.execute_input":"2026-02-16T13:48:34.759608Z","iopub.status.idle":"2026-02-16T13:48:34.849946Z","shell.execute_reply":"2026-02-16T13:48:34.847420Z"}},"outputs":[{"name":"stdout","text":"Device: cpu \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"DATA_ROOT <- \"/kaggle/input/competitions/data-science-ara-7-0/dataset/dataset\"\n\nif (!dir.exists(DATA_ROOT)) {\n  stop(\"DATA_ROOT not found. Check Kaggle structure.\")\n}\n\ncat(\"[INFO] Using DATA_ROOT:\", DATA_ROOT, \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:52:23.060234Z","iopub.execute_input":"2026-02-16T13:52:23.062048Z","iopub.status.idle":"2026-02-16T13:52:23.085114Z","shell.execute_reply":"2026-02-16T13:52:23.082971Z"}},"outputs":[{"name":"stdout","text":"[INFO] Using DATA_ROOT: /kaggle/input/competitions/data-science-ara-7-0/dataset/dataset \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"TRAIN_IMG_DIR  <- file.path(DATA_ROOT, \"train\", \"images\")\nTRAIN_MASK_DIR <- file.path(DATA_ROOT, \"train\", \"mask\")\nTEST_IMG_DIR   <- file.path(DATA_ROOT, \"test\", \"images\")\n\ndirs <- c(TRAIN_IMG_DIR, TRAIN_MASK_DIR, TEST_IMG_DIR)\n\nfor (d in dirs) {\n  if (!dir.exists(d)) {\n    stop(paste(\"Directory not found:\", d))\n  }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:52:24.572760Z","iopub.execute_input":"2026-02-16T13:52:24.574793Z","iopub.status.idle":"2026-02-16T13:52:24.604065Z","shell.execute_reply":"2026-02-16T13:52:24.601664Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\npattern_img <- \"\\\\.(jpg|jpeg|png)$\"\n\ntrain_images <- sort(list.files(\n  TRAIN_IMG_DIR,\n  pattern = pattern_img,\n  full.names = TRUE,\n  ignore.case = TRUE\n))\n\ntrain_masks <- sort(list.files(\n  TRAIN_MASK_DIR,\n  pattern = pattern_img,\n  full.names = TRUE,\n  ignore.case = TRUE\n))\n\ntest_images <- sort(list.files(\n  TEST_IMG_DIR,\n  pattern = pattern_img,\n  full.names = TRUE,\n  ignore.case = TRUE\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:52:26.598660Z","iopub.execute_input":"2026-02-16T13:52:26.600374Z","iopub.status.idle":"2026-02-16T13:52:26.644935Z","shell.execute_reply":"2026-02-16T13:52:26.642912Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"cat(\"====================================\\n\")\ncat(\"[INFO] Train images :\", length(train_images), \"\\n\")\ncat(\"[INFO] Train masks  :\", length(train_masks), \"\\n\")\ncat(\"[INFO] Test images  :\", length(test_images), \"\\n\")\ncat(\"====================================\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:52:28.651842Z","iopub.execute_input":"2026-02-16T13:52:28.654014Z","iopub.status.idle":"2026-02-16T13:52:28.691151Z","shell.execute_reply":"2026-02-16T13:52:28.688689Z"}},"outputs":[{"name":"stdout","text":"====================================\n[INFO] Train images : 498 \n[INFO] Train masks  : 498 \n[INFO] Test images  : 295 \n====================================\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Pair Image Mask & Manifest","metadata":{}},{"cell_type":"code","source":"extract_index <- function(name) {\n  m <- regexpr(\"[0-9]+\", name)\n  if (m[1] != -1) {\n    return(regmatches(name, m))\n  } else {\n    return(NA)\n  }\n}\n\nmask_index <- list()\n\nfor (m in train_masks) {\n  stem <- tools::file_path_sans_ext(basename(m))\n  idx  <- extract_index(stem)\n  \n  if (!is.na(idx)) {\n    mask_index[[idx]] <- m\n  }\n}\n\npairs <- list()\n\nfor (img in train_images) {\n  stem <- tools::file_path_sans_ext(basename(img))\n  idx  <- extract_index(stem)\n  \n  if (!is.na(idx) && !is.null(mask_index[[idx]])) {\n    pairs[[length(pairs) + 1]] <- list(\n      image_path = img,\n      mask_path  = mask_index[[idx]],\n      id         = idx\n    )\n  }\n}\n\nif (length(pairs) == 0) {\n  stop(\"No valid image-mask pairs found\")\n}\n\ncat(\"[INFO] Valid image-mask pairs:\", length(pairs), \"\\n\")\n\ndf_manifest <- data.frame(\n  image_path = sapply(pairs, function(x) x$image_path),\n  mask_path  = sapply(pairs, function(x) x$mask_path),\n  id         = sapply(pairs, function(x) x$id),\n  stringsAsFactors = FALSE\n)\n\ncat(\"[INFO] Final training samples:\", nrow(df_manifest), \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:53:38.318894Z","iopub.execute_input":"2026-02-16T13:53:38.321200Z","iopub.status.idle":"2026-02-16T13:53:38.469368Z","shell.execute_reply":"2026-02-16T13:53:38.467157Z"}},"outputs":[{"name":"stdout","text":"[INFO] Valid image-mask pairs: 498 \n[INFO] Final training samples: 498 \n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Morphology & Dice Riks Analysis","metadata":{}},{"cell_type":"code","source":"records <- list()\nall_component_areas <- c()\n\npb <- progress::progress_bar$new(\n  format = \"Analyzing dataset [:bar] :percent\",\n  total = length(pairs),\n  clear = FALSE,\n  width = 60\n)\n\nfor (i in seq_along(pairs)) {\n  \n  pb$tick()\n  \n  mask_path <- pairs[[i]]$mask_path\n  \n  # Read grayscale image\n  mask_img <- imager::load.image(mask_path)\n  \n  # Convert to matrix\n  mask_mat <- as.matrix(mask_img[,,1,1])\n  \n  h <- nrow(mask_mat)\n  w <- ncol(mask_mat)\n  total_pixels <- h * w\n  \n  # Binary mask (255 foreground assumption)\n  bin_mask <- ifelse(mask_mat == 255, 1, 0)\n  \n  pothole_pixels <- sum(bin_mask)\n  area_ratio <- pothole_pixels / total_pixels\n  \n  # Connected components\n  labeled <- imager::label(as.cimg(bin_mask), high_connectivity = TRUE)\n  label_vec <- as.vector(labeled)\n  \n  component_table <- table(label_vec)\n  \n  # Remove background (label 0)\n  if (\"0\" %in% names(component_table)) {\n    component_table <- component_table[names(component_table) != \"0\"]\n  }\n  \n  component_areas <- as.numeric(component_table)\n  \n  if (length(component_areas) > 0) {\n    all_component_areas <- c(all_component_areas, component_areas)\n  }\n  \n  records[[i]] <- list(\n    image = basename(pairs[[i]]$image_path),\n    height = h,\n    width = w,\n    has_pothole = as.integer(pothole_pixels > 0),\n    area_ratio = area_ratio,\n    total_pothole_pixels = pothole_pixels,\n    num_components = length(component_areas),\n    max_component_ratio = ifelse(\n      length(component_areas) > 0,\n      max(component_areas) / total_pixels,\n      0\n    ),\n    min_component_pixels = ifelse(\n      length(component_areas) > 0,\n      min(component_areas),\n      0\n    )\n  )\n}\n\ndf <- do.call(rbind, lapply(records, as.data.frame))\n\ncat(\"[INFO] Dataset analysis complete\\n\")\ncat(\"[INFO] Total samples:\", nrow(df), \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:54:27.462744Z","iopub.execute_input":"2026-02-16T13:54:27.464871Z","execution_failed":"2026-02-16T13:57:22.100Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Insight, Prior & Feasibility","metadata":{}},{"cell_type":"code","source":"cat(\"\\n[INSIGHT] Pothole presence distribution:\\n\")\nprint(table(df$has_pothole))\n\n# Empty mask ratio\nempty_ratio <- mean(df$has_pothole == 0)\n\ncat(sprintf(\"\\n[INSIGHT] Empty-mask ratio: %.2f%%\\n\", empty_ratio * 100))\n\ncat(\"\\n[INSIGHT] Pothole area ratio:\\n\")\n\narea_stats <- summary(df$area_ratio)\n\narea_quantiles <- quantile(\n  df$area_ratio,\n  probs = c(0.10, 0.25, 0.50, 0.75, 0.90),\n  na.rm = TRUE\n)\n\nprint(area_stats)\ncat(\"\\nCustom percentiles:\\n\")\nprint(area_quantiles)\n\ncat(\"\\n[INSIGHT] Number of components per image:\\n\")\nprint(summary(df$num_components))\n\ncat(\"\\n[INSIGHT] Dominant component ratio:\\n\")\nprint(summary(df$max_component_ratio))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"comp_series <- all_component_areas\n\ncat(\"\\n[INSIGHT] Connected component area (pixels):\\n\")\n\n# Summary statistics\nprint(summary(comp_series))\n\n# Custom percentiles\npercentiles <- quantile(\n  comp_series,\n  probs = c(0.10, 0.25, 0.50, 0.75, 0.90),\n  na.rm = TRUE\n)\n\ncat(\"\\nCustom percentiles:\\n\")\nprint(percentiles)\n\nmin_area_candidate <- as.integer(\n  quantile(comp_series, probs = 0.10, na.rm = TRUE)\n)\n\ncat(sprintf(\"\\n[RECOMMENDATION] Candidate MIN_AREA: ~%d pixels\\n\",\n            min_area_candidate))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tiny_image_ratio <- mean(df$area_ratio < 0.01)\n\ncat(\"\\n[FEASIBILITY CHECK]\\n\")\ncat(sprintf(\"Images with pothole <1%% area: %.2f%%\\n\",\n            tiny_image_ratio * 100))\n\n# Feasibility classification\nif (tiny_image_ratio > 0.6) {\n  feasibility <- \"HARD\"\n} else if (tiny_image_ratio > 0.4) {\n  feasibility <- \"MODERATE\"\n} else {\n  feasibility <- \"FAVORABLE\"\n}\n\ncat(sprintf(\"[FEASIBILITY STATUS] %s\\n\", feasibility))\n\ncat(\"\\n[THRESHOLD PRIOR]\\n\")\ncat(\"→ Start sweep in range: 0.30 – 0.45\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing & Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"Normalization & Base Config","metadata":{}},{"cell_type":"code","source":"IMG_SIZE <- 512\n\nIMAGENET_MEAN <- c(0.485, 0.456, 0.406)\nIMAGENET_STD  <- c(0.229, 0.224, 0.225)\n\ncat(\"[INFO] IMG_SIZE:\", IMG_SIZE, \"\\n\")\ncat(\"[INFO] IMAGENET_MEAN:\", paste(IMAGENET_MEAN, collapse = \", \"), \"\\n\")\ncat(\"[INFO] IMAGENET_STD :\", paste(IMAGENET_STD, collapse = \", \"), \"\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Transform Factory","metadata":{}},{"cell_type":"code","source":"build_base_transform <- function() {\n  \n  function(img_path) {\n    \n    # Load image (RGB)\n    img <- torchvision::image_read(img_path)\n    \n    # Resize\n    img <- torchvision::transform_resize(\n      img,\n      size = c(IMG_SIZE, IMG_SIZE)\n    )\n    \n    # Convert to float [0,1]\n    img <- img$to(dtype = torch_float()) / 255\n    \n    # Normalize (ImageNet)\n    mean <- torch_tensor(IMAGENET_MEAN)$view(c(3,1,1))\n    std  <- torch_tensor(IMAGENET_STD)$view(c(3,1,1))\n    \n    img <- (img - mean) / std\n    \n    return(img)\n  }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train Augmentation","metadata":{}},{"cell_type":"code","source":"build_train_transform <- function() {\n  \n  function(img_path, mask_path) {\n    \n    img  <- torchvision::image_read(img_path)\n    mask <- torchvision::image_read(mask_path)\n    \n    # Resize\n    img  <- torchvision::transform_resize(img,  c(IMG_SIZE, IMG_SIZE))\n    mask <- torchvision::transform_resize(mask, c(IMG_SIZE, IMG_SIZE))\n    \n    # Random horizontal flip\n    if (runif(1) < 0.5) {\n      img  <- torchvision::transform_hflip(img)\n      mask <- torchvision::transform_hflip(mask)\n    }\n    \n    # Convert to float\n    img  <- img$to(dtype = torch_float()) / 255\n    mask <- mask$to(dtype = torch_float()) / 255\n    \n    # Normalize image only\n    mean <- torch_tensor(IMAGENET_MEAN)$view(c(3,1,1))\n    std  <- torch_tensor(IMAGENET_STD)$view(c(3,1,1))\n    img  <- (img - mean) / std\n    \n    return(list(image = img, mask = mask))\n  }\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Valid & Test","metadata":{}},{"cell_type":"code","source":"build_valid_transform <- function() {\n  \n  function(img_path, mask_path) {\n    \n    img  <- torchvision::image_read(img_path)\n    mask <- torchvision::image_read(mask_path)\n    \n    # Resize\n    img  <- torchvision::transform_resize(img,  c(IMG_SIZE, IMG_SIZE))\n    mask <- torchvision::transform_resize(mask, c(IMG_SIZE, IMG_SIZE))\n    \n    # Convert to float\n    img  <- img$to(dtype = torch_float()) / 255\n    mask <- mask$to(dtype = torch_float()) / 255\n    \n    # Normalize image only\n    mean <- torch_tensor(IMAGENET_MEAN)$view(c(3,1,1))\n    std  <- torch_tensor(IMAGENET_STD)$view(c(3,1,1))\n    \n    img <- (img - mean) / std\n    \n    return(list(image = img, mask = mask))\n  }\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"build_test_transform <- function() {\n  \n  function(img_path) {\n    \n    img <- torchvision::image_read(img_path)\n    \n    img <- torchvision::transform_resize(img, c(IMG_SIZE, IMG_SIZE))\n    \n    img <- img$to(dtype = torch_float()) / 255\n    \n    mean <- torch_tensor(IMAGENET_MEAN)$view(c(3,1,1))\n    std  <- torch_tensor(IMAGENET_STD)$view(c(3,1,1))\n    \n    img <- (img - mean) / std\n    \n    return(img)\n  }\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Construction & Training","metadata":{}},{"cell_type":"markdown","source":"Seed, Device, Split","metadata":{}},{"cell_type":"code","source":"SEED <- 42\n\nset.seed(SEED)\ntorch_manual_seed(SEED)\n\ndevice <- if (cuda_is_available()) {\n  torch_device(\"cuda\")\n} else {\n  torch_device(\"cpu\")\n}\n\ncat(\"Device:\", device$type, \"\\n\")\n\nset.seed(SEED)\n\nn <- nrow(df_manifest)\nval_size <- floor(0.15 * n)\n\nval_indices <- sample(seq_len(n), size = val_size)\n\ndf_val   <- df_manifest[val_indices, ]\ndf_train <- df_manifest[-val_indices, ]\n\ncat(\"Train:\", nrow(df_train), \"| Val:\", nrow(df_val), \"\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dataset Class","metadata":{}},{"cell_type":"code","source":"PotholeDataset <- dataset(\n  name = \"PotholeDataset\",\n  \n  initialize = function(df, transform = NULL) {\n    self$df <- df\n    self$transform <- transform\n  },\n  \n  .getitem = function(i) {\n    \n    img_path  <- self$df$image_path[i]\n    mask_path <- self$df$mask_path[i]\n    \n    # Load image (RGB)\n    img <- torchvision::image_read(img_path)\n    \n    # Load mask (grayscale → take first channel)\n    mask <- torchvision::image_read(mask_path)[1,,]\n    \n    # Convert mask to binary (==255)\n    mask <- (mask == 255)$to(dtype = torch_float())\n    \n    if (!is.null(self$transform)) {\n      out <- self$transform(img_path, mask_path)\n      img  <- out$image\n      mask <- out$mask\n    }\n    \n    # Add channel dimension to mask (1 x H x W)\n    mask <- mask$unsqueeze(1)\n    \n    return(list(img, mask))\n  },\n  \n  .length = function() {\n    nrow(self$df)\n  }\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Loss, Metric, Model Factory","metadata":{}},{"cell_type":"code","source":"dice_coef <- function(prob, target, thr = 0.40, eps = 1e-7) {\n  \n  pred <- (prob > thr)$to(dtype = torch_float())\n  \n  inter <- (pred * target)$sum(dim = c(3,4))\n  union <- pred$sum(dim = c(3,4)) + target$sum(dim = c(3,4))\n  \n  dice <- (2 * inter + eps) / (union + eps)\n  \n  dice$mean()\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dice_loss <- function(logits, target, eps = 1e-7) {\n  \n  prob <- torch_sigmoid(logits)\n  \n  inter <- (prob * target)$sum(dim = c(3,4))\n  union <- prob$sum(dim = c(3,4)) + target$sum(dim = c(3,4))\n  \n  dice <- (2 * inter + eps) / (union + eps)\n  \n  1 - dice$mean()\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"focal_loss <- function(logits, target, gamma = 2.0) {\n  \n  prob <- torch_sigmoid(logits)\n  \n  bce <- nnf_binary_cross_entropy_with_logits(\n    logits, target, reduction = \"none\"\n  )\n  \n  pt <- torch_exp(-bce)\n  \n  loss <- ((1 - pt)^gamma) * bce\n  \n  loss$mean()\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"build_model <- function() {\n  \n  nn_module(\n    initialize = function() {\n      \n      self$conv1 <- nn_conv2d(3, 32, 3, padding = 1)\n      self$conv2 <- nn_conv2d(32, 64, 3, padding = 1)\n      self$conv3 <- nn_conv2d(64, 1, 1)\n    },\n    \n    forward = function(x) {\n      x <- nnf_relu(self$conv1(x))\n      x <- nnf_relu(self$conv2(x))\n      x <- self$conv3(x)\n      x\n    }\n  )\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train Loop","metadata":{}},{"cell_type":"code","source":"train_one_model <- function(model, train_dataset, val_dataset, max_epoch = 20) {\n  \n  cat(\"\\n===== TRAINING MODEL =====\\n\")\n  \n  model <- model$to(device = device)\n  \n  optimizer <- optim_adamw(\n    model$parameters,\n    lr = 1e-4,\n    weight_decay = 1e-4\n  )\n  \n  scheduler <- lr_cosine_annealing_lr(\n    optimizer,\n    T_max = max_epoch\n  )\n  \n  train_loader <- dataloader(\n    train_dataset,\n    batch_size = 4,\n    shuffle = TRUE\n  )\n  \n  val_loader <- dataloader(\n    val_dataset,\n    batch_size = 4,\n    shuffle = FALSE\n  )\n  \n  best_val <- 0\n  \n  for (epoch in 1:max_epoch) {\n    \n    # -------- TRAIN --------\n    model$train()\n    total_loss <- 0\n    \n    coro::loop(for (b in train_loader) {\n      \n      imgs  <- b[[1]]$to(device = device)\n      masks <- b[[2]]$to(device = device)\n      \n      optimizer$zero_grad()\n      \n      logits <- model(imgs)\n      \n      loss <- dice_loss(logits, masks) +\n              0.6 * focal_loss(logits, masks)\n      \n      loss$backward()\n      optimizer$step()\n      \n      total_loss <- total_loss + loss$item()\n    })\n    \n    scheduler$step()\n    \n    avg_loss <- total_loss / length(train_loader)\n    \n    # -------- VALID --------\n    model$eval()\n    dices <- c()\n    \n    coro::loop(for (b in val_loader) {\n      \n      imgs  <- b[[1]]$to(device = device)\n      masks <- b[[2]]$to(device = device)\n      \n      prob <- torch_sigmoid(model(imgs))\n      \n      dice_val <- dice_coef(prob, masks)$item()\n      dices <- c(dices, dice_val)\n    })\n    \n    val_dice <- mean(dices)\n    \n    cat(sprintf(\n      \"Epoch %02d | TrainLoss %.4f | ValDice %.4f\\n\",\n      epoch, avg_loss, val_dice\n    ))\n    \n    if (val_dice > best_val) {\n      best_val <- val_dice\n      torch_save(model$state_dict(), \"/kaggle/working/best_model.pt\")\n      cat(\">> Best model saved\\n\")\n    }\n  }\n  \n  cat(sprintf(\"[DONE] Best Val Dice: %.4f\\n\", best_val))\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run Training","metadata":{}},{"cell_type":"code","source":"cat(\"\\nTraining UNet-like model\\n\")\ntrain_one_model(model_unet, train_dataset, val_dataset, max_epoch = 28)\n\ncat(\"\\nTraining DeepLab-like model\\n\")\ntrain_one_model(model_deeplab, train_dataset, val_dataset, max_epoch = 20)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimization, Validation & Refinement","metadata":{}},{"cell_type":"markdown","source":"Setup","metadata":{}},{"cell_type":"code","source":"device <- if (cuda_is_available()) {\n  torch_device(\"cuda\")\n} else {\n  torch_device(\"cpu\")\n}\n\ncat(\"Device:\", device$type, \"\\n\")\n\ncat(\"[INFO] Validation samples:\", nrow(df_val), \"\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Validation Loader","metadata":{}},{"cell_type":"code","source":"val_dataset <- PotholeDataset(\n  df = df_val,\n  transform = build_valid_transform()\n)\n\nval_loader <- dataloader(\n  dataset = val_dataset,\n  batch_size = 4,\n  shuffle = FALSE\n)\n\ncat(\"[INFO] Validation loader ready\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load Models","metadata":{}},{"cell_type":"code","source":"model_unet <- build_unet_model()\nmodel_unet$to(device = device)\n\nstate_dict <- torch_load(\"/kaggle/working/best_unet.pt\")\nmodel_unet$load_state_dict(state_dict)\n\nmodel_unet$eval()\n\ncat(\"Model loaded\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Metric & Postprocess","metadata":{}},{"cell_type":"code","source":"dice_score <- function(pred, target, eps = 1e-7) {\n  \n  inter <- (pred * target)$sum()\n  union <- pred$sum() + target$sum()\n  \n  (2 * inter + eps) / (union + eps)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"remove_small_objects <- function(mask, min_area) {\n  \n  # mask: matrix 0/1\n  \n  bin_mask <- as.cimg(mask)\n  \n  # Connected components (8-connectivity)\n  labeled <- imager::label(bin_mask, high_connectivity = TRUE)\n  \n  labels_vec <- as.vector(labeled)\n  comp_table <- table(labels_vec)\n  \n  clean_mask <- matrix(0, nrow = nrow(mask), ncol = ncol(mask))\n  \n  for (lab in names(comp_table)) {\n    \n    if (lab == \"0\") next  # skip background\n    \n    if (comp_table[[lab]] >= min_area) {\n      clean_mask[labeled == as.numeric(lab)] <- 1\n    }\n  }\n  \n  clean_mask\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Optuna Objective","metadata":{}},{"cell_type":"code","source":"objective_function <- function(w_u, w_d, threshold, min_area) {\n  \n  # Normalize weights\n  s <- w_u + w_d\n  w_u <- w_u / s\n  w_d <- w_d / s\n  \n  dices <- c()\n  \n  model_unet$eval()\n  model_deeplab$eval()\n  \n  coro::loop(for (b in val_loader) {\n    \n    imgs  <- b[[1]]$to(device = device)\n    masks <- b[[2]]$to(device = device)\n    \n    pu <- torch_sigmoid(model_unet(imgs))$to(device=\"cpu\")\n    pd <- torch_sigmoid(model_deeplab(imgs))$to(device=\"cpu\")\n    \n    prob <- w_u * pu + w_d * pd\n    \n    batch_size <- prob$size(1)\n    \n    for (i in 1:batch_size) {\n      \n      pred <- (prob[i,1,,] > threshold)$to(dtype=torch_float())\n      pred_mat <- as.matrix(pred)\n      \n      pred_clean <- remove_small_objects(pred_mat, min_area)\n      \n      gt <- as.matrix(masks[i,1,,]$to(device=\"cpu\"))\n      \n      dices <- c(dices, dice_score(\n        torch_tensor(pred_clean),\n        torch_tensor(gt)\n      )$item())\n    }\n  })\n  \n  mean(dices)\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_score <- 0\n\nfor (w in seq(0.3, 0.7, by=0.1)) {\n  for (thr in seq(0.30, 0.45, by=0.05)) {\n    for (area in seq(100, 400, by=50)) {\n      \n      score <- objective_function(\n        w_u = w,\n        w_d = 1 - w,\n        threshold = thr,\n        min_area = area\n      )\n      \n      if (score > best_score) {\n        best_score <- score\n        cat(\"New Best:\", best_score,\n            \"| w:\", w,\n            \"| thr:\", thr,\n            \"| area:\", area, \"\\n\")\n      }\n    }\n  }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run Optuna","metadata":{}},{"cell_type":"code","source":"set.seed(42)\n\nn_trials <- 40\nbest_score <- 0\nbest_params <- list()\n\nfor (trial in 1:n_trials) {\n  \n  # Random sample\n  w_unetpp  <- runif(1, 0.3, 0.7)\n  w_deeplab <- runif(1, 0.3, 0.7)\n  \n  threshold <- runif(1, 0.30, 0.45)\n  min_area  <- sample(seq(100, 400, by=20), 1)\n  \n  score <- objective_function(\n    w_u = w_unetpp,\n    w_d = w_deeplab,\n    threshold = threshold,\n    min_area = min_area\n  )\n  \n  if (score > best_score) {\n    best_score <- score\n    best_params <- list(\n      w_unetpp = w_unetpp,\n      w_deeplab = w_deeplab,\n      threshold = threshold,\n      min_area = min_area\n    )\n    \n    cat(\"New Best:\", best_score, \"\\n\")\n  }\n}\n\n# Normalize weights\nws <- best_params$w_unetpp + best_params$w_deeplab\nbest_params$w_unetpp <- best_params$w_unetpp / ws\nbest_params$w_deeplab <- best_params$w_deeplab / ws\n\nOPT_CONFIG <- list(\n  weights = list(\n    unetpp = best_params$w_unetpp,\n    deeplab = best_params$w_deeplab\n  ),\n  threshold = best_params$threshold,\n  min_area = best_params$min_area\n)\n\ncat(\"\\n[BEST CONFIG]\\n\")\nprint(OPT_CONFIG)\n\ncat(sprintf(\"Validation Dice: %.4f\\n\", best_score))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference, Encoding & Submission","metadata":{}},{"cell_type":"markdown","source":"Setup","metadata":{}},{"cell_type":"code","source":"device <- if (cuda_is_available()) {\n  torch_device(\"cuda\")\n} else {\n  torch_device(\"cpu\")\n}\n\ncat(\"Device:\", device$type, \"\\n\")\n\n\nTEST_IMG_DIR <- file.path(DATA_ROOT, \"test\", \"images\")\n\nSAMPLE_SUB <- \"/kaggle/input/data-science-ara-7-0/sample_submission.csv\"\n\nW_U <- OPT_CONFIG$weights$unetpp\nW_D <- OPT_CONFIG$weights$deeplab\n\nTHRESHOLD <- OPT_CONFIG$threshold\nMIN_AREA  <- OPT_CONFIG$min_area\n\ncat(\"Using optimized ensemble config\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load Models","metadata":{}},{"cell_type":"code","source":"model_unet <- build_unet_model()\nmodel_unet$to(device = device)\n\nstate_dict <- torch_load(\"/kaggle/working/best_unet.pt\")\nmodel_unet$load_state_dict(state_dict)\n\nmodel_unet$eval()\n\ncat(\"Model loaded\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nTest Transform","metadata":{}},{"cell_type":"code","source":"build_test_transform <- function() {\n  \n  function(img_path) {\n    \n    # Load image (RGB tensor C x H x W)\n    img <- torchvision::image_read(img_path)\n    \n    # Resize\n    img <- torchvision::transform_resize(\n      img,\n      size = c(IMG_SIZE, IMG_SIZE)\n    )\n    \n    # Convert to float [0,1]\n    img <- img$to(dtype = torch_float()) / 255\n    \n    # Normalize (ImageNet)\n    mean <- torch_tensor(IMAGENET_MEAN)$view(c(3,1,1))\n    std  <- torch_tensor(IMAGENET_STD)$view(c(3,1,1))\n    \n    img <- (img - mean) / std\n    \n    return(img)\n  }\n}\n\n# Create transform instance\ntest_transform <- build_test_transform()\n\ncat(\"Test transform ready\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"RLE","metadata":{}},{"cell_type":"code","source":"encode_rle <- function(mask) {\n  \n  # mask: matrix 0/1\n  \n  binary <- ifelse(mask == 1, 1, 0)\n  \n  # Transpose lalu flatten (column-major)\n  pixels <- as.vector(t(binary))\n  \n  # Add padding 0 at beginning and end\n  pixels <- c(0, pixels, 0)\n  \n  # Find where values change\n  runs <- which(pixels[-1] != pixels[-length(pixels)])\n  \n  # Start positions\n  starts <- runs[seq(1, length(runs), by = 2)]\n  \n  # Lengths\n  lengths <- runs[seq(2, length(runs), by = 2)] - starts\n  \n  # Combine\n  rle <- paste(\n    as.vector(rbind(starts, lengths)),\n    collapse = \" \"\n  )\n  \n  return(rle)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Final Ensemble INference","metadata":{}},{"cell_type":"code","source":"test_images <- list.files(\n  TEST_IMG_DIR,\n  pattern = \"\\\\.jpg$\",\n  full.names = TRUE\n)\n\nrecords <- list()\n\nmodel_unet$eval()\nmodel_deeplab$eval()\n\nfor (img_path in test_images) {\n  \n  img_name <- basename(img_path)\n  \n  # Load image\n  img_raw <- imager::load.image(img_path)\n  \n  h0 <- dim(img_raw)[1]\n  w0 <- dim(img_raw)[2]\n  \n  # Apply transform\n  x <- test_transform(img_path)\n  x <- x$unsqueeze(1)$to(device = device)\n  \n  # Horizontal flip TTA\n  x_flip <- torch_flip(x, dims = 4)\n  \n  # Forward\n  p_u <- torch_sigmoid(model_unet(x))\n  p_d <- torch_sigmoid(model_deeplab(x))\n  \n  p_u_f <- torch_flip(torch_sigmoid(model_unet(x_flip)), dims = 4)\n  p_d_f <- torch_flip(torch_sigmoid(model_deeplab(x_flip)), dims = 4)\n  \n  p_u <- (p_u + p_u_f) / 2\n  p_d <- (p_d + p_d_f) / 2\n  \n  prob <- (W_U * p_u + W_D * p_d)[1,1,,]$to(device=\"cpu\")\n  \n  prob_mat <- as.matrix(prob)\n  \n  pred <- ifelse(prob_mat > THRESHOLD, 1, 0)\n  pred <- remove_small_objects(pred, MIN_AREA)\n  \n  # Resize back\n  pred_img <- imager::resize(as.cimg(pred), size_x = w0, size_y = h0)\n  pred_mat <- as.matrix(pred_img)\n  \n  rle <- if (sum(pred_mat) == 0) \"\" else encode_rle(pred_mat)\n  \n  records[[length(records) + 1]] <- data.frame(\n    ImageId = img_name,\n    rle = rle\n  )\n}\n\nsubmission <- do.call(rbind, records)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Submission","metadata":{}},{"cell_type":"code","source":"df_sub <- do.call(rbind, records)\n\ndf_sample <- read.csv(SAMPLE_SUB, stringsAsFactors = FALSE)\n\n# Reorder sesuai sample submission\ndf_sub <- df_sub[match(df_sample$ImageId, df_sub$ImageId), ]\n\nOUT_SUB <- \"/kaggle/working/submission.csv\"\n\nwrite.csv(df_sub, OUT_SUB, row.names = FALSE)\n\ncat(\"Saved to:\", OUT_SUB, \"\\n\")\ncat(\"Rows:\", nrow(df_sub), \"\\n\")\ncat(\"Empty RLE:\", sum(df_sub$rle == \"\"), \"\\n\")\n\nprint(head(df_sub))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}